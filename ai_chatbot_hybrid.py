"""
AI ì±—ë´‡ 1.5ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ (ì •ëŸ‰ ê³„ì‚° + ë²¡í„° ê²€ìƒ‰)

í•µì‹¬ ê°œì„ :
- ì§ˆë¬¸ ë¶„ë¥˜: ì •ëŸ‰í˜• vs íƒìƒ‰í˜• ìë™ êµ¬ë¶„
- ì •ëŸ‰ ê³„ì‚°: íŒë‹¤ìŠ¤ë¡œ ì •í™•í•œ ìˆ«ì ê³„ì‚° (í•©ê³„, í‰ê· , ìµœëŒ€/ìµœì†Œ ë“±)
- íƒìƒ‰ ê²€ìƒ‰: ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
- AI ì—­í• : ê³„ì‚° ê²°ê³¼ ì„¤ëª… + ê·¼ê±° ìš”ì•½ (í™˜ê° ë°©ì§€)
"""

import streamlit as st
import pandas as pd
import chromadb
import google.generativeai as genai
import uuid
import hashlib
from typing import Tuple, List, Dict, Optional, Literal
import re


# ============================================================================
# 1. ì§ˆë¬¸ ë¶„ë¥˜ ì—”ì§„
# ============================================================================

def classify_question(question: str) -> Literal["quantitative", "exploratory", "business"]:
    """
    ì§ˆë¬¸ì„ 3ê°€ì§€ ìœ í˜•ìœ¼ë¡œ ë¶„ë¥˜

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸

    Returns:
        - "quantitative": ì •ëŸ‰ ê³„ì‚° í•„ìš” (í•©ê³„, í‰ê· , ê°œìˆ˜ ë“±)
        - "exploratory": íƒìƒ‰ ê²€ìƒ‰ í•„ìš” (ì–´ë””ì—, ë¬´ì—‡ì´, ì–¸ì œ ë“±)
        - "business": ë¹„ì¦ˆë‹ˆìŠ¤ íŒë‹¨ í•„ìš” (ë¶€ì¡±, ì¶©ë¶„, ê¶Œê³  ë“±) - í–¥í›„ 2ë‹¨ê³„
    """
    q = question.lower()

    # ì •ëŸ‰í˜• í‚¤ì›Œë“œ (íŒë‹¤ìŠ¤ ê³„ì‚° í•„ìš”)
    quantitative_keywords = [
        # ì§‘ê³„ í•¨ìˆ˜
        "ì´", "ì „ì²´", "í•©ê³„", "ì´í•©", "ëª¨ë‘", "all", "total", "sum",
        "í‰ê· ", "average", "avg", "mean",
        "ìµœëŒ€", "ìµœì†Œ", "ê°€ì¥ ë§", "ê°€ì¥ ì ", "max", "min", "maximum", "minimum",
        "ê°œìˆ˜", "ëª‡ ê°œ", "ëª‡ê°œ", "count", "number of",

        # ì„¼í„°ë³„/SKUë³„ ì§‘ê³„
        "ì„¼í„°ë³„", "SKUë³„", "ì œí’ˆë³„", "ì°½ê³ ë³„",
        "ê° ì„¼í„°", "ê° SKU", "ê°ê°",

        # ë¹„êµ
        "ë§ì€", "ì ì€", "ë†’ì€", "ë‚®ì€",
    ]

    # íƒìƒ‰í˜• í‚¤ì›Œë“œ (ë²¡í„° ê²€ìƒ‰ í•„ìš”)
    exploratory_keywords = [
        "ì–´ë””", "ì–´ëŠ", "ë¬´ì—‡", "ì–¸ì œ", "ì–´ë–¤",
        "where", "what", "when", "which",
        "ëª©ë¡", "ë¦¬ìŠ¤íŠ¸", "list",
        "ë³´ìœ ", "ìˆëŠ”", "ì¡´ì¬",
    ]

    # ë¹„ì¦ˆë‹ˆìŠ¤í˜• í‚¤ì›Œë“œ (í–¥í›„ 2ë‹¨ê³„)
    business_keywords = [
        "ë¶€ì¡±", "ì¶©ë¶„", "ê¶Œê³ ", "ê¶Œì¥", "ìœ„í—˜", "ê²½ê³ ",
        "ì•ˆì „ì¬ê³ ", "ë¦¬ë“œíƒ€ì„", "ì…ê³  í•„ìš”", "ë°œì£¼",
        "insufficient", "enough", "recommend", "risk",
    ]

    # í‚¤ì›Œë“œ ë§¤ì¹­
    if any(kw in q for kw in quantitative_keywords):
        return "quantitative"
    elif any(kw in q for kw in business_keywords):
        return "business"
    elif any(kw in q for kw in exploratory_keywords):
        return "exploratory"
    else:
        # ê¸°ë³¸ê°’: íƒìƒ‰í˜• (ë²¡í„° ê²€ìƒ‰ì´ ë” ì•ˆì „)
        return "exploratory"


def extract_entities(question: str, available_centers: List[str], available_skus: List[str]) -> Dict[str, List[str]]:
    """
    ì§ˆë¬¸ì—ì„œ ì„¼í„°/SKU ê°œì²´ëª… ì¶”ì¶œ

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        available_centers: í˜„ì¬ í•„í„°ì˜ ì„¼í„° ëª©ë¡
        available_skus: í˜„ì¬ í•„í„°ì˜ SKU ëª©ë¡

    Returns:
        {"centers": [...], "skus": [...]}
    """
    q = question.upper()

    # ì„¼í„° ì¶”ì¶œ
    centers = [c for c in available_centers if c.upper() in q]

    # SKU ì¶”ì¶œ
    skus = [s for s in available_skus if s.upper() in q]

    return {
        "centers": centers if centers else available_centers,  # ì—†ìœ¼ë©´ ì „ì²´
        "skus": skus if skus else available_skus,
    }


# ============================================================================
# 2. ì •ëŸ‰ ê³„ì‚° ì—”ì§„ (íŒë‹¤ìŠ¤)
# ============================================================================

def calculate_quantitative(
    question: str,
    snapshot_df: pd.DataFrame,
    entities: Dict[str, List[str]]
) -> Dict[str, any]:
    """
    íŒë‹¤ìŠ¤ë¡œ ì •í™•í•œ ì •ëŸ‰ ê³„ì‚° ìˆ˜í–‰

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        snapshot_df: í•„í„°ë§ëœ ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        entities: ì¶”ì¶œëœ ì„¼í„°/SKU ì •ë³´

    Returns:
        {
            "type": "total" | "average" | "max" | "min" | "count" | "group_by",
            "result": ê³„ì‚° ê²°ê³¼ (ìˆ«ì ë˜ëŠ” DataFrame),
            "description": ê²°ê³¼ ì„¤ëª… í…ìŠ¤íŠ¸
        }
    """
    q = question.lower()

    # ë°ì´í„° í•„í„°ë§
    df = snapshot_df.copy()
    if "center" in df.columns:
        df = df[df["center"].isin(entities["centers"])]
    if "resource_code" in df.columns:
        df = df[df["resource_code"].isin(entities["skus"])]

    # ìµœì‹  ìŠ¤ëƒ…ìƒ·ë§Œ ì‚¬ìš© (ì„¼í„°-SKUë³„ ìµœì‹  ë‚ ì§œ)
    if "date" in df.columns and not df.empty:
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.sort_values("date").groupby(["center", "resource_code"], as_index=False).last()

    if df.empty:
        return {
            "type": "empty",
            "result": None,
            "description": "í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."
        }

    # ì¬ê³  ìˆ˜ëŸ‰ ìˆ«ì ë³€í™˜
    df["stock_qty"] = pd.to_numeric(df.get("stock_qty", 0), errors="coerce").fillna(0)

    # 1. ì´ ì¬ê³  / í•©ê³„
    if any(kw in q for kw in ["ì´", "ì „ì²´", "í•©ê³„", "ì´í•©", "total", "sum"]):
        total = df["stock_qty"].sum()
        centers_str = ", ".join(entities["centers"][:3])
        if len(entities["centers"]) > 3:
            centers_str += f" ì™¸ {len(entities["centers"]) - 3}ê³³"

        return {
            "type": "total",
            "result": total,
            "description": f"{centers_str}ì˜ ì´ ì¬ê³ ëŠ” **{total:,.0f}ê°œ**ì…ë‹ˆë‹¤.",
            "breakdown": df.groupby("center")["stock_qty"].sum().to_dict()
        }

    # 2. í‰ê· 
    if any(kw in q for kw in ["í‰ê· ", "average", "avg", "mean"]):
        avg = df["stock_qty"].mean()
        return {
            "type": "average",
            "result": avg,
            "description": f"í‰ê·  ì¬ê³ ëŠ” **{avg:,.0f}ê°œ**ì…ë‹ˆë‹¤.",
        }

    # 3. ìµœëŒ€ / ìµœì†Œ
    if any(kw in q for kw in ["ìµœëŒ€", "ê°€ì¥ ë§", "max", "maximum"]):
        max_row = df.loc[df["stock_qty"].idxmax()]
        return {
            "type": "max",
            "result": max_row["stock_qty"],
            "description": f"ì¬ê³ ê°€ ê°€ì¥ ë§ì€ ê²ƒì€ **{max_row['center']} {max_row['resource_code']}** ({max_row['stock_qty']:,.0f}ê°œ)ì…ë‹ˆë‹¤.",
        }

    if any(kw in q for kw in ["ìµœì†Œ", "ê°€ì¥ ì ", "min", "minimum"]):
        min_row = df.loc[df["stock_qty"].idxmin()]
        return {
            "type": "min",
            "result": min_row["stock_qty"],
            "description": f"ì¬ê³ ê°€ ê°€ì¥ ì ì€ ê²ƒì€ **{min_row['center']} {min_row['resource_code']}** ({min_row['stock_qty']:,.0f}ê°œ)ì…ë‹ˆë‹¤.",
        }

    # 4. ì„¼í„°ë³„ / SKUë³„ ì§‘ê³„
    if any(kw in q for kw in ["ì„¼í„°ë³„", "ê° ì„¼í„°", "ì°½ê³ ë³„"]):
        by_center = df.groupby("center")["stock_qty"].sum().sort_values(ascending=False)
        lines = [f"- **{center}**: {qty:,.0f}ê°œ" for center, qty in by_center.items()]
        return {
            "type": "group_by_center",
            "result": by_center.to_dict(),
            "description": "ì„¼í„°ë³„ ì¬ê³ :\n" + "\n".join(lines)
        }

    if any(kw in q for kw in ["SKUë³„", "ì œí’ˆë³„", "ê° SKU"]):
        by_sku = df.groupby("resource_code")["stock_qty"].sum().sort_values(ascending=False)
        lines = [f"- **{sku}**: {qty:,.0f}ê°œ" for sku, qty in by_sku.head(10).items()]
        if len(by_sku) > 10:
            lines.append(f"... ì™¸ {len(by_sku) - 10}ê°œ SKU")
        return {
            "type": "group_by_sku",
            "result": by_sku.to_dict(),
            "description": "SKUë³„ ì¬ê³  (ìƒìœ„ 10ê°œ):\n" + "\n".join(lines)
        }

    # 5. ê°œìˆ˜
    if any(kw in q for kw in ["ê°œìˆ˜", "ëª‡ ê°œ", "ëª‡ê°œ", "count"]):
        if "ì„¼í„°" in q:
            count = df["center"].nunique()
            return {
                "type": "count",
                "result": count,
                "description": f"ì„¼í„° ê°œìˆ˜ëŠ” **{count}ê°œ**ì…ë‹ˆë‹¤.",
            }
        elif "SKU" in q or "ì œí’ˆ" in q:
            count = df["resource_code"].nunique()
            return {
                "type": "count",
                "result": count,
                "description": f"SKU ê°œìˆ˜ëŠ” **{count}ê°œ**ì…ë‹ˆë‹¤.",
            }

    # ê¸°ë³¸: ì´ ì¬ê³  ë°˜í™˜
    total = df["stock_qty"].sum()
    return {
        "type": "total",
        "result": total,
        "description": f"ì¡°íšŒëœ ì¬ê³ ëŠ” **{total:,.0f}ê°œ**ì…ë‹ˆë‹¤.",
    }


# ============================================================================
# 3. ë²¡í„° ê²€ìƒ‰ ì—”ì§„ (ê¸°ì¡´ ë¡œì§)
# ============================================================================

@st.cache_resource
def _chroma_cloud():
    """Chroma Cloud í´ë¼ì´ì–¸íŠ¸"""
    try:
        client = chromadb.CloudClient(
            api_key=st.secrets["chroma"]["api_key"],
            tenant=st.secrets["chroma"]["tenant"],
            database=st.secrets["chroma"]["database"],
        )
        return client
    except Exception as e:
        st.error(f"Chroma Cloud ì—°ê²° ì‹¤íŒ¨: {e}")
        return None


def _get_filter_hash(centers: list, skus: list) -> str:
    """í•„í„° ì¡°í•© í•´ì‹œ"""
    key = f"{sorted(centers)}_{sorted(skus)}"
    return hashlib.md5(key.encode()).hexdigest()[:8]


def _build_session_collection_name() -> str:
    """ì„¸ì…˜ ì»¬ë ‰ì…˜ëª…"""
    sid = st.session_state.get("_ai_session_id")
    if not sid:
        sid = st.session_state["_ai_session_id"] = uuid.uuid4().hex[:8]
    return f"scm_session_{sid}"


def _embed_batch(texts: list[str], batch_size: int = 100) -> list[list[float]]:
    """Gemini ì„ë² ë”© (ë°°ì¹˜ ì²˜ë¦¬)"""
    if not texts:
        return []

    genai.configure(api_key=st.secrets["gemini"]["api_key"])
    model = st.secrets["gemini"].get("embedding_model", "text-embedding-004")

    all_embeddings = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i + batch_size]
        try:
            res = genai.embed_content(
                model=model,
                content=batch,
                task_type="retrieval_document"
            )
            if hasattr(res, "embeddings"):
                all_embeddings.extend([e.values for e in res.embeddings])
            elif isinstance(res, dict) and "embeddings" in res:
                all_embeddings.extend([r["embedding"] for r in res["embeddings"]])
            else:
                all_embeddings.append(res["embedding"])
        except Exception as e:
            st.warning(f"ì„ë² ë”© ë°°ì¹˜ {i//batch_size + 1} ì‹¤íŒ¨: {e}")
            continue

    return all_embeddings


def _documents_from_snapshot(snap: pd.DataFrame, max_rows: int = 2000) -> Tuple[List[str], List[Dict], List[str]]:
    """ìŠ¤ëƒ…ìƒ· â†’ ë¬¸ì„œ ë³€í™˜"""
    docs, metas, ids = [], [], []
    use = snap.head(max_rows)

    for i, r in use.iterrows():
        # ë‚ ì§œë¥¼ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜
        date_val = r.get('date')
        if pd.isna(date_val):
            date_str = "N/A"
        else:
            try:
                date_str = pd.to_datetime(date_val).strftime('%Y-%m-%d')
            except:
                date_str = str(date_val)

        doc = (
            f"[SNAPSHOT] "
            f"ë‚ ì§œ:{date_str} "
            f"ì„¼í„°:{r.get('center')} "
            f"SKU:{r.get('resource_code')} "
            f"ì¬ê³ :{r.get('stock_qty')}ê°œ"
        )
        if pd.notna(r.get('resource_name')):
            doc += f" ({r.get('resource_name')})"

        docs.append(doc)
        # "type" í‚¤ì›Œë“œëŠ” Chroma ë‚´ë¶€ ì˜ˆì•½ì–´ì´ë¯€ë¡œ "doc_type"ìœ¼ë¡œ ë³€ê²½
        metas.append({
            "doc_type": "snapshot",
            "center": str(r.get("center", "")) if pd.notna(r.get("center")) else "",
            "sku": str(r.get("resource_code", "")) if pd.notna(r.get("resource_code")) else "",
            "date": date_str,
        })
        ids.append(f"snap-{i}")

    return docs, metas, ids


def _ensure_session_index(snap_filtered: pd.DataFrame, filter_hash: str, max_rows: int = 2000):
    """ì„¸ì…˜ ì¸ë±ìŠ¤ ìƒì„±/ì¬ì‚¬ìš© (ìºì‹±)"""
    client = _chroma_cloud()
    if client is None:
        return None, 0

    col_name = _build_session_collection_name()

    # ìºì‹±: ê°™ì€ í•„í„°ë©´ ì¬ì‚¬ìš©
    if st.session_state.get("_last_filter_hash") == filter_hash:
        try:
            col = client.get_collection(col_name)
            return col, col.count()
        except:
            pass

    # ìƒˆ ì¸ë±ì‹±
    try:
        client.delete_collection(col_name)
    except:
        pass

    col = client.create_collection(col_name)

    docs, metas, ids = _documents_from_snapshot(snap_filtered, max_rows)
    if not docs:
        return col, 0

    embs = _embed_batch(docs, batch_size=100)
    if len(embs) != len(docs):
        docs = docs[:len(embs)]
        metas = metas[:len(embs)]
        ids = ids[:len(embs)]

    if embs:
        col.add(ids=ids, documents=docs, metadatas=metas, embeddings=embs)

    st.session_state["_last_filter_hash"] = filter_hash
    return col, len(docs)


def search_documents(col: chromadb.Collection, question: str, k: int = 5) -> List[str]:
    """ë²¡í„° ê²€ìƒ‰"""
    try:
        res = col.query(query_texts=[question], n_results=k)
        return res.get("documents", [[]])[0]
    except Exception as e:
        st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


# ============================================================================
# 4. í•˜ì´ë¸Œë¦¬ë“œ ë‹µë³€ ìƒì„±
# ============================================================================

def generate_hybrid_answer(
    question: str,
    question_type: str,
    calc_result: Optional[Dict] = None,
    search_docs: Optional[List[str]] = None,
    session_digest: str = ""
) -> str:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ë‹µë³€ ìƒì„±

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        question_type: "quantitative" | "exploratory"
        calc_result: ì •ëŸ‰ ê³„ì‚° ê²°ê³¼
        search_docs: ë²¡í„° ê²€ìƒ‰ ë¬¸ì„œ
        session_digest: ì„¸ì…˜ ìš”ì•½

    Returns:
        AI ë‹µë³€ í…ìŠ¤íŠ¸
    """
    try:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        model_name = st.secrets["gemini"].get("generation_model", "gemini-1.5-flash")
        model = genai.GenerativeModel(model_name)

        if question_type == "quantitative":
            # ì •ëŸ‰í˜•: ê³„ì‚° ê²°ê³¼ë¥¼ ì„¤ëª…/í•´ì„
            prompt = f"""ë‹¹ì‹ ì€ SCM ì¬ê³  ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ê³„ì‚° ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…í•˜ì„¸ìš”.

[ì§ˆë¬¸]
{question}

[ì •í™•í•œ ê³„ì‚° ê²°ê³¼]
{calc_result.get('description', '')}

[ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸]
{session_digest}

**ë‹µë³€ ê·œì¹™:**
1. ê³„ì‚° ê²°ê³¼ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ìˆ«ì ë³€ê²½ ê¸ˆì§€)
2. 2-3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
3. ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ë‚˜ í•´ì„ ì œê³µ ê°€ëŠ¥
4. í•œêµ­ì–´ë¡œ ì‘ì„±

ë‹µë³€:"""

        else:  # exploratory
            # íƒìƒ‰í˜•: ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½
            prompt = f"""ë‹¹ì‹ ì€ SCM ì¬ê³  ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ê·¼ê±° ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì„œ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”.

[ì§ˆë¬¸]
{question}

[ê·¼ê±° ë°ì´í„°]
{chr(10).join(f"- {d}" for d in search_docs)}

[ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸]
{session_digest}

**ë‹µë³€ ê·œì¹™:**
1. ê·¼ê±° ë°ì´í„°ì— ìˆëŠ” ì •ë³´ë§Œ ì‚¬ìš©
2. ìˆ˜ì¹˜/ì„¼í„°/SKUë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨
3. 2-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ
4. ì¶”ì •í•˜ì§€ ë§ ê²ƒ
5. í•œêµ­ì–´ë¡œ ì‘ì„±

ë‹µë³€:"""

        response = model.generate_content(prompt)
        return response.text

    except Exception as e:
        st.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
        # í´ë°±
        if calc_result:
            return calc_result.get('description', 'ê³„ì‚° ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.')
        else:
            return "ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\n\n" + \
                   "\n".join(f"â€¢ {d}" for d in (search_docs or [])[:3])


# ============================================================================
# 5. ë©”ì¸ UI í•¨ìˆ˜
# ============================================================================

def render_hybrid_chatbot_tab(
    snapshot_df: pd.DataFrame,
    selected_centers: List[str],
    selected_skus: List[str]
):
    """
    í•˜ì´ë¸Œë¦¬ë“œ AI ì±—ë´‡ íƒ­ ë Œë”ë§

    Args:
        snapshot_df: ì „ì²´ ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        selected_centers: ì„ íƒëœ ì„¼í„°
        selected_skus: ì„ íƒëœ SKU
    """
    st.subheader("ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸ (1.5ë‹¨ê³„: í•˜ì´ë¸Œë¦¬ë“œ)")

    # í•„í„°ë§
    snap = snapshot_df.copy()
    if "center" in snap.columns:
        snap = snap[snap["center"].astype(str).isin(selected_centers)]
    if "resource_code" in snap.columns:
        snap = snap[snap["resource_code"].astype(str).isin(selected_skus)]

    if snap.empty:
        st.warning("ì„ íƒëœ í•„í„°ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    # ì„¸ì…˜ ìš”ì•½
    session_digest = (
        f"ì´ ì¬ê³ ={pd.to_numeric(snap.get('stock_qty'), errors='coerce').fillna(0).sum():,.0f}ê°œ / "
        f"ì„¼í„° {snap.get('center', pd.Series([], dtype=str)).nunique()}ê³³ / "
        f"SKU {snap.get('resource_code', pd.Series([], dtype=str)).nunique()}ê°œ / "
        f"ìµœì‹ ì¼={pd.to_datetime(snap.get('date'), errors='coerce').max():%Y-%m-%d}"
    )

    # í•„í„° í•´ì‹œ
    filter_hash = _get_filter_hash(selected_centers, selected_skus)

    # ìë™ ì¸ë±ì‹± (íƒìƒ‰í˜• ì§ˆë¬¸ ëŒ€ë¹„)
    if st.session_state.get("_last_filter_hash") != filter_hash:
        with st.spinner("ğŸ“š ë²¡í„° ì¸ë±ìŠ¤ ì¤€ë¹„ ì¤‘..."):
            try:
                col, n = _ensure_session_index(snap, filter_hash, max_rows=2000)
                if col and n > 0:
                    st.success(f"âœ… {n:,}ê±´ ì¸ë±ì‹± ì™„ë£Œ")
            except Exception as e:
                st.warning(f"ì¸ë±ì‹± ì‹¤íŒ¨ (ì •ëŸ‰ ê³„ì‚°ì€ ê°€ëŠ¥): {e}")

    # ì„¸ì…˜ ì •ë³´
    with st.expander("â„¹ï¸ ì„¸ì…˜ ì •ë³´"):
        st.caption(session_digest)
        st.caption("**ì‹œìŠ¤í…œ ëª¨ë“œ:** í•˜ì´ë¸Œë¦¬ë“œ (ì •ëŸ‰ ê³„ì‚° + ë²¡í„° ê²€ìƒ‰)")

    st.divider()

    # ì§ˆë¬¸ ì…ë ¥
    q = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: REVVNì˜ ì´ ì¬ê³ ëŠ”? / ì¬ê³ ê°€ ê°€ì¥ ë§ì€ ì„¼í„°ëŠ”?",
        key="hybrid_q"
    )

    col1, col2 = st.columns([4, 1])
    with col2:
        k = st.slider("ê²€ìƒ‰ ê²°ê³¼", 1, 10, 5, key="hybrid_k")

    if st.button("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", type="primary") and q:
        with st.spinner("ğŸ” ë¶„ì„ ì¤‘..."):
            # 1. ì§ˆë¬¸ ë¶„ë¥˜
            q_type = classify_question(q)
            entities = extract_entities(q, selected_centers, selected_skus)

            st.caption(f"ğŸ”– ì§ˆë¬¸ ìœ í˜•: **{q_type}** | ëŒ€ìƒ: {entities['centers'][:2]} Ã— {entities['skus'][:2]}")

            # 2. ì§ˆë¬¸ ìœ í˜•ë³„ ì²˜ë¦¬
            if q_type == "quantitative":
                # ì •ëŸ‰ ê³„ì‚°
                calc_result = calculate_quantitative(q, snap, entities)

                # AI ì„¤ëª… ìƒì„±
                answer = generate_hybrid_answer(
                    question=q,
                    question_type="quantitative",
                    calc_result=calc_result,
                    session_digest=session_digest
                )

                st.markdown("### ğŸ“Š ë‹µë³€")
                st.markdown(answer)

                # ê³„ì‚° ìƒì„¸
                with st.expander("ğŸ”¢ ê³„ì‚° ìƒì„¸"):
                    st.write(f"**ê³„ì‚° ìœ í˜•:** {calc_result['type']}")
                    st.write(f"**ê²°ê³¼:** {calc_result['result']}")
                    if "breakdown" in calc_result:
                        st.write("**ì„¼í„°ë³„ ë¶„í•´:**")
                        for center, qty in calc_result["breakdown"].items():
                            st.write(f"- {center}: {qty:,.0f}ê°œ")

            elif q_type == "exploratory":
                # ë²¡í„° ê²€ìƒ‰
                try:
                    client = _chroma_cloud()
                    col = client.get_collection(_build_session_collection_name())
                    docs = search_documents(col, q, k=k)

                    if not docs:
                        st.info("ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í•„í„°ë¥¼ ì¡°ì •í•´ë³´ì„¸ìš”.")
                    else:
                        # AI ìš”ì•½ ìƒì„±
                        answer = generate_hybrid_answer(
                            question=q,
                            question_type="exploratory",
                            search_docs=docs,
                            session_digest=session_digest
                        )

                        st.markdown("### ğŸ“Š ë‹µë³€")
                        st.markdown(answer)

                        # ê·¼ê±°
                        with st.expander("ğŸ” ê·¼ê±° ë°ì´í„°"):
                            for i, d in enumerate(docs, 1):
                                st.write(f"{i}. {d}")

                except Exception as e:
                    st.error(f"ê²€ìƒ‰ ì‹¤íŒ¨: {e}")

            else:  # business
                st.info("ğŸš§ ë¹„ì¦ˆë‹ˆìŠ¤ íŒë‹¨ ì§ˆë¬¸ì€ 2ë‹¨ê³„ì—ì„œ ì§€ì› ì˜ˆì •ì…ë‹ˆë‹¤.")
                st.caption("í˜„ì¬ëŠ” ì •ëŸ‰ ê³„ì‚°ê³¼ íƒìƒ‰ ê²€ìƒ‰ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.")

    # ì˜ˆì‹œ ì§ˆë¬¸
    st.divider()
    st.caption("**ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:**")

    col1, col2 = st.columns(2)
    with col1:
        st.caption("**ì •ëŸ‰ ê³„ì‚°í˜•**")
        st.caption("â€¢ ì´ ì¬ê³ ëŠ”?")
        st.caption("â€¢ ì„¼í„°ë³„ ì¬ê³ ëŠ”?")
        st.caption("â€¢ ì¬ê³ ê°€ ê°€ì¥ ë§ì€ ì„¼í„°ëŠ”?")
        st.caption("â€¢ SKU ê°œìˆ˜ëŠ”?")

    with col2:
        st.caption("**íƒìƒ‰í˜•**")
        st.caption("â€¢ REVVNì—ëŠ” ì–´ë–¤ SKUê°€ ìˆë‚˜ìš”?")
        st.caption("â€¢ BA00021ì€ ì–´ëŠ ì„¼í„°ì— ìˆë‚˜ìš”?")
        st.caption("â€¢ ìµœê·¼ ìŠ¤ëƒ…ìƒ· ë‚ ì§œëŠ”?")
        st.caption("â€¢ íƒœê´‘KRì˜ ì¬ê³  í˜„í™©ì€?")
