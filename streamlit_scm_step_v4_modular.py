"""Modularised entry point for the SCM dashboard v4."""

from __future__ import annotations

from typing import Dict, List, Optional

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from scm_dashboard_v4.config import CENTER_COL, PALETTE, configure_page, initialize_session_state
from scm_dashboard_v4.consumption import apply_consumption_with_events
from scm_dashboard_v4.inventory import pivot_inventory_cost_from_raw
from scm_dashboard_v4.kpi import kpi_breakdown_per_sku
from scm_dashboard_v4.loaders import load_from_excel, load_from_gsheet_api, load_snapshot_raw
from scm_dashboard_v4.processing import (
    merge_wip_as_moves,
    normalize_center_name,
    normalize_moves,
    normalize_refined_snapshot,
    load_wip_from_incoming,
)
from scm_dashboard_v4.sales import prepare_amazon_sales_series
from scm_dashboard_v4.timeline import build_timeline
from scm_dashboard_v4.sales import prepare_amazon_daily_sales

configure_page()
initialize_session_state()


# ==================== Tabs for inputs ====================
tab1, tab2 = st.tabs(["ì—‘ì…€ ì—…ë¡œë“œ", "Google Sheets"])

moves: Optional[pd.DataFrame] = None
snap_long: Optional[pd.DataFrame] = None

with tab1:
    xfile = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"], key="excel_modular")
    if xfile is not None:
        df_move, df_ref, df_incoming, snap_raw_df = load_from_excel(xfile)
        st.session_state["_data_source"] = "excel"
        st.session_state["_snapshot_raw_cache"] = snap_raw_df

        moves_raw = normalize_moves(df_move)
        snap_long = normalize_refined_snapshot(df_ref)

        try:
            wip_df = load_wip_from_incoming(df_incoming)
            moves = merge_wip_as_moves(moves_raw, wip_df)
            st.success(
                f"WIP {len(wip_df)}ê±´ ë°˜ì˜ ì™„ë£Œ" if wip_df is not None and not wip_df.empty else "WIP ì—†ìŒ"
            )
        except Exception as exc:
            moves = moves_raw
            st.warning(f"WIP ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {exc}")

with tab2:
    st.info("Google Sheets APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.")
    st.caption("ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ ì¸ì¦í•©ë‹ˆë‹¤.")

    if st.button("Google Sheetsì—ì„œ ë°ì´í„° ë¡œë“œ", type="primary"):
        try:
            df_move, df_ref, df_incoming = load_from_gsheet_api()

            if df_move.empty or df_ref.empty:
                st.error("âŒ Google Sheets APIë¡œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                st.stop()

            st.session_state["_data_source"] = "gsheet"

            moves_raw = normalize_moves(df_move)
            snap_long = normalize_refined_snapshot(df_ref)
            try:
                wip_df = load_wip_from_incoming(df_incoming)
                moves = merge_wip_as_moves(moves_raw, wip_df)
                st.success(
                    f"âœ… Google Sheets ë¡œë“œ ì™„ë£Œ! WIP {len(wip_df)}ê±´ ë°˜ì˜" if wip_df is not None and not wip_df.empty else "âœ… Google Sheets ë¡œë“œ ì™„ë£Œ! WIP ì—†ìŒ"
                )
            except Exception as exc:
                moves = moves_raw
                st.warning(f"âš ï¸ WIP ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {exc}")
        except Exception as exc:
            st.error(f"âŒ Google Sheets ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")
            st.info(
                "ğŸ’¡ í•´ê²° ë°©ë²•:\n- ì„œë¹„ìŠ¤ ê³„ì • í‚¤ íŒŒì¼ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸\n- ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— ì„œë¹„ìŠ¤ ê³„ì • ì´ë©”ì¼ì´ ê³µìœ ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n- ì‹œíŠ¸ëª…ì´ ì •í™•í•œì§€ í™•ì¸ (SCM_í†µí•©, snap_ì •ì œ)"
            )

if moves is None or snap_long is None:
    try:
        df_move, df_ref, df_incoming = load_from_gsheet_api()
        if not df_move.empty and not df_ref.empty:
            st.session_state["_data_source"] = "gsheet"
            moves = normalize_moves(df_move)
            snap_long = normalize_refined_snapshot(df_ref)
            try:
                wip_df = load_wip_from_incoming(df_incoming)
                moves = merge_wip_as_moves(moves, wip_df)
            except Exception:
                pass
            st.success("âœ… Google Sheetsì—ì„œ ë°ì´í„° ë¡œë“œë¨ (í•„ìš” ì‹œ ì—‘ì…€ ì—…ë¡œë“œ íƒ­ ì‚¬ìš© ê°€ëŠ¥)")
        else:
            st.info("ì—‘ì…€ ì—…ë¡œë“œ ë˜ëŠ” Google Sheetsì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ë©´ í•„í„°/ì°¨íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
            st.stop()
    except Exception:
        st.info("ì—‘ì…€ ì—…ë¡œë“œ ë˜ëŠ” Google Sheetsì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ë©´ í•„í„°/ì°¨íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
        st.stop()

assert moves is not None and snap_long is not None

# -------------------- Filters --------------------
centers_snap = set(snap_long["center"].dropna().astype(str).unique().tolist())
centers_moves = set(
    moves["from_center"].dropna().astype(str).unique().tolist() + moves["to_center"].dropna().astype(str).unique().tolist()
)

all_centers = set()
for center in centers_snap | centers_moves:
    normalized = normalize_center_name(center)
    if normalized:
        all_centers.add(normalized)

centers = sorted(list(all_centers))
skus = sorted(snap_long["resource_code"].dropna().astype(str).unique().tolist())

today = pd.Timestamp.today().normalize()
PAST_DAYS = 42
FUTURE_DAYS = 60

snap_min = pd.to_datetime(snap_long["date"]).min().normalize()
snap_max = pd.to_datetime(snap_long["date"]).max().normalize()

bound_min = max(today - pd.Timedelta(days=PAST_DAYS), snap_min)
bound_max = min(today + pd.Timedelta(days=FUTURE_DAYS), snap_max + pd.Timedelta(days=60))


def _init_range() -> None:
    if "date_range" not in st.session_state:
        st.session_state.date_range = (
            max(today - pd.Timedelta(days=20), bound_min),
            min(today + pd.Timedelta(days=20), bound_max),
        )
    if "horizon_days" not in st.session_state:
        st.session_state.horizon_days = 20


def _apply_horizon_to_range() -> None:
    h = int(st.session_state.horizon_days)
    h = max(0, min(h, FUTURE_DAYS))
    st.session_state.horizon_days = h
    start = max(today - pd.Timedelta(days=h), bound_min)
    end = min(today + pd.Timedelta(days=h), bound_max)
    st.session_state.date_range = (start, end)


def _clamp_range(r: tuple[pd.Timestamp, pd.Timestamp]) -> tuple[pd.Timestamp, pd.Timestamp]:
    s, e = pd.Timestamp(r[0]).normalize(), pd.Timestamp(r[1]).normalize()
    s = max(min(s, bound_max), bound_min)
    e = max(min(e, bound_max), bound_min)
    if e < s:
        e = s
    return (s, e)


_init_range()

st.sidebar.header("í•„í„°")
centers_sel = st.sidebar.multiselect("ì„¼í„° ì„ íƒ", centers, default=(["íƒœê´‘KR"] if "íƒœê´‘KR" in centers else centers[:1]))
skus_sel = st.sidebar.multiselect("SKU ì„ íƒ", skus, default=([s for s in ["BA00022", "BA00021"] if s in skus] or skus[:2]))

st.sidebar.subheader("ê¸°ê°„ ì„¤ì •")
st.sidebar.number_input(
    "ë¯¸ë˜ ì „ë§ ì¼ìˆ˜",
    min_value=0,
    max_value=FUTURE_DAYS,
    step=1,
    key="horizon_days",
    on_change=_apply_horizon_to_range,
)

range_value = st.sidebar.slider(
    "ê¸°ê°„",
    min_value=bound_min.to_pydatetime(),
    max_value=bound_max.to_pydatetime(),
    value=tuple(d.to_pydatetime() for d in _clamp_range(st.session_state.date_range)),
    format="YYYY-MM-DD",
)

start_dt = pd.Timestamp(range_value[0]).normalize()
end_dt = pd.Timestamp(range_value[1]).normalize()
_latest_snap = snap_long["date"].max()
proj_days_for_build = max(0, int((end_dt - _latest_snap).days))

st.sidebar.header("í‘œì‹œ ì˜µì…˜")
show_prod = st.sidebar.checkbox("ìƒì‚°ì¤‘(ë¯¸ì™„ë£Œ) í‘œì‹œ", value=True)
use_cons_forecast = st.sidebar.checkbox("ì¶”ì„¸ ê¸°ë°˜ ì¬ê³  ì˜ˆì¸¡", value=True)
lookback_days = st.sidebar.number_input("ì¶”ì„¸ ê³„ì‚° ê¸°ê°„(ì¼)", min_value=7, max_value=56, value=28, step=7)

st.sidebar.subheader("ì…ê³  ë°˜ì˜ ê°€ì •")
lag_days = st.sidebar.number_input(
    "ì…ê³  ë°˜ì˜ ë¦¬ë“œíƒ€ì„(ì¼) â€“ inbound ë¯¸ê¸°ë¡ ì‹œ arrival+N",
    min_value=0,
    max_value=21,
    value=7,
    step=1,
)

with st.sidebar.expander("í”„ë¡œëª¨ì…˜ ê°€ì¤‘ì¹˜(+%)", expanded=False):
    enable_event = st.checkbox("ê°€ì¤‘ì¹˜ ì ìš©", value=False)
    ev_start = st.date_input("ì‹œì‘ì¼")
    ev_end = st.date_input("ì¢…ë£Œì¼")
    ev_pct = st.number_input("ê°€ì¤‘ì¹˜(%)", min_value=-100.0, max_value=300.0, value=30.0, step=5.0)

if enable_event:
    events = [
        {
            "start": pd.Timestamp(ev_start).strftime("%Y-%m-%d"),
            "end": pd.Timestamp(ev_end).strftime("%Y-%m-%d"),
            "uplift": ev_pct / 100.0,
        }
    ]
else:
    events = []

# -------------------- KPIs (SKUë³„ ë¶„í•´) --------------------
st.subheader("ìš”ì•½ KPI")

_snap_date_col = "date" if "date" in snap_long.columns else "snapshot_date"
_latest_dt = pd.to_datetime(snap_long[_snap_date_col]).max().normalize()
_latest_dt_str = _latest_dt.strftime("%Y-%m-%d")

_name_col = None
for cand in ["resource_name", "ìƒí’ˆëª…", "í’ˆëª…"]:
    if cand in snap_long.columns:
        _name_col = cand
        break
_name_map: Dict[str, str] = {}
if _name_col:
    name_rows = (
        snap_long[snap_long[_snap_date_col] == _latest_dt]
        .dropna(subset=["resource_code"])[["resource_code", _name_col]]
        .drop_duplicates()
    )
    _name_map = dict(zip(name_rows["resource_code"].astype(str), name_rows[_name_col].astype(str)))

_today = pd.Timestamp.today().normalize()
mv = moves.copy()
mv["carrier_mode"] = mv["carrier_mode"].astype(str).str.upper()
mv["resource_code"] = mv["resource_code"].astype(str)

kpi_df = kpi_breakdown_per_sku(
    snap_long,
    mv,
    centers_sel,
    skus_sel,
    _today,
    _snap_date_col,
    _latest_dt,
    int(lag_days),
)


def _chunks(lst: List[str], n: int):
    for i in range(0, len(lst), n):
        yield lst[i : i + n]


for group in _chunks(skus_sel, 2):
    cols = st.columns(len(group))
    for i, sku in enumerate(group):
        with cols[i].container(border=True):
            name = _name_map.get(sku, "")
            if name:
                st.markdown(f"**{name}**  \n`{sku}`")
            else:
                st.markdown(f"`{sku}`")
            c1, c2, c3 = st.columns(3)
            c1.metric("í˜„ì¬ ì¬ê³ ", f"{kpi_df.loc[sku, 'current']:,}")
            c2.metric("ì´ë™ì¤‘", f"{kpi_df.loc[sku, 'in_transit']:,}")
            c3.metric("ìƒì‚°ì¤‘", f"{kpi_df.loc[sku, 'wip']:,}")

st.divider()

# -------------------- Step Chart --------------------
st.subheader("ê³„ë‹¨ì‹ ì¬ê³  íë¦„")

timeline = build_timeline(
    snap_long,
    moves,
    centers_sel,
    skus_sel,
    start_dt,
    end_dt,
    horizon_days=proj_days_for_build,
    today=today,
    lag_days=int(lag_days),
)

if use_cons_forecast and not timeline.empty:
    timeline = apply_consumption_with_events(
        timeline,
        snap_long,
        centers_sel,
        skus_sel,
        start_dt,
        end_dt,
        lookback_days=int(lookback_days),
        events=events,
    )

if timeline.empty:
    st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    vis_df = timeline[(timeline["date"] >= start_dt) & (timeline["date"] <= end_dt)].copy()
    vis_df.loc[vis_df["center"] == "WIP", "center"] = "ìƒì‚°ì¤‘"
    if "íƒœê´‘KR" not in centers_sel:
        vis_df = vis_df[vis_df["center"] != "ìƒì‚°ì¤‘"]
    if not show_prod:
        vis_df = vis_df[vis_df["center"] != "ìƒì‚°ì¤‘"]

    vis_df = vis_df[vis_df["stock_qty"] > 0]

    vis_df["label"] = vis_df["resource_code"] + " @ " + vis_df["center"]

    fig = px.line(
        vis_df,
        x="date",
        y="stock_qty",
        color="label",
        line_shape="hv",
        title="ì„ íƒí•œ SKU Ã— ì„¼í„°(ë° ì´ë™ì¤‘/ìƒì‚°ì¤‘) ê³„ë‹¨ì‹ ì¬ê³  íë¦„",
        render_mode="svg",
    )
    fig.update_layout(
        hovermode="x unified",
        xaxis_title="ë‚ ì§œ",
        yaxis_title="ì¬ê³ ëŸ‰(EA)",
        legend_title_text="SKU @ Center / ìƒì‚°ì¤‘(ì ì„ )",
        margin=dict(l=20, r=20, t=60, b=20),
    )


    if vis_df.empty:
        st.info("ì„ íƒí•œ ì¡°ê±´ì—ì„œ í‘œì‹œí•  ì„¼í„°/ìƒì‚°ì¤‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        vis_df["label"] = vis_df["resource_code"] + " @ " + vis_df["center"]

        fig = px.line(
            vis_df,
            x="date",
            y="stock_qty",
            color="label",
            line_shape="hv",
            title="ì„ íƒí•œ SKU Ã— ì„¼í„°(ë° ìƒì‚°ì¤‘) ê³„ë‹¨ì‹ ì¬ê³  íë¦„",
            render_mode="svg",
        )
        fig.update_layout(
            hovermode="x unified",
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ì¬ê³ ëŸ‰(EA)",
            legend_title_text="SKU @ Center / ìƒì‚°ì¤‘(ì ì„ )",
            margin=dict(l=20, r=20, t=60, b=20),
        )

        if start_dt <= today <= end_dt:
            fig.add_vline(x=today, line_width=1, line_dash="solid", line_color="rgba(255, 0, 0, 0.4)")
            fig.add_annotation(
                x=today,
                y=1.02,
                xref="x",
                yref="paper",
                text="ì˜¤ëŠ˜",
                showarrow=False,
                font=dict(size=12, color="#555"),
                align="center",
                yanchor="bottom",
            )

        fig.update_yaxes(tickformat=",.0f")
        fig.update_traces(
            hovertemplate="ë‚ ì§œ: %{x|%Y-%m-%d}<br>ì¬ê³ : %{y:,.0f} EA<br>%{fullData.name}<extra></extra>"
        )

        line_colors: Dict[str, str] = {}
        color_idx = 0
        for tr in fig.data:
            name = tr.name or ""
            if " @ " in name and name not in line_colors:
                line_colors[name] = PALETTE[color_idx % len(PALETTE)]
                color_idx += 1
        for i, tr in enumerate(fig.data):
            name = tr.name or ""
            if " @ " not in name:
                continue
            _, kind = name.split(" @ ", 1)
            line_color = line_colors.get(name, PALETTE[0])
            if kind == "ìƒì‚°ì¤‘":
                fig.data[i].update(line=dict(color=line_color, dash="dash", width=1.0), opacity=0.8)
            else:
                fig.data[i].update(line=dict(color=line_color, dash="solid", width=1.5), opacity=1.0)

        chart_key = (
            f"stepchart|centers={','.join(centers_sel)}|skus={','.join(skus_sel)}|"
            f"{start_dt:%Y%m%d}-{end_dt:%Y%m%d}|h{int(st.session_state.horizon_days)}|"
            f"prod{int(show_prod)}"
        )
        st.plotly_chart(fig, use_container_width=True, config={"displaylogo": False}, key=chart_key)

# ==================== Amazon US Sales vs Inventory ====================
amazon_centers = sorted({c for c in snap_long["center"].unique() if "amazon" in str(c).lower()})
selected_amazon_centers = [c for c in centers_sel if c in amazon_centers]

sales_series = prepare_amazon_daily_sales(
    snap_long,
    centers=selected_amazon_centers or amazon_centers,
    skus=skus_sel,
    rolling_window=7,
)

if not sales_series.empty:
    sales_df = sales_series.frame
    # This chart shows Amazon-related snapshot totals with derived sales deltas.
    # Users can toggle individual traces (sales, inventory, rolling avg) via the legend.
    st.divider()
    st.subheader("Amazon US ì¼ë³„ íŒë§¤ vs. ì¬ê³ ")

    chart = make_subplots(specs=[[{"secondary_y": True}]])
    chart.add_trace(
        go.Bar(
            x=sales_df["date"],
            y=sales_df["daily_sales"],
            name="Daily Sales (EA)",
            marker_color=PALETTE[0],
        ),
        secondary_y=False,
    )
    chart.add_trace(
        go.Scatter(
            x=sales_df["date"],
            y=sales_df["inventory_qty"],
            mode="lines+markers",
            name="Amazon Inventory (EA)",
            line=dict(color=PALETTE[1], width=2),
        ),
        secondary_y=True,
    )


    line_colors: Dict[str, str] = {}
    color_idx = 0
    for tr in fig.data:
        name = tr.name or ""
        if " @ " in name and name not in line_colors:
            line_colors[name] = PALETTE[color_idx % len(PALETTE)]
            color_idx += 1
    for i, tr in enumerate(fig.data):
        name = tr.name or ""
        if " @ " not in name:
            continue
        _, kind = name.split(" @ ", 1)
        line_color = line_colors.get(name, PALETTE[0])
        if kind == "ìƒì‚°ì¤‘":
            fig.data[i].update(line=dict(color=line_color, dash="dash", width=1.0), opacity=0.8)
        else:
            fig.data[i].update(line=dict(color=line_color, dash="solid", width=1.5), opacity=1.0)

    chart_key = (
        f"stepchart|centers={','.join(centers_sel)}|skus={','.join(skus_sel)}|"
        f"{start_dt:%Y%m%d}-{end_dt:%Y%m%d}|h{int(st.session_state.horizon_days)}|"
        f"prod{int(show_prod)}"
    )
    sales_fig.update_yaxes(tickformat=",.0f")
    st.plotly_chart(sales_fig, use_container_width=True, config={"displaylogo": False})

# -------------------- Amazon US sales vs. inventory --------------------
st.subheader("Amazon US ì¼ì¼ íŒë§¤ & ì¬ê³ ")
sales_result = prepare_amazon_sales_series(snap_long, skus_sel, start_dt, end_dt)
sales_df = sales_result.data

if sales_df.empty:
    st.caption("ì„ íƒëœ SKU/ê¸°ê°„ì— ëŒ€í•œ Amazon US íŒë§¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    sales_fig = go.Figure()
    sales_fig.add_bar(
        x=sales_df["date"],
        y=sales_df["sales_qty"],
        name="ì¼ì¼ íŒë§¤ëŸ‰",
        marker_color="#ff7f0e",
        opacity=0.8,
    )
    sales_fig.add_scatter(
        x=sales_df["date"],
        y=sales_df["inventory_qty"],
        name="Amazon ì¬ê³ ",
        mode="lines",
        line=dict(color="#1f77b4", width=2),
        yaxis="y2",
    )
    sales_fig.add_scatter(
        x=sales_df["date"],
        y=sales_df["sales_roll_mean"],
        name="íŒë§¤ 7ì¼ ì´ë™í‰ê· ",
        mode="lines",
        line=dict(color="#d62728", dash="dash"),
        visible="legendonly",
    )

    sales_fig.update_layout(
        barmode="overlay",
        hovermode="x unified",
        legend_title_text="Amazon íŒë§¤/ì¬ê³ ",
        xaxis=dict(title="ë‚ ì§œ"),
        yaxis=dict(title="ì¼ì¼ íŒë§¤ëŸ‰(EA)"),
        yaxis2=dict(title="Amazon ì¬ê³ (EA)", overlaying="y", side="right"),
        margin=dict(l=20, r=40, t=40, b=20),
    )
    sales_fig.update_yaxes(tickformat=",.0f")
    st.plotly_chart(sales_fig, use_container_width=True, config={"displaylogo": False})

# -------------------- Upcoming Arrivals (fixed) --------------------
st.subheader("ì…ê³  ì˜ˆì • ë‚´ì—­ (ì„ íƒ ì„¼í„°/SKU)")
window_start = start_dt
window_end = end_dt

mv_view = mv.copy()
if not mv_view.empty:
    pred_inbound = pd.Series(pd.NaT, index=mv_view.index, dtype="datetime64[ns]")

    mask_inb = mv_view["inbound_date"].notna()
    pred_inbound.loc[mask_inb] = mv_view.loc[mask_inb, "inbound_date"]

    mask_arr = (~mask_inb) & mv_view["arrival_date"].notna()
    if mask_arr.any():
        past_arr = mask_arr & (mv_view["arrival_date"] <= today)
        pred_inbound.loc[past_arr] = mv_view.loc[past_arr, "arrival_date"] + pd.Timedelta(days=int(lag_days))

        fut_arr = mask_arr & (mv_view["arrival_date"] > today)
        pred_inbound.loc[fut_arr] = mv_view.loc[fut_arr, "arrival_date"]

    mv_view["pred_inbound_date"] = pred_inbound

arr_transport = mv_view[
    (mv_view["carrier_mode"] != "WIP")
    & (mv_view["to_center"].isin(centers_sel))
    & (mv_view["resource_code"].isin(skus_sel))
    & (mv_view["inbound_date"].isna())
].copy()

arr_transport["display_date"] = arr_transport["arrival_date"].fillna(arr_transport["onboard_date"])
arr_transport = arr_transport[arr_transport["display_date"].notna()]
arr_transport = arr_transport[
    (arr_transport["display_date"] >= window_start) & (arr_transport["display_date"] <= window_end)
]

arr_wip = pd.DataFrame()
if "íƒœê´‘KR" in centers_sel:
    arr_wip = mv_view[
        (mv_view["carrier_mode"] == "WIP")
        & (mv_view["to_center"] == "íƒœê´‘KR")
        & (mv_view["resource_code"].isin(skus_sel))
        & (mv_view["event_date"].notna())
        & (mv_view["event_date"] >= window_start)
        & (mv_view["event_date"] <= window_end)
    ].copy()
    arr_wip["display_date"] = arr_wip["event_date"]

confirmed_inbound = arr_transport.copy()
if _name_map and not confirmed_inbound.empty:
    confirmed_inbound["resource_name"] = confirmed_inbound["resource_code"].map(_name_map).fillna("")

st.markdown("#### âœ… í™•ì • ì…ê³  (Upcoming Inbound)")
if confirmed_inbound.empty:
    st.caption("ì„ íƒí•œ ì¡°ê±´ì—ì„œ ì˜ˆì •ëœ ìš´ì†¡ ì…ê³ ê°€ ì—†ìŠµë‹ˆë‹¤. (ì˜¤ëŠ˜ ì´í›„ / ì„ íƒ ê¸°ê°„)")
else:
    confirmed_inbound["days_to_arrival"] = (
        confirmed_inbound["display_date"].dt.normalize() - today
    ).dt.days
    confirmed_inbound["days_to_inbound"] = (
        confirmed_inbound["pred_inbound_date"].dt.normalize() - today
    ).dt.days
    confirmed_inbound = confirmed_inbound.sort_values(
        ["display_date", "to_center", "resource_code", "qty_ea"],
        ascending=[True, True, True, False],
    )
    inbound_cols = [
        "display_date",
        "days_to_arrival",
        "to_center",
        "resource_code",
        "resource_name",
        "qty_ea",
        "carrier_mode",
        "onboard_date",
        "pred_inbound_date",
        "days_to_inbound",
        "lot",
    ]
    inbound_cols = [c for c in inbound_cols if c in confirmed_inbound.columns]
    st.dataframe(
        confirmed_inbound[inbound_cols].head(1000),
        use_container_width=True,
        height=300,
    )
    st.caption("â€» pred_inbound_date: ì˜ˆìƒ ì…ê³ ì¼ (ë„ì°©ì¼ + ë¦¬ë“œíƒ€ì„), days_to_inbound: ì˜ˆìƒ ì…ê³ ê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜")

if not arr_wip.empty:
    if _name_map:
        arr_wip["resource_name"] = arr_wip["resource_code"].map(_name_map).fillna("")
    st.markdown("#### ğŸ›  ìƒì‚°ì¤‘ (WIP) ì§„í–‰ í˜„í™©")
    arr_wip = arr_wip.sort_values(
        ["display_date", "resource_code", "qty_ea"], ascending=[True, True, False]
    )
    arr_wip["days_to_completion"] = (
        arr_wip["display_date"].dt.normalize() - today
    ).dt.days
    wip_cols = [
        "display_date",
        "days_to_completion",
        "resource_code",
        "resource_name",
        "qty_ea",
        "pred_inbound_date",
        "lot",
    ]
    wip_cols = [c for c in wip_cols if c in arr_wip.columns]
    st.dataframe(arr_wip[wip_cols].head(1000), use_container_width=True, height=260)
else:
    st.caption("ìƒì‚°ì¤‘(WIP) ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

# -------------------- ì„ íƒ ì„¼í„° í˜„ì¬ ì¬ê³  (ì „ì²´ SKU) --------------------
st.subheader(f"ì„ íƒ ì„¼í„° í˜„ì¬ ì¬ê³  (ìŠ¤ëƒ…ìƒ· {_latest_dt_str} / ì „ì²´ SKU)")

cur = snap_long[(snap_long["date"] == _latest_dt) & (snap_long["center"].isin(centers_sel))].copy()
pivot = (
    cur.groupby(["resource_code", "center"], as_index=False)["stock_qty"].sum()
    .pivot(index="resource_code", columns="center", values="stock_qty")
    .fillna(0)
    .astype(int)
)
pivot["ì´í•©"] = pivot.sum(axis=1)

col1, col2 = st.columns([2, 1])
with col1:
    q = st.text_input(
        "SKU í•„í„° â€” í’ˆëª©ë²ˆí˜¸ ê²€ìƒ‰ ì‹œ í•´ë‹¹ SKUì˜ ì„¼í„°ë³„ ì œì¡°ë²ˆí˜¸(LOT) í™•ì¸",
        "",
        key="sku_filter_text_modular",
    )
with col2:
    sort_by = st.selectbox("ì •ë ¬ ê¸°ì¤€", ["ì´í•©"] + list(pivot.columns.drop("ì´í•©")), index=0)

col1, col2 = st.columns(2)
with col1:
    hide_zero = st.checkbox("ì´í•©=0 ìˆ¨ê¸°ê¸°", value=True)
with col2:
    show_cost = st.checkbox("ì¬ê³ ìì‚°(ì œì¡°ì›ê°€) í‘œì‹œ", value=False)

view = pivot.copy()
if q.strip():
    view = view[view.index.str.contains(q.strip(), case=False, regex=False)]
if hide_zero:
    view = view[view["ì´í•©"] > 0]
view = view.sort_values(by=sort_by, ascending=False)

base_df = view.reset_index().rename(columns={"resource_code": "SKU"})
if _name_map:
    base_df.insert(1, "í’ˆëª…", base_df["SKU"].map(_name_map).fillna(""))

if show_cost:
    snap_raw_df = load_snapshot_raw()
    cost_pivot = pivot_inventory_cost_from_raw(snap_raw_df, _latest_dt, centers_sel)
    if cost_pivot.empty:
        st.warning(
            "ì¬ê³ ìì‚° ê³„ì‚°ì„ ìœ„í•œ 'snapshot_raw' ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì–´ ìˆ˜ëŸ‰ë§Œ í‘œì‹œí•©ë‹ˆë‹¤. (ì—‘ì…€ì— 'snapshot_raw' ì‹œíŠ¸ê°€ ìˆìœ¼ë©´ ìë™ ì‚¬ìš©ë©ë‹ˆë‹¤)"
        )
        show_df = base_df
    else:
        merged = base_df.merge(cost_pivot.rename(columns={"resource_code": "SKU"}), on="SKU", how="left")
        cost_cols2 = [c for c in merged.columns if c.endswith("_ì¬ê³ ìì‚°")] + (
            ["ì´ ì¬ê³ ìì‚°"] if "ì´ ì¬ê³ ìì‚°" in merged.columns else []
        )
        if cost_cols2:
            merged[cost_cols2] = merged[cost_cols2].fillna(0).astype(int)
            for col in cost_cols2:
                merged[col] = merged[col].apply(lambda x: f"{x:,}ì›")
        qty_center_cols = [c for c in merged.columns if c not in ["SKU", "í’ˆëª…", "ì´í•©"] + cost_cols2]
        ordered = ["SKU"] + (["í’ˆëª…"] if "í’ˆëª…" in merged.columns else []) + qty_center_cols + (
            ["ì´í•©"] if "ì´í•©" in merged.columns else []
        ) + cost_cols2
        show_df = merged[ordered]
else:
    show_df = base_df

qty_cols = [c for c in show_df.columns if c not in ["SKU"] and not c.endswith("_ì¬ê³ ìì‚°") and c != "ì´ ì¬ê³ ìì‚°"]
for col in qty_cols:
    if col in show_df.columns:
        show_df[col] = show_df[col].apply(lambda x: f"{x:,}" if pd.notna(x) and isinstance(x, (int, float)) else x)

st.dataframe(show_df, use_container_width=True, height=380)

csv_bytes = show_df.to_csv(index=False).encode("utf-8-sig")
st.download_button(
    "í˜„ì¬ í‘œ CSV ë‹¤ìš´ë¡œë“œ",
    data=csv_bytes,
    file_name=f"centers_{'-'.join(centers_sel)}_snapshot_{_latest_dt_str}.csv",
    mime="text/csv",
)

st.caption("â€» ì´ í‘œëŠ” **ì„ íƒëœ ì„¼í„° ì „ì²´ SKU**ì˜ ìµœì‹  ìŠ¤ëƒ…ìƒ· ì¬ê³ ì…ë‹ˆë‹¤. ìƒë‹¨ 'SKU ì„ íƒ'ê³¼ ë¬´ê´€í•˜ê²Œ ëª¨ë“  SKUê°€ í¬í•¨ë©ë‹ˆë‹¤.")

filtered_df = show_df if "SKU" in show_df.columns else view.reset_index().rename(columns={"resource_code": "SKU"})
visible_skus = filtered_df["SKU"].dropna().astype(str).unique().tolist()

if len(visible_skus) == 1:
    lot_sku = visible_skus[0]
    snap_raw_df = load_snapshot_raw()
    if snap_raw_df is None or snap_raw_df.empty:
        latest_dt_str = pd.to_datetime(snap_long["date"]).max().strftime("%Y-%m-%d")
        st.markdown(f"### ë¡œíŠ¸ ìƒì„¸ (ìŠ¤ëƒ…ìƒ· {latest_dt_str} / **{', '.join(centers_sel)}** / **{lot_sku}**)")
        st.caption("í•´ë‹¹ ì¡°ê±´ì˜ ë¡œíŠ¸ ìƒì„¸ê°€ ì—†ìŠµë‹ˆë‹¤. (snapshot_raw ì—†ìŒ)")
    else:
        sr = snap_raw_df.copy()
        cols_map = {c.strip().lower(): c for c in sr.columns}
        col_date = cols_map.get("snapshot_date") or cols_map.get("date")
        col_sku = cols_map.get("resource_code") or cols_map.get("sku") or cols_map.get("ìƒí’ˆì½”ë“œ")
        col_lot = cols_map.get("lot")
        used_centers = [ct for ct in centers_sel if CENTER_COL.get(ct) in sr.columns]
        if not all([col_date, col_sku, col_lot]) or not used_centers:
            st.caption("í•´ë‹¹ ì¡°ê±´ì˜ ë¡œíŠ¸ ìƒì„¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            sr[col_date] = pd.to_datetime(sr[col_date], errors="coerce")
            sub = sr[(sr[col_date].dt.normalize() == _latest_dt.normalize()) & (sr[col_sku].astype(str) == str(lot_sku))].copy()
            if sub.empty:
                st.caption("í•´ë‹¹ ì¡°ê±´ì˜ ë¡œíŠ¸ ìƒì„¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for ct in used_centers:
                    c = CENTER_COL[ct]
                    sub[c] = pd.to_numeric(sub[c], errors="coerce").fillna(0).clip(lower=0)
                out = pd.DataFrame({"lot": sub[col_lot].astype(str).fillna("(no lot)")})
                for ct in used_centers:
                    out[ct] = sub.groupby(col_lot)[CENTER_COL[ct]].transform("sum")
                out = out.drop_duplicates()
                out["í•©ê³„"] = out[used_centers].sum(axis=1)
                out = out[out["í•©ê³„"] > 0]
                latest_dt_str = pd.to_datetime(snap_long["date"]).max().strftime("%Y-%m-%d")
                st.markdown(f"### ë¡œíŠ¸ ìƒì„¸ (ìŠ¤ëƒ…ìƒ· {latest_dt_str} / **{', '.join(centers_sel)}** / **{lot_sku}**)")
                if out.empty:
                    st.caption("í•´ë‹¹ ì¡°ê±´ì˜ ë¡œíŠ¸ ìƒì„¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    st.dataframe(
                        out[["lot"] + used_centers + ["í•©ê³„"]].sort_values("í•©ê³„", ascending=False).reset_index(drop=True),
                        use_container_width=True,
                        height=320,
                    )
