"""íŒë§¤ ë°ì´í„° ê³„ì‚° ëª¨ë“ˆ.

ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ íŒë§¤ëŸ‰ ê³„ì‚°, ì˜ˆì¸¡ ìƒì„± ë“±ì˜ ë¡œì§ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

from __future__ import annotations

from typing import Dict, Iterable, List, Optional, Sequence

import numpy as np
import pandas as pd

from center_alias import normalize_center_value
from scm_dashboard_v9.domain.filters import filter_by_centers, safe_to_datetime

from .data_utils import coerce_cols, empty_sales_frame


def sales_from_snapshot(
    snap_long: pd.DataFrame,
    centers: List[str],
    skus: List[str],
    start: pd.Timestamp,
    end: pd.Timestamp,
) -> pd.DataFrame:
    """
    ìŠ¤ëƒ…ìƒ·ì˜ ì¼ê°„ ì°¨ë¶„ìœ¼ë¡œ 'íŒë§¤(ì‹¤ì¸¡)'ë§Œ ê³„ì‚°.
    - ì¦ê°€ë¶„(+)ì€ ì…ê³ ë¡œ ë³´ê³  íŒë§¤ì—ì„œ ì œì™¸
    - ê°ì†Œë¶„(-)ë§Œ íŒë§¤ë¡œ ë³¸ë‹¤
    ë°˜í™˜: index=date, columns=sku, ê°’=EA/Day
    """
    c = coerce_cols(snap_long)
    s = snap_long.rename(
        columns={
            c["date"]: "date",
            c["center"]: "center",
            c["sku"]: "resource_code",
            c["qty"]: "stock_qty",
        }
    )[["date", "center", "resource_code", "stock_qty"]].copy()

    s["date"] = safe_to_datetime(s["date"])
    s = s[
        s["center"].astype(str).isin(centers)
        & s["resource_code"].astype(str).isin(skus)
    ]
    if s.empty:
        idx = pd.date_range(start, end, freq="D")
        return pd.DataFrame(0, index=idx, columns=skus)

    pv = (
        s.groupby(["date", "resource_code"])["stock_qty"]
        .sum()
        .unstack("resource_code")
        .reindex(columns=skus, fill_value=0)
        .sort_index()
    )
    pv = pv.asfreq("D").ffill()  # D ê°„ê²© ë³´ì •
    d = pv.diff().fillna(0)
    sales = (-d).clip(lower=0)  # ê°ì†Œë¶„ë§Œ íŒë§¤
    sales = sales.loc[(sales.index >= start) & (sales.index <= end)]
    return sales


def sales_forecast_ma(
    sales_daily: pd.DataFrame,
    *,
    sku: str,
    start: pd.Timestamp,
    end: pd.Timestamp,
    lookback_days: int = 28,
    promo_multiplier: float = 1.0,
    value_column: str = "qty_sold",
) -> pd.DataFrame:
    """Return a constant daily forecast using a guarded moving-average base.

    ``sales_daily`` is expected to contain at least ``date``, ``resource_code``
    and the ``value_column`` (defaults to ``qty_sold``).  The function mirrors
    the defensive logic described in the user guidance: the centre names must
    already be normalised and the forecast should survive even when only a few
    historical points are available.
    """

    if sales_daily is None or sales_daily.empty:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    start_norm = pd.to_datetime(start).normalize()
    end_norm = pd.to_datetime(end).normalize()
    if pd.isna(start_norm) or pd.isna(end_norm) or end_norm < start_norm:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    sku_str = str(sku)
    df = sales_daily.copy()
    df["resource_code"] = df.get("resource_code", "").astype(str)
    df = df[df["resource_code"] == sku_str]
    if df.empty:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    df["date"] = pd.to_datetime(df.get("date"), errors="coerce").dt.normalize()
    df = df.dropna(subset=["date"])
    if df.empty:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    values = pd.to_numeric(df.get(value_column), errors="coerce").fillna(0.0)
    df[value_column] = values

    last_hist_day = start_norm - pd.Timedelta(days=1)
    history = df[df["date"] <= last_hist_day]
    if history.empty:
        history = df

    lookback = max(1, int(lookback_days))
    history = history.sort_values("date").tail(lookback)
    if history.empty:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    series = history.set_index("date")[value_column].asfreq("D").fillna(0.0)
    if series.empty:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    ma7 = series.rolling(7, min_periods=1).mean()
    if not ma7.empty:
        base = float(ma7.iloc[-1])
    else:
        base = float(series.mean()) if not series.empty else 0.0

    if not np.isfinite(base):
        base = 0.0

    multiplier = float(promo_multiplier) if np.isfinite(promo_multiplier) else 1.0
    base = max(0.0, base * multiplier)
    has_positive_history = bool((series > 0).any())
    qty = int(round(base))
    if qty <= 0 and has_positive_history:
        qty = 1
    elif qty < 0:
        qty = 0

    index = pd.date_range(start_norm, end_norm, freq="D")
    if index.empty:
        return pd.DataFrame(columns=["date", "resource_code", "qty_pred"])

    return pd.DataFrame(
        {
            "date": index,
            "resource_code": sku_str,
            "qty_pred": qty,
        }
    )


def sales_from_snapshot_raw(
    snap_raw: Optional[pd.DataFrame],
    centers: Sequence[str],
    skus: Sequence[str],
    start: pd.Timestamp,
    end: pd.Timestamp,
    *,
    debug: Optional[dict[str, object]] = None,
) -> pd.DataFrame:
    """ì›ì‹œ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¡œë¶€í„° ë§¤ì¶œ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ê³  ë³€í™˜í•©ë‹ˆë‹¤.

    ì´ í•¨ìˆ˜ëŠ” ë‹¤êµ­ì–´ ì»¬ëŸ¼ëª…ì„ ì§€ì›í•˜ëŠ” ê°•ê±´í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ:
    1. ì»¬ëŸ¼ëª… ì •ê·œí™” (í•œê¸€/ì˜ë¬¸ ë‹¤êµ­ì–´ ì§€ì›)
    2. ì„¼í„°ëª… ì •ê·œí™” (normalize_center_value ì ìš©)
    3. ì„¼í„° ë° SKU í•„í„°ë§
    4. ê¸°ê°„ í•„í„°ë§ ë° ìœ íš¨ì„± ê²€ì¦
    5. ì¼ìë³„ ë§¤ì¶œ ì§‘ê³„ (ì¤‘ë³µ ì œê±°)

    Args:
        snap_raw: ì›ì‹œ ìŠ¤ëƒ…ìƒ· DataFrame (ë‹¤ì–‘í•œ ì»¬ëŸ¼ëª… í˜•ì‹ ì§€ì›)
            - í•„ìˆ˜ ì»¬ëŸ¼: date/snapshot_date/ìŠ¤ëƒ…ìƒ·ì¼ì ì¤‘ í•˜ë‚˜
            - í•„ìˆ˜ ì»¬ëŸ¼: fba_output_stock/ì¶œê³ ìˆ˜ëŸ‰/fbaì¶œê³  ì¤‘ í•˜ë‚˜
            - ì„ íƒ ì»¬ëŸ¼: center/ì„¼í„°/warehouse, resource_code/sku/ìƒí’ˆì½”ë“œ
        centers: ëŒ€ìƒ ì„¼í„° ë¦¬ìŠ¤íŠ¸ (ì •ê·œí™” ì „ ê°’)
        skus: ëŒ€ìƒ SKU ë¦¬ìŠ¤íŠ¸
        start: ì¡°íšŒ ì‹œì‘ ë‚ ì§œ
        end: ì¡°íšŒ ì¢…ë£Œ ë‚ ì§œ
        debug: ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘ ë”•ì…”ë„ˆë¦¬ (ì„ íƒ)
            - 'rows_before_center_filter': ì„¼í„° í•„í„° ì „ í–‰ ìˆ˜
            - 'rows_after_center_filter': ì„¼í„° í•„í„° í›„ í–‰ ìˆ˜
            - 'snapshot_centers': ìŠ¤ëƒ…ìƒ·ì— í¬í•¨ëœ ì„¼í„° ë¦¬ìŠ¤íŠ¸
            - 'warning': ì˜¤ë¥˜ ë©”ì‹œì§€ (ìˆì„ ê²½ìš°)

    Returns:
        ì¼ìë³„ SKU ë§¤ì¶œ DataFrame
        - ì»¬ëŸ¼: date, resource_code, sales_ea
        - sales_ea: 0 ì´ìƒ ì •ìˆ˜ (ìŒìˆ˜ ì œê±°ë¨)
        - ë¹ˆ ê²°ê³¼ ì‹œ: ë™ì¼ ìŠ¤í‚¤ë§ˆì˜ ë¹ˆ DataFrame

    Notes:
        - ì„¼í„° ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ìš”ì²­ ì„¼í„°ë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš© (ë˜ëŠ” AMZUS)
        - í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½ ì‹œ ê²½ê³ ì™€ í•¨ê»˜ ë¹ˆ DataFrame ë°˜í™˜
        - ì¤‘ë³µ ë°ì´í„°ëŠ” í•©ê³„ë¡œ ì§‘ê³„ë¨

    Examples:
        >>> debug_info = {}
        >>> sales_df = sales_from_snapshot_raw(
        ...     snap_raw=raw_snapshot,
        ...     centers=["AMZUS", "AMZEU"],
        ...     skus=["SKU001", "SKU002"],
        ...     start=pd.Timestamp("2024-01-01"),
        ...     end=pd.Timestamp("2024-01-31"),
        ...     debug=debug_info,
        ... )
        >>> print(debug_info['snapshot_centers'])
        ['AMZEU', 'AMZUS']
    """
    if snap_raw is None or snap_raw.empty:
        if debug is not None:
            debug.clear()
            debug.update(
                {
                    "rows_before_center_filter": 0,
                    "rows_after_center_filter": 0,
                    "snapshot_centers": [],
                }
            )
        return empty_sales_frame()

    df = snap_raw.copy()

    rename_map: dict[str, str] = {}
    date_candidates = {"snapshot_date", "date", "ìŠ¤ëƒ…ìƒ·ì¼ì", "ìŠ¤ëƒ…ìƒ· ì¼ì", "ìŠ¤ëƒ…ìƒ·ì¼"}
    center_candidates = {"center", "ì„¼í„°", "ì°½ê³ ", "ì°½ê³ ëª…", "warehouse"}
    sku_candidates = {"resource_code", "sku", "ìƒí’ˆì½”ë“œ", "product_code"}
    output_candidates = {
        "fba_output_stock",
        "fbaì¶œê³ ",
        "ì¶œê³ ìˆ˜ëŸ‰",
        "ì¶œê³ ",
        "fba_output",
        "ì¶œê³  ea",
    }

    for col in df.columns:
        key = str(col).strip().lower()
        if key in date_candidates:
            rename_map[col] = "date"
        elif key in center_candidates:
            rename_map[col] = "center"
        elif key in sku_candidates:
            rename_map[col] = "resource_code"
        elif key in output_candidates or "fba_output_stock" in key:
            rename_map[col] = "fba_output_stock"

    df = df.rename(columns=rename_map)

    if "fba_output_stock" not in df.columns:
        if debug is not None:
            centers_for_debug: list[str] = []
            if "center" in df.columns:
                centers_for_debug = df["center"].dropna().astype(str).unique().tolist()
            debug.clear()
            debug.update(
                {
                    "rows_before_center_filter": len(df),
                    "rows_after_center_filter": len(df),
                    "snapshot_centers": sorted(centers_for_debug),
                    "warning": "missing fba_output_stock column",
                }
            )
        return empty_sales_frame()

    if "date" not in df.columns:
        centers_for_debug = []
        if "center" in df.columns:
            centers_for_debug = df["center"].dropna().astype(str).unique().tolist()
        if debug is not None:
            debug.clear()
            debug.update(
                {
                    "rows_before_center_filter": len(df),
                    "rows_after_center_filter": len(df),
                    "snapshot_centers": sorted(centers_for_debug),
                    "warning": "missing date column",
                }
            )
        return empty_sales_frame()

    df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.normalize()
    df = df.dropna(subset=["date"])
    df["fba_output_stock"] = pd.to_numeric(
        df.get("fba_output_stock"), errors="coerce"
    ).fillna(0)

    rows_before_center_filter = len(df)
    available_centers: list[str] = []

    if "center" in df.columns:
        df["center"] = df["center"].apply(normalize_center_value)
        df = df[df["center"].notna()]
        available_centers = (
            df["center"].dropna().astype(str).unique().tolist() if not df.empty else []
        )
    else:
        # If center is absent in snapshot_raw, infer a single Amazon centre to keep
        # the downstream filters working. Use the first requested centre, default AMZUS.
        inferred = None
        for ct in centers:
            norm = normalize_center_value(ct)
            if norm:
                inferred = norm
                break
        if inferred is None:
            inferred = "AMZUS"
        df["center"] = inferred
        available_centers = [inferred]

    if "center" in df.columns and centers:
        centers_norm = {
            normalized
            for c in centers
            for normalized in [normalize_center_value(c)]
            if normalized is not None
        }
        if centers_norm:
            df = df[df["center"].isin(centers_norm)]

    rows_after_center_filter = len(df)

    if debug is not None:
        debug.clear()
        debug.update(
            {
                "rows_before_center_filter": rows_before_center_filter,
                "rows_after_center_filter": rows_after_center_filter,
                "snapshot_centers": sorted(available_centers),
            }
        )

    if "resource_code" not in df.columns:
        return empty_sales_frame()

    if skus:
        sku_set = {str(s) for s in skus if str(s).strip()}
        if sku_set:
            df = df[df["resource_code"].astype(str).isin(sku_set)]

    if df.empty:
        return empty_sales_frame()

    start_norm = pd.to_datetime(start).normalize()
    end_norm = pd.to_datetime(end).normalize()

    df = df[(df["date"] >= start_norm) & (df["date"] <= end_norm)]
    if df.empty:
        return empty_sales_frame()

    grouped = (
        df.groupby(["date", "resource_code"], as_index=False)["fba_output_stock"]
        .sum()
        .rename(columns={"fba_output_stock": "sales_ea"})
    )

    grouped["sales_ea"] = (
        pd.to_numeric(grouped["sales_ea"], errors="coerce")
        .fillna(0)
        .clip(lower=0)
        .round()
        .astype(int)
    )
    return grouped


def sales_forecast_from_inventory_projection(
    inv_actual: pd.DataFrame,
    inv_forecast: pd.DataFrame,
    *,
    centers: Sequence[str],
    skus: Sequence[str],
    start: pd.Timestamp,
    end: pd.Timestamp,
    today: pd.Timestamp,
) -> pd.DataFrame:
    """Derive future sales from the projected inventory trajectory.

    ``apply_consumption_with_events`` already produces the most accurate stock
    projection for Amazon centres by blending actual inventory, inbound moves
    and the calibrated consumption trend.  Sales should therefore mirror the
    day-on-day decrease of that stock projection so that both visuals stay in
    sync even when promotions or inbound events shift the depletion curve.
    """

    today_norm = pd.to_datetime(today).normalize()

    frames: list[pd.DataFrame] = []
    for label, frame in (("actual", inv_actual), ("forecast", inv_forecast)):
        if frame is None or frame.empty:
            continue
        if not {"date", "center", "resource_code", "stock_qty"}.issubset(frame.columns):
            continue
        chunk = frame.copy()
        chunk["date"] = pd.to_datetime(
            chunk.get("date"), errors="coerce"
        ).dt.normalize()
        chunk = chunk.dropna(subset=["date"])
        if label == "actual":
            chunk = chunk[chunk["date"] <= today_norm]
        else:
            chunk = chunk[chunk["date"] > today_norm]
        if chunk.empty:
            continue
        chunk["center"] = chunk.get("center", "").apply(normalize_center_value)
        chunk = chunk[chunk["center"].notna()]
        chunk["resource_code"] = chunk.get("resource_code", "").astype(str).str.strip()
        chunk["stock_qty"] = pd.to_numeric(
            chunk.get("stock_qty"), errors="coerce"
        ).fillna(0.0)
        chunk["__source"] = label
        frames.append(chunk)

    if not frames:
        return pd.DataFrame(columns=["date", "resource_code", "sales_ea"])

    combined = pd.concat(frames, ignore_index=True)

    if "__source" in combined.columns:
        combined["__priority"] = (
            combined["__source"].map({"actual": 0, "forecast": 1}).fillna(1)
        )
        combined = (
            combined.sort_values(["date", "resource_code", "center", "__priority"])
            .drop_duplicates(subset=["date", "resource_code", "center"], keep="first")
            .drop(columns=["__source", "__priority"], errors="ignore")
        )

    centers_norm = [normalize_center_value(c) for c in centers]
    centers_norm = [c for c in centers_norm if c]
    skus_norm = [str(sku).strip() for sku in skus if str(sku).strip()]

    if centers_norm:
        combined = combined[combined["center"].isin(set(centers_norm))]
    if skus_norm:
        combined = combined[combined["resource_code"].isin(set(skus_norm))]

    if combined.empty:
        return pd.DataFrame(columns=["date", "resource_code", "sales_ea"])

    start_norm = pd.to_datetime(start).normalize()
    end_norm = pd.to_datetime(end).normalize()
    combined = combined[
        (combined["date"] >= start_norm) & (combined["date"] <= end_norm)
    ]
    if combined.empty:
        return pd.DataFrame(columns=["date", "resource_code", "sales_ea"])

    pivot = (
        combined.groupby(["date", "resource_code"])["stock_qty"]
        .sum()
        .unstack("resource_code")
    )
    if pivot.empty:
        return pd.DataFrame(columns=["date", "resource_code", "sales_ea"])

    pivot = pivot.reindex(columns=skus_norm, fill_value=0.0)
    full_index = pd.date_range(start_norm, end_norm, freq="D")
    pivot = pivot.reindex(full_index).sort_index()
    pivot = pivot.ffill().fillna(0.0)

    diff = pivot.diff()
    sales = (-diff).clip(lower=0.0)

    # ì¬ê³ ê°€ ì¦ê°€í•œ ë‚ (ì…ê³ ê°€ ìˆëŠ” ë‚ )ì—ë„ ì‹¤ì œë¡œëŠ” íŒë§¤ê°€ ë°œìƒí•©ë‹ˆë‹¤.
    # í•˜ì§€ë§Œ ì¬ê³  ë³€í™”(diff)ë¡œëŠ” ì •í™•íˆ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤:
    #   ì˜ˆ: ì¬ê³  100 â†’ ì…ê³  50, íŒë§¤ 30 â†’ ì¬ê³  120
    #   diff = +20 â†’ sales = 0 (í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” 30 íŒë§¤)
    # í•´ê²°: ì…ê³  ë‚ ì§œë¥¼ ì œì™¸í•œ í‰ê·  ì¼ íŒë§¤ëŸ‰ì„ ì…ê³  ë‚ ì§œì— ì ìš©
    inbound_mask = diff > 0

    # ì…ê³  ë‚ ì§œë¥¼ ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚° (ì…ê³  íšŸìˆ˜ì— ë¹„ë¡€í•˜ì§€ ì•Šë„ë¡)
    sales_no_inbound = sales.copy()
    for sku in sales.columns:
        if sku in inbound_mask.columns and inbound_mask[sku].any():
            sales_no_inbound.loc[inbound_mask[sku], sku] = np.nan

    avg_sales = sales_no_inbound.mean(skipna=True)
    avg_sales = avg_sales.where(np.isfinite(avg_sales), 0.0)

    for sku in sales.columns:
        if sku in inbound_mask.columns and inbound_mask[sku].any():
            sales.loc[inbound_mask[sku], sku] = avg_sales[sku]

    # ì¬ê³ ê°€ 0ì¸ ë‚ ì§œì—ë§Œ íŒë§¤ë¥¼ 0ìœ¼ë¡œ ì„¤ì •.
    # ì´ì „ ë¡œì§ì€ ì²« ë²ˆì§¸ 0 ì´í›„ ëª¨ë“  íŒë§¤ë¥¼ ì°¨ë‹¨í–ˆì§€ë§Œ,
    # ì¬ê³ ê°€ ë‹¤ì‹œ ì–‘ìˆ˜ê°€ ë˜ë©´ íŒë§¤ë„ ì¬ê°œë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    for sku in sales.columns:
        stock_series = pivot[sku]
        # ë¯¸ë˜ ê¸°ê°„ì—ì„œë§Œ ì²´í¬
        future_stock = stock_series.loc[stock_series.index > today_norm]
        zero_mask = future_stock <= 0

        if zero_mask.any():
            zero_dates = future_stock.index[zero_mask]
            # ì¬ê³ ê°€ 0ì¸ ë‚ ì§œì—ë§Œ íŒë§¤ë¥¼ 0ìœ¼ë¡œ ì„¤ì •
            sales.loc[zero_dates, sku] = 0.0

    future = sales.loc[sales.index > today_norm]
    if future.empty:
        return pd.DataFrame(columns=["date", "resource_code", "sales_ea"])

    tidy = (
        future.round(0)
        .astype(int)
        .stack()
        .reset_index()
        .rename(columns={"level_0": "date", "level_1": "resource_code", 0: "sales_ea"})
    )
    tidy["date"] = pd.to_datetime(tidy["date"], errors="coerce").dt.normalize()
    tidy = tidy.dropna(subset=["date"])
    tidy["sales_ea"] = tidy["sales_ea"].clip(lower=0)
    return tidy.sort_values(["resource_code", "date"]).reset_index(drop=True)


def sales_forecast_from_actual_sales_with_stock_limit(
    sales_actual: pd.DataFrame,
    inv_forecast: pd.DataFrame,
    *,
    skus: Sequence[str],
    start: pd.Timestamp,
    end: pd.Timestamp,
    today: pd.Timestamp,
    lookback_days: int = 28,
) -> pd.DataFrame:
    """ê³¼ê±° ì‹¤ì œ íŒë§¤ëŸ‰(sales_qty)ìœ¼ë¡œ í‰ê· ì„ ê³„ì‚°í•˜ê³  ë¯¸ë˜ì— ì ìš©.
    ì¬ê³ ê°€ 0ì¸ ë‚ ì§œëŠ” íŒë§¤ë„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¬ê³ -íŒë§¤ ì‹œê°ì  ì¼ì¹˜.

    Args:
        sales_actual: ê³¼ê±° ì‹¤ì œ íŒë§¤ ë°ì´í„° (columns: date, resource_code, sales_qty)
        inv_forecast: ë¯¸ë˜ ì¬ê³  ì˜ˆì¸¡ (columns: date, resource_code, stock_qty)
        skus: SKU ëª©ë¡
        start: ì˜ˆì¸¡ ì‹œì‘ì¼
        end: ì˜ˆì¸¡ ì¢…ë£Œì¼
        today: ì˜¤ëŠ˜ ë‚ ì§œ (ê³¼ê±°/ë¯¸ë˜ êµ¬ë¶„)
        lookback_days: í‰ê·  ê³„ì‚° ì‹œ ì¡°íšŒí•  ê³¼ê±° ì¼ìˆ˜

    Returns:
        DataFrame: ë¯¸ë˜ íŒë§¤ ì˜ˆì¸¡ (columns: date, resource_code, sales_qty)
    """
    # DEBUG: Streamlit ëŸ°íƒ€ì„ ì²´í¬
    debug_enabled = False
    try:
        import streamlit as st
        from streamlit.runtime.scriptrunner import get_script_run_ctx

        if get_script_run_ctx() is not None:
            debug_enabled = True
            st.write(
                "\n**ğŸ” [sales_forecast_from_actual_sales_with_stock_limit] ê³¼ê±° íŒë§¤ ê¸°ë°˜ ì˜ˆì¸¡:**"
            )
    except (ImportError, RuntimeError):
        pass

    today_norm = pd.to_datetime(today).normalize()
    start_norm = pd.to_datetime(start).normalize()
    end_norm = pd.to_datetime(end).normalize()

    # 1. ê³¼ê±° sales_qtyë¡œ í‰ê·  ê³„ì‚° (ì •í™•í•œ ë°ì´í„° ì‚¬ìš©)
    if sales_actual is None or sales_actual.empty:
        avg_sales_by_sku = {sku: 0.0 for sku in skus}
        if debug_enabled:
            st.warning("  âš ï¸ sales_actualì´ ë¹„ì–´ìˆìŒ â†’ í‰ê·  íŒë§¤ëŸ‰ 0ìœ¼ë¡œ ì„¤ì •")
    else:
        lookback_start = today_norm - pd.Timedelta(days=lookback_days)
        recent_sales = sales_actual[
            (sales_actual["date"] >= lookback_start)
            & (sales_actual["date"] <= today_norm)
        ].copy()

        avg_sales_by_sku = {}
        for sku in skus:
            sku_sales = recent_sales[recent_sales["resource_code"] == sku]["sales_qty"]
            avg = float(sku_sales.mean()) if not sku_sales.empty else 0.0
            avg_sales_by_sku[sku] = max(0.0, avg)

        if debug_enabled:
            st.write(f"  - lookback ê¸°ê°„: {lookback_start} ~ {today_norm}")
            st.write(f"  - ê³¼ê±° íŒë§¤ ë°ì´í„°: {len(recent_sales)} í–‰")
            st.write(f"  - **í‰ê·  ì¼ íŒë§¤ëŸ‰ (SKUë³„):** {avg_sales_by_sku}")

    # 2. ë¯¸ë˜ ë‚ ì§œì— í‰ê·  ì ìš© (ë‹¨ìˆœí•˜ê³  ëª…í™•)
    future_start = today_norm + pd.Timedelta(days=1)
    if future_start > end_norm:
        return pd.DataFrame(columns=["date", "resource_code", "sales_qty"])

    future_dates = pd.date_range(future_start, end_norm, freq="D")
    forecast_rows = []
    for sku in skus:
        for date in future_dates:
            forecast_rows.append(
                {
                    "date": date,
                    "resource_code": sku,
                    "sales_qty": avg_sales_by_sku[sku],
                }
            )

    sales_forecast = pd.DataFrame(forecast_rows)

    if debug_enabled:
        st.write(f"\n  - ë¯¸ë˜ ê¸°ê°„: {future_start} ~ {end_norm}")
        st.write(f"  - ì´ˆê¸° íŒë§¤ ì˜ˆì¸¡: {len(sales_forecast)} í–‰")
        st.write(
            f"  - íŒë§¤ í•©ê³„ (SKUë³„): {sales_forecast.groupby('resource_code')['sales_qty'].sum().to_dict()}"
        )

    if sales_forecast.empty:
        return pd.DataFrame(columns=["date", "resource_code", "sales_qty"])

    # 3. ì¬ê³ ê°€ 0ì¸ ë‚ ì§œëŠ” íŒë§¤ë„ 0ìœ¼ë¡œ ì„¤ì • (ì‹œê°ì  ì¼ì¹˜)
    if inv_forecast is not None and not inv_forecast.empty:
        inv_forecast = inv_forecast.copy()
        inv_forecast["date"] = pd.to_datetime(inv_forecast["date"]).dt.normalize()

        if debug_enabled:
            st.write(f"\n  **ì¬ê³  ê¸°ë°˜ íŒë§¤ ì œì•½:**")

        for sku in skus:
            sku_inv = inv_forecast[inv_forecast["resource_code"] == sku]
            zero_dates = sku_inv[sku_inv["stock_qty"] <= 0]["date"].values

            if len(zero_dates) > 0:
                mask = (sales_forecast["resource_code"] == sku) & (
                    sales_forecast["date"].isin(zero_dates)
                )
                sales_forecast.loc[mask, "sales_qty"] = 0.0

                if debug_enabled:
                    st.write(
                        f"  - {sku}: ì¬ê³  0ì¸ ë‚ ì§œ {len(zero_dates)}ê°œ â†’ í•´ë‹¹ ë‚ ì§œ íŒë§¤ëŸ‰ 0ìœ¼ë¡œ ì„¤ì •"
                    )
            elif debug_enabled:
                st.write(f"  - {sku}: ì¬ê³  0 ì—†ìŒ â†’ í‰ê·  íŒë§¤ëŸ‰ ìœ ì§€")

    if debug_enabled:
        st.write(f"\n  **ìµœì¢… íŒë§¤ ì˜ˆì¸¡:**")
        st.write(
            f"  - íŒë§¤ í•©ê³„ (SKUë³„): {sales_forecast.groupby('resource_code')['sales_qty'].sum().to_dict()}"
        )
        st.write("  - ìƒ˜í”Œ (ë§ˆì§€ë§‰ 10í–‰):")
        st.dataframe(sales_forecast.tail(10))

    return sales_forecast


def sales_from_snapshot_decays(
    snap_like: Optional[pd.DataFrame],
    centers: Sequence[str],
    skus: Sequence[str],
    start: pd.Timestamp,
    end: pd.Timestamp,
) -> pd.DataFrame:
    if snap_like is None or snap_like.empty:
        return empty_sales_frame()

    centers_list = [str(c) for c in centers if str(c).strip()]
    skus_list = [str(s) for s in skus if str(s).strip()]
    if not centers_list or not skus_list:
        return empty_sales_frame()

    matrix = sales_from_snapshot(
        snap_like,
        centers=centers_list,
        skus=skus_list,
        start=start,
        end=end,
    )

    if matrix is None or matrix.empty:
        return empty_sales_frame()

    tidy = matrix.reset_index().melt(
        id_vars="date", var_name="resource_code", value_name="sales_ea"
    )

    tidy["date"] = pd.to_datetime(tidy.get("date"), errors="coerce").dt.normalize()
    tidy = tidy.dropna(subset=["date"])
    tidy["resource_code"] = tidy["resource_code"].astype(str)
    tidy = tidy[tidy["resource_code"].isin(skus_list)]

    start_norm = pd.to_datetime(start).normalize()
    end_norm = pd.to_datetime(end).normalize()
    tidy = tidy[(tidy["date"] >= start_norm) & (tidy["date"] <= end_norm)]

    tidy["sales_ea"] = (
        pd.to_numeric(tidy.get("sales_ea"), errors="coerce")
        .fillna(0)
        .clip(lower=0)
        .round()
        .astype(int)
    )

    tidy = tidy[tidy["sales_ea"] >= 0]
    tidy = tidy.sort_values(["date", "resource_code"]).reset_index(drop=True)
    return tidy
