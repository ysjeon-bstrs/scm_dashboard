
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import re
from datetime import datetime
from datetime import timedelta
from io import BytesIO

st.set_page_config(page_title="SCM Step Dashboard v2", layout="wide")

st.title("ğŸ“¦ ì„¼í„°Ã—SKU ì¬ê³  íë¦„ (ê³„ë‹¨ì‹) ëŒ€ì‹œë³´ë“œ â€” v2 (In-Transit + WIP)")

st.markdown("""
- **ì—‘ì…€ ì—…ë¡œë“œ**: `SCM_í†µí•©`(ì´ë™ ë¡œê·¸) + `sample_snapshot`(ì¬ê³  ìŠ¤ëƒ…ìƒ·) + *(ì„ íƒ)* `ì…ê³ ì˜ˆì •ë‚´ì—­`(ìƒì‚°/WIP)ì´ ë“¤ì–´ìˆëŠ” íŒŒì¼ì„ ì˜¬ë¦¬ì„¸ìš”.
- ê¸°ì¤€ ìˆ˜ëŸ‰: **qty_ea**
- SKU ì½”ë“œëŠ” **resource_code** ì™€ 1:1 ë§¤ì¹­
- ì¶œë°œì°½ê³  ê°ì†Œ: **onboard_date**(Hì—´ ì˜ë¯¸: ì¬ê³  ë°°ì •/ì¶œë°œì¼)  
- ë„ì°©ì°½ê³  ì¦ê°€: **inbound_date** ìš°ì„ , ì—†ìœ¼ë©´ **arrival_date(ETA)** â†’ `event_date`
- ì´ë™ì¤‘: **In-Transit(SEA/AIR)** ê°€ìƒ ë¼ì¸ (íŒŒë€ ì ì„ )
- ìƒì‚°ì¤‘: **WIP** ê°€ìƒ ë¼ì¸ (ë¹¨ê°„ ì‹¤ì„ ), ì™„ë£Œì¼ì— **íƒœê´‘KR** ì‹¤ì¬ê³ ì— í•©ì‚°
""")

# -------------------- Helpers --------------------
def _coalesce_columns(df, candidates, parse_date=False):
    all_names = []
    for item in candidates:
        if isinstance(item, (list, tuple, set)):
            all_names.extend([str(x).strip() for x in item])
        else:
            all_names.append(str(item).strip())
    cols = [c for c in df.columns if str(c).strip() in all_names]
    if not cols:
        return pd.Series(pd.NaT if parse_date else np.nan, index=df.index)
    sub = df[cols].copy()
    if parse_date:
        for c in cols:
            sub[c] = pd.to_datetime(sub[c], errors="coerce")
    out = sub.bfill(axis=1).iloc[:, 0]
    return out

@st.cache_data(ttl=300)
def load_from_excel(file):
    # Streamlit UploadedFile ì§€ì›
    data = file.read() if hasattr(file, "read") else file
    bio = BytesIO(data) if isinstance(data, (bytes, bytearray)) else file

    xl = pd.ExcelFile(bio, engine="openpyxl")
    need = {"SCM_í†µí•©": None, "sample_snapshot": None}
    for s in xl.sheet_names:
        if s in need:
            need[s] = s
    if need["SCM_í†µí•©"] is None or need["sample_snapshot"] is None:
        st.error("ì—‘ì…€ì— 'SCM_í†µí•©'ê³¼ 'sample_snapshot' ì‹œíŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    df_move = pd.read_excel(bio, sheet_name=need["SCM_í†µí•©"], engine="openpyxl")
    bio.seek(0)
    df_snap = pd.read_excel(bio, sheet_name=need["sample_snapshot"], engine="openpyxl")
    bio.seek(0)
    # WIP ì‹œíŠ¸ëŠ” ìˆì„ ìˆ˜ë„/ì—†ì„ ìˆ˜ë„
    wip_df = None
    if "ì…ê³ ì˜ˆì •ë‚´ì—­" in xl.sheet_names:
        wip_df = pd.read_excel(bio, sheet_name="ì…ê³ ì˜ˆì •ë‚´ì—­", engine="openpyxl")
    return df_move, df_snap, wip_df

def normalize_snapshot(df_snap):
    df = df_snap.copy()
    df.columns = [str(c).strip() for c in df.columns]
    rename_map = {}
    for c in df.columns:
        cs = str(c)
        if ("ìŠ¤ëƒ…ìƒ·" in cs and "ì¼ì" in cs) or cs.lower() in ["snapshot_date","date"]:
            rename_map[c] = "snapshot_date"
        elif cs.strip() in ["ì°½ê³ ëª…","center"]:
            rename_map[c] = "center"
    df = df.rename(columns=rename_map)
    if "snapshot_date" not in df.columns or "center" not in df.columns:
        st.error("sample_snapshot ì‹œíŠ¸ì— 'ìŠ¤ëƒ…ìƒ· ì¼ì'ì™€ 'ì°½ê³ ëª…'ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    id_cols = ["snapshot_date", "center"]
    sku_cols = [c for c in df.columns if c not in id_cols and "ìŠ¤ëƒ…ìƒ·" not in str(c)]
    longy = df.melt(id_vars=id_cols, value_vars=sku_cols, var_name="resource_code", value_name="stock_qty")
    longy["snapshot_date"] = pd.to_datetime(longy["snapshot_date"], errors="coerce")
    longy["stock_qty"] = pd.to_numeric(longy["stock_qty"], errors="coerce").fillna(0).astype(int)
    return longy.dropna(subset=["snapshot_date","center","resource_code"])

def normalize_moves(df):
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    resource_code = _coalesce_columns(df, [["resource_code","ìƒí’ˆì½”ë“œ","RESOURCE_CODE"]])
    qty_ea       = _coalesce_columns(df, [["qty_ea","QTY_EA","ìˆ˜ëŸ‰(EA)"]])
    carrier_mode = _coalesce_columns(df, [["carrier_mode","ìš´ì†¡ë°©ë²•","carrier mode"]])
    from_center  = _coalesce_columns(df, [["from_center","ì¶œë°œì°½ê³ "]])
    to_center    = _coalesce_columns(df, [["to_center","ë„ì°©ì°½ê³ "]])
    onboard_date = _coalesce_columns(df, [["onboard_date","ë°°ì •ì¼","ì¶œë°œì¼","H"]], parse_date=True)  # Hì—´ ì˜ë¯¸
    arrival_date = _coalesce_columns(df, [["arrival_date","ë„ì°©ì¼","eta_date","ETA"]], parse_date=True)
    inbound_date = _coalesce_columns(df, [["inbound_date","ì…ê³ ì¼"]], parse_date=True)
    real_depart  = _coalesce_columns(df, [["ì‹¤ì œ ì„ ì ì¼","real_departure","AI"]], parse_date=True)

    out = pd.DataFrame({
        "resource_code": resource_code.astype(str).str.strip(),
        "qty_ea": pd.to_numeric(qty_ea, errors="coerce").fillna(0).astype(int),
        "carrier_mode": carrier_mode.astype(str).str.strip(),
        "from_center": from_center.astype(str).str.strip(),
        "to_center": to_center.astype(str).str.strip(),
        "onboard_date": onboard_date,
        "arrival_date": arrival_date,
        "inbound_date": inbound_date,
        "real_departure": real_depart,
    })
    out["event_date"] = out["inbound_date"].where(out["inbound_date"].notna(), out["arrival_date"])
    return out


def _parse_po_date(po_str):
    """
    ì˜ˆ: 'T250812-0001' -> 2025-08-12
    ê·œì¹™: ì˜ë¬¸ 1ì + YYMMDD + '-' ...
    """
    if not isinstance(po_str, str):
        return pd.NaT
    m = re.search(r"[A-Za-z](\d{2})(\d{2})(\d{2})", po_str)
    if not m:
        return pd.NaT
    yy, mm, dd = m.groups()
    year = 2000 + int(yy)  # 20xx ê°€ì •
    try:
        return pd.Timestamp(datetime(year, int(mm), int(dd)))
    except Exception:
        return pd.NaT



def load_wip_from_incoming(df_incoming, default_center="íƒœê´‘KR"):
    """
    'ì…ê³ ì˜ˆì •ë‚´ì—­' ì‹œíŠ¸ ì •ê·œí™”:
      - wip_start = po_no(ë°œì£¼ë²ˆí˜¸)ì—ì„œ íŒŒì‹±í•œ ë‚ ì§œ
      - wip_ready = intended_push_date
      - qty_ea    = quantity
      - to_center = íƒœê´‘KR (ê³ ì •)
    """
    if df_incoming is None or df_incoming.empty:
        return pd.DataFrame()

    df = df_incoming.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]

    # ì»¬ëŸ¼ ì¶”ë¡ 
    po_col   = next((c for c in df.columns if c in ["po_no","ponumber","po"]), None)
    date_col = next((c for c in df.columns if "intended_push_date" in c or "ì…ê³ " in c), None)
    sku_col  = next((c for c in df.columns if c in ["product_code","resource_code","ìƒí’ˆì½”ë“œ"]), None)
    qty_col  = next((c for c in df.columns if c in ["quantity","qty","ìˆ˜ëŸ‰"]), None)

    if not po_col or not date_col or not sku_col or not qty_col:
        # í•„ìˆ˜ ì»¬ëŸ¼ì´ í•˜ë‚˜ë¼ë„ ì—†ìœ¼ë©´ ë¹ˆ DF ë°˜í™˜
        return pd.DataFrame()

    out = pd.DataFrame({
        "resource_code": df[sku_col].astype(str).str.strip(),
        "to_center": default_center,
        "wip_ready": pd.to_datetime(df[date_col], errors="coerce"),
        "qty_ea": pd.to_numeric(df[qty_col], errors="coerce").fillna(0).astype(int)
    })

    # ë°œì£¼ì¼ íŒŒì‹± â†’ wip_start
    out["wip_start"] = df[po_col].map(_parse_po_date)
    # ë°œì£¼ì¼ì´ ëª» ì½í˜”ìœ¼ë©´(ì˜ˆì™¸ ì¼€ì´ìŠ¤) ìµœì†Œí•œ wip_ready - 10ì¼ë¡œ ë³´ì •
    mask_na = out["wip_start"].isna() & out["wip_ready"].notna()
    out.loc[mask_na, "wip_start"] = out.loc[mask_na, "wip_ready"] - pd.to_timedelta(10, unit="D")

    # ìœ íš¨ê°’ë§Œ
    out = out.dropna(subset=["resource_code","wip_ready","wip_start"]).reset_index(drop=True)
    return out[["resource_code","to_center","wip_start","wip_ready","qty_ea"]]

def merge_wip_as_moves(moves_df, wip_df):
    if wip_df is None or wip_df.empty:
        return moves_df
    wip_moves = pd.DataFrame({
        "resource_code": wip_df["resource_code"],
        "qty_ea": wip_df["qty_ea"].astype(int),
        "carrier_mode": "WIP",
        "from_center": "WIP",
        "to_center": wip_df["to_center"],
        "onboard_date": wip_df["wip_start"],
        "arrival_date": wip_df["wip_ready"],
        "inbound_date": pd.NaT,
        "real_departure": pd.NaT,
        "event_date": wip_df["wip_ready"],
    })
    return pd.concat([moves_df, wip_moves], ignore_index=True)

def build_timeline(snap_long, moves, centers_sel, skus_sel,
                   start_dt, end_dt, horizon_days=0):
    """
    ë°˜í™˜: date, center, resource_code, stock_qty
    - ì‹¤ì œ ì„¼í„° ë¼ì¸: ìŠ¤ëƒ…ìƒ· + (ì¶œë°œ:onboard -, ë„ì°©:event +)
    - In-Transit(SEA/AIR/WIP) ê°€ìƒ ë¼ì¸: onboard +, event -
    """
    horizon_end = end_dt + pd.Timedelta(days=horizon_days)
    full_dates = pd.date_range(start_dt, horizon_end, freq="D")

    base = snap_long[
        snap_long["center"].isin(centers_sel) &
        snap_long["resource_code"].isin(skus_sel)
    ].copy().rename(columns={"snapshot_date":"date"})
    if base.empty:
        return pd.DataFrame(columns=["date","center","resource_code","stock_qty"])
    base = base[(base["date"] >= start_dt) & (base["date"] <= end_dt)]

    lines = []

    # 1) ì‹¤ì œ ì„¼í„° ë¼ì¸
    for (ct, sku), grp in base.groupby(["center","resource_code"]):
        grp = grp.sort_values("date")
        last_dt = grp["date"].max()

        if horizon_days > 0:
            proj_dates = pd.date_range(last_dt + pd.Timedelta(days=1), horizon_end, freq="D")
            proj_df = pd.DataFrame({"date": proj_dates, "center": ct,
                                    "resource_code": sku, "stock_qty": np.nan})
            ts = pd.concat([grp[["date","center","resource_code","stock_qty"]], proj_df], ignore_index=True)
        else:
            ts = grp[["date","center","resource_code","stock_qty"]].copy()

        ts = ts.sort_values("date")
        ts["stock_qty"] = ts["stock_qty"].ffill()

        mv = moves[moves["resource_code"] == sku].copy()

        eff_minus = (
            mv[(mv["from_center"].astype(str) == str(ct)) &
               (mv["onboard_date"].notna()) &
               (mv["onboard_date"] > last_dt)]
            .groupby("onboard_date", as_index=False)["qty_ea"].sum()
            .rename(columns={"onboard_date":"date","qty_ea":"delta"})
        )
        eff_minus["delta"] *= -1

        eff_plus = (
            mv[(mv["to_center"].astype(str) == str(ct)) &
               (mv["event_date"].notna()) &
               (mv["event_date"] > last_dt)]
            .groupby("event_date", as_index=False)["qty_ea"].sum()
            .rename(columns={"event_date":"date","qty_ea":"delta"})
        )

        eff_all = pd.concat([eff_minus, eff_plus], ignore_index=True).sort_values("date")
        for d, delta in zip(eff_all["date"], eff_all["delta"]):
            ts.loc[ts["date"] >= d, "stock_qty"] = ts.loc[ts["date"] >= d, "stock_qty"] + delta

        ts["stock_qty"] = ts["stock_qty"].clip(lower=0)
        lines.append(ts)

    # 2) In-Transit ê°€ìƒ ë¼ì¸ (SEA/AIR/WIP)
    def mode_tag(s):
        s = str(s)
        if "WIP" in s.upper(): return "WIP"
        if "í•´ìƒ" in s or "SEA" in s.upper(): return "SEA"
        if any(x in s for x in ["í•­ê³µ","íŠ¹ì†¡","íƒë°°"]) or "AIR" in s.upper(): return "AIR"
        return "OTHER"

    mv_sel = moves[
        moves["resource_code"].isin(skus_sel) &
        (moves["from_center"].astype(str).isin(centers_sel) | moves["to_center"].astype(str).isin(centers_sel) | (moves["carrier_mode"].astype(str).str.upper()=="WIP"))
    ].copy()
    mv_sel["mode_tag"] = mv_sel["carrier_mode"].map(mode_tag)

    for sku, gsku in mv_sel.groupby("resource_code"):
        for mode, g in gsku.groupby("mode_tag"):
            add_onboard = (
                g[g["onboard_date"].notna()]
                .groupby("onboard_date", as_index=False)["qty_ea"].sum()
                .rename(columns={"onboard_date":"date","qty_ea":"delta"})
            )
            add_event = (
                g[g["event_date"].notna()]
                .groupby("event_date", as_index=False)["qty_ea"].sum()
                .rename(columns={"event_date":"date","qty_ea":"delta"})
            )
            add_event["delta"] *= -1
            deltas = pd.concat([add_onboard, add_event], ignore_index=True)
            if deltas.empty:
                continue
            s = pd.Series(0, index=pd.to_datetime(full_dates))
            for d, v in deltas.groupby("date")["delta"].sum().items():
                d = pd.to_datetime(d)
                if d < full_dates[0]:
                    s.iloc[:] = s.iloc[:] + v
                else:
                    s.loc[s.index >= d] = s.loc[s.index >= d] + v
            vdf = pd.DataFrame({
                "date": s.index,
                "center": f"In-Transit({mode})" if mode != "WIP" else "WIP",
                "resource_code": sku,
                "stock_qty": s.values.clip(min=0)
            })
            lines.append(vdf)

    if not lines:
        return pd.DataFrame(columns=["date","center","resource_code","stock_qty"])

    out = pd.concat(lines, ignore_index=True)
    out = out[(out["date"] >= start_dt) & (out["date"] <= horizon_end)]
    return out

# -------------------- Tabs for inputs --------------------
tab1, tab2 = st.tabs(["ì—‘ì…€ ì—…ë¡œë“œ", "CSV ìˆ˜ë™ ì—…ë¡œë“œ"])

with tab1:
    xfile = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"], key="excel")
    if xfile is not None:
        df_move, df_snap, df_incoming = load_from_excel(xfile)
        moves_raw = normalize_moves(df_move)
        snap_long = normalize_snapshot(df_snap)

        # WIP ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•©
        try:
            wip_df = load_wip_from_incoming(df_incoming)
            moves = merge_wip_as_moves(moves_raw, wip_df)
            st.success(f"WIP {len(wip_df)}ê±´ ë°˜ì˜ ì™„ë£Œ" if wip_df is not None else "WIP ì—†ìŒ")
        except Exception as e:
            moves = moves_raw
            st.warning(f"WIP ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

with tab2:
    cs_snap = st.file_uploader("sample_snapshot.csv ì—…ë¡œë“œ", type=["csv"], key="snapcsv")
    cs_move = st.file_uploader("SCM_í†µí•©.csv ì—…ë¡œë“œ", type=["csv"], key="movecsv")
    if cs_snap is not None and cs_move is not None:
        snap_raw = pd.read_csv(cs_snap)
        move_raw = pd.read_csv(cs_move)
        moves = normalize_moves(move_raw)
        if "resource_code" in [c.lower() for c in snap_raw.columns]:
            sr = snap_raw.copy()
            cn = {}
            for c in sr.columns:
                cl = c.lower()
                if cl in ["date","snapshot_date","ìŠ¤ëƒ…ìƒ· ì¼ì"]:
                    cn[c] = "snapshot_date"
                elif cl in ["center","ì°½ê³ ëª…"]:
                    cn[c] = "center"
                elif cl == "resource_code":
                    cn[c] = "resource_code"
                elif cl in ["stock_qty","qty","quantity"]:
                    cn[c] = "stock_qty"
            sr = sr.rename(columns=cn)
            sr["snapshot_date"] = pd.to_datetime(sr["snapshot_date"], errors="coerce")
            sr["stock_qty"] = pd.to_numeric(sr["stock_qty"], errors="coerce").fillna(0).astype(int)
            snap_long = sr[["snapshot_date","center","resource_code","stock_qty"]].dropna()
        else:
            snap_long = normalize_snapshot(snap_raw)

if "snap_long" not in locals():
    st.info("ì—‘ì…€ ë˜ëŠ” CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ í•„í„°/ì°¨íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
    st.stop()

# -------------------- Filters --------------------
centers = sorted(snap_long["center"].dropna().astype(str).unique().tolist())
skus = sorted(snap_long["resource_code"].dropna().astype(str).unique().tolist())
min_date = snap_long["snapshot_date"].min()
max_date = snap_long["snapshot_date"].max()

st.sidebar.header("í•„í„°")
centers_sel = st.sidebar.multiselect("ì„¼í„° ì„ íƒ", centers, default=centers[:2])
skus_sel = st.sidebar.multiselect("SKU ì„ íƒ", skus, default=skus[:3])
date_range = st.sidebar.slider("ê¸°ê°„",
    min_value=min_date.to_pydatetime(),
    max_value=max_date.to_pydatetime(),
    value=(max_date.to_pydatetime() - timedelta(days=60), max_date.to_pydatetime()),
    format="YYYY-MM-DD")
horizon = st.sidebar.number_input("ë¯¸ë˜ ì „ë§ ì¼ìˆ˜", min_value=0, max_value=60, value=10)

start_dt = pd.to_datetime(date_range[0]).normalize()
end_dt = pd.to_datetime(date_range[1]).normalize()
combine_it = st.sidebar.checkbox("In-Transit í•©ì¹˜ê¸°", value=True)
show_wip   = st.sidebar.checkbox("WIP í‘œì‹œ", value=True)


# -------------------- KPIs --------------------
st.subheader("ìš”ì•½ KPI")

# ì˜¤ëŠ˜ ë‚ ì§œ(í‘œì‹œìš©)
today = pd.Timestamp.today().normalize()
today_str = today.strftime("%Y-%m-%d")

# ìµœì‹  ìŠ¤ëƒ…ìƒ· ê¸°ì¤€ í˜„ì¬ ì´ ì¬ê³ (ì„ íƒ ì„¼í„°Ã—SKU)
latest_dt = snap_long["snapshot_date"].max()
latest = snap_long[
    (snap_long["snapshot_date"] == latest_dt) &
    (snap_long["center"].isin(centers_sel)) &
    (snap_long["resource_code"].isin(skus_sel))
]
cur_stock = int(latest["stock_qty"].sum()) if not latest.empty else 0

# ì´ë™ ì¤‘ ì¬ê³ (í•´ìƒ/í•­ê³µ) - ì˜¤ëŠ˜ ê¸°ì¤€, ì„ íƒ ì¡°ê±´ í•œì •
in_transit_mask = (
    (moves["onboard_date"].notna()) &
    (moves["onboard_date"] <= today) &
    (moves["inbound_date"].isna()) &
    ((moves["arrival_date"].isna()) | (moves["arrival_date"] > today)) &
    (moves["to_center"].astype(str).isin(centers_sel)) &
    (moves["resource_code"].astype(str).isin(skus_sel))
)
in_transit = moves[in_transit_mask]
sea_qty = int(in_transit[moves["carrier_mode"].astype(str).str.contains("í•´ìƒ", na=False)]["qty_ea"].sum())
air_qty = int(in_transit[moves["carrier_mode"].astype(str).str.contains("í•­ê³µ|íŠ¹ì†¡|íƒë°°|AIR", na=False)]["qty_ea"].sum())

# WIP(ë¯¸ì™„ë£Œ ìƒì‚°) - ì˜¤ëŠ˜ ê¸°ì¤€ ì”ëŸ‰ (ê¸°ê°„ ìŠ¬ë¼ì´ë”ì™€ ë¬´ê´€í•˜ê²Œ ê³„ì‚°)
wip_moves = moves[moves["carrier_mode"].astype(str).str.upper() == "WIP"].copy()
if not wip_moves.empty:
    on = (wip_moves.dropna(subset=["onboard_date"])
                     .groupby("onboard_date", as_index=True)["qty_ea"].sum())
    ev = (wip_moves.dropna(subset=["event_date"])
                    .groupby("event_date", as_index=True)["qty_ea"].sum() * -1)
    wip_flow = pd.concat([on, ev]).groupby(level=0).sum().sort_index()
    # ì˜¤ëŠ˜ê¹Œì§€ ëˆ„ì 
    wip_cum = wip_flow[wip_flow.index <= today].cumsum()
    wip_today = int(wip_cum.iloc[-1]) if not wip_cum.empty else 0
else:
    wip_today = 0

# íƒ€ì„ë¼ì¸(ì‹¤ì œ ì„¼í„°ë§Œ)ì—ì„œ horizonì¼ ë’¤ ì˜ˆìƒ ì¬ê³ (ì„ íƒ ì„¼í„°Ã—SKU í•©)
timeline = build_timeline(snap_long, moves, centers_sel, skus_sel,
                          start_dt, end_dt, horizon_days=horizon)
if not timeline.empty:
    future_last = timeline["date"].max()
    real_mask = (~timeline["center"].isin(["WIP"])) & (~timeline["center"].str.startswith("In-Transit", na=False))
    future_stock = int(timeline[(timeline["date"] == future_last) & real_mask]["stock_qty"].sum())
else:
    future_last = latest_dt
    future_stock = cur_stock

# KPI ì¶œë ¥ (ë¼ë²¨ì— ë‚ ì§œ í¬í•¨)
k1, k2, k3, k4 = st.columns(4)
k1.metric(f"í˜„ì¬ ì´ ì¬ê³ ({today_str})", f"{cur_stock:,}")
k2.metric("ë°”ë‹¤ ìœ„(í•´ìƒ) ì´ë™", f"{sea_qty:,}")
k3.metric("í˜„ì¬ WIP(ë¯¸ì™„ë£Œ ìƒì‚°)", f"{wip_today:,}")
k4.metric(f"{horizon}ì¼ ë’¤ ì˜ˆìƒ ì¬ê³ (ì„ íƒ í•©)", f"{future_stock:,}")

st.divider()


# -------------------- Step Chart (Plotly) --------------------
st.subheader("ê³„ë‹¨ì‹ ì¬ê³  íë¦„")
if timeline.empty:
    st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    vis_df = timeline[(timeline["date"] >= start_dt) & (timeline["date"] <= (end_dt + pd.Timedelta(days=horizon)))].copy()
    vis_df["label"] = vis_df["resource_code"] + " @ " + vis_df["center"]
    fig = px.line(
        vis_df,
        x="date",
        y="stock_qty",
        color="label",
        line_shape="hv",
        title="ì„ íƒí•œ SKU Ã— ì„¼í„°(ë° In-Transit/WIP) ê³„ë‹¨ì‹ ì¬ê³  íë¦„",
        render_mode="svg"
    )
    fig.update_traces(
        mode="lines",
        hovertemplate="ë‚ ì§œ: %{x|%Y-%m-%d}<br>ì¬ê³ : %{y:,} EA<br>%{fullData.name}<extra></extra>"
    )
    fig.update_layout(
        hovermode="x unified",
        xaxis_title="Date",
        yaxis_title="Inventory (qty_ea)",
        legend_title_text="SKU @ Center / In-Transit / WIP",
        margin=dict(l=20, r=20, t=60, b=20)
    )
    # ìŠ¤íƒ€ì¼: In-Transit â†’ íŒŒë€ ì ì„ , WIP â†’ ë¹¨ê°„ ì‹¤ì„ 
    for tr in fig.data:
        nm = (tr.name or "")
        if "In-Transit" in nm:
            tr.update(line=dict(dash="dot", width=2, color="#1f77b4"))
        elif "WIP" in nm:
            tr.update(line=dict(dash="solid", width=2, color="#d62728"))
    st.plotly_chart(fig, use_container_width=True, config={"displaylogo": False})
    # In-Transit ë¼ë²¨ í†µí•© (SEA/AIR/OTHER -> In-Transit)
    vis_df["center"] = vis_df["center"].str.replace(r"^In-Transit.*", "In-Transit", regex=True)
    vis_df["label"]  = vis_df["resource_code"] + " @ " + vis_df["center"]  # ë¼ë²¨ ì¬ìƒì„±
    vis_df = timeline[(timeline["date"] >= start_dt) &
                  (timeline["date"] <= (end_dt + pd.Timedelta(days=horizon)))].copy()

    if combine_it:
    vis_df["center"] = vis_df["center"].str.replace(r"^In-Transit.*", "In-Transit", regex=True)

    if not show_wip:
    vis_df = vis_df[vis_df["center"] != "WIP"]

    vis_df["label"] = vis_df["resource_code"] + " @ " + vis_df["center"]



# -------------------- Simulation --------------------
st.subheader("ì¶œê³  ê°€ëŠ¥ ì‹œë®¬ë ˆì´ì…˜")
sim_c1, sim_c2, sim_c3, sim_c4 = st.columns(4)
with sim_c1:
    sim_center = st.selectbox("ì„¼í„°", centers, index=0)
with sim_c2:
    sim_sku = st.selectbox("SKU", skus, index=0)
with sim_c3:
    sim_days = st.number_input("ë©°ì¹  ë’¤", min_value=0, max_value=60, value=20, step=1)
with sim_c4:
    sim_qty = st.number_input("í•„ìš” ìˆ˜ëŸ‰", min_value=0, step=1000, value=20000)

sim_tl = build_timeline(snap_long, moves, [sim_center], [sim_sku],
                        start_dt=min_date, end_dt=max_date, horizon_days=sim_days)
if sim_tl.empty:
    st.info("í•´ë‹¹ ì¡°í•©ì˜ íƒ€ì„ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    sim_target_date = sim_tl["date"].max()
    real_mask = (sim_tl["center"]==sim_center) & ~sim_tl["center"].isin(["WIP"]) & ~sim_tl["center"].str.startswith("In-Transit", na=False)
    sim_stock = int(sim_tl[(sim_tl["date"]==sim_target_date) & real_mask]["stock_qty"].sum())
    ok = sim_stock >= sim_qty
    st.metric(f"{sim_days}ì¼ ë’¤ '{sim_center}'ì˜ '{sim_sku}' ì˜ˆìƒ ì¬ê³ ",
              f"{sim_stock:,}", delta=f"í•„ìš” {sim_qty:,}")
    if ok:
        st.success("ì¶œê³  ê°€ëŠ¥")
    else:
        st.error("ì¶œê³  ë¶ˆê°€")


st.subheader("ë„ì°© ì˜ˆì • ë‚´ì—­ (ì„ íƒ ì„¼í„°/sku)")
if "event_date" in moves.columns:
    upcoming = moves[(moves["event_date"] > latest_dt) &
                     (moves["to_center"].astype(str).isin(centers_sel)) &
                     (moves["resource_code"].astype(str).isin(skus_sel))]               .sort_values("event_date")[
                   ["event_date","to_center","resource_code","qty_ea","carrier_mode"]
               ]
    if upcoming.empty:
        st.caption("ë„ì°© ì˜ˆì • ì—†ìŒ")
    else:
        st.dataframe(upcoming.head(500), use_container_width=True, height=260)



