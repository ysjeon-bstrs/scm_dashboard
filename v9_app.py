"""
SCM Dashboard v9 ë©”ì¸ ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸

ì´ íŒŒì¼ì€ v5_main.pyì˜ ëª¨ë“ˆí™”ëœ ë²„ì „ìœ¼ë¡œ,
ë¡œì§ì„ ë„ë©”ì¸/ë°ì´í„°/UI ê³„ì¸µìœ¼ë¡œ ë¶„ë¦¬í•˜ì—¬ ê°„ê²°ì„±ì„ ê°œì„ í–ˆìŠµë‹ˆë‹¤.

ì£¼ìš” ë³€ê²½ì‚¬í•­ (v5 ëŒ€ë¹„):
- 1041ì¤„ â†’ ~300ì¤„ë¡œ ê°ì†Œ
- ë°ì´í„° ë¡œë”©: data_sources ëª¨ë“ˆë¡œ ë¶„ë¦¬
- í•„í„°/ê²€ì¦: domain ëª¨ë“ˆë¡œ ë¶„ë¦¬
- í…Œì´ë¸” ë Œë”ë§: ì£¼ìš” ë¡œì§ ìœ ì§€ (í–¥í›„ ui.tablesë¡œ ë¶„ë¦¬ ì˜ˆì •)
"""

from __future__ import annotations

import logging
from typing import Any, Dict, List, Optional, Sequence, Tuple

import pandas as pd
import streamlit as st

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

from center_alias import normalize_center_value

# v9 ëª¨ë“ˆ ì„í¬íŠ¸
from scm_dashboard_v9.analytics import pivot_inventory_cost_from_raw
from scm_dashboard_v9.core import build_timeline as build_core_timeline
from scm_dashboard_v9.core.config import CENTER_COL, CONFIG
from scm_dashboard_v9.data_sources import LoadedData, ensure_data
from scm_dashboard_v9.domain import (
    calculate_date_bounds,
    extract_center_and_sku_options,
    filter_by_centers,
    is_empty_or_none,
    safe_to_datetime,
    validate_timeline_inputs,
)
from scm_dashboard_v9.forecast import (
    apply_consumption_with_events,
    build_amazon_forecast_context,
)
from scm_dashboard_v9.ui import (
    build_amazon_snapshot_kpis,
    build_shopee_snapshot_kpis,
    render_amazon_sales_vs_inventory,
    render_amazon_snapshot_kpis,
    render_shopee_snapshot_kpis,
    render_sku_summary_cards,
    render_step_chart,
    render_taekwang_stock_dashboard,
)
from scm_dashboard_v9.ui.adapters import handle_domain_errors
from scm_dashboard_v9.ui.charts import _sku_color_map, _timeline_inventory_matrix
from scm_dashboard_v9.ui.tables import (
    build_resource_name_map,
    render_inbound_and_wip_tables,
    render_inventory_table,
    render_lot_details,
)


def _validate_data_quality(
    snapshot: pd.DataFrame,
    moves: pd.DataFrame,
) -> Tuple[bool, Optional[str]]:
    """
    ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.

    Args:
        snapshot: ìŠ¤ëƒ…ìƒ· ë°ì´í„°í”„ë ˆì„
        moves: ì´ë™ ì›ì¥ ë°ì´í„°í”„ë ˆì„

    Returns:
        (is_valid, error_message) íŠœí”Œ
    """
    # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
    required_snapshot_cols = ["resource_code", "center"]
    missing_snap_cols = [
        col for col in required_snapshot_cols if col not in snapshot.columns
    ]
    if missing_snap_cols:
        return (
            False,
            f"ìŠ¤ëƒ…ìƒ· ë°ì´í„°ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_snap_cols)}",
        )

    required_moves_cols = ["resource_code", "to_center", "qty_ea"]
    missing_move_cols = [col for col in required_moves_cols if col not in moves.columns]
    if missing_move_cols:
        return (
            False,
            f"ì´ë™ ì›ì¥ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_move_cols)}",
        )

    # ë°ì´í„° í¬ê¸° ê²€ì¦
    if len(snapshot) == 0:
        return False, "ìŠ¤ëƒ…ìƒ· ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"

    if len(moves) == 0:
        logger.warning("ì´ë™ ì›ì¥ì´ ë¹„ì–´ìˆìŒ (ê²½ê³ )")

    # ì¤‘ë³µ ë°ì´í„° ê²€ì¦
    if "date" in snapshot.columns:
        dup_count = snapshot.duplicated(
            subset=["date", "center", "resource_code"]
        ).sum()
        if dup_count > 0:
            logger.warning(f"ìŠ¤ëƒ…ìƒ·ì— ì¤‘ë³µ ë°ì´í„° {dup_count}ê±´ ë°œê²¬")

    return True, None


def get_consumption_params_from_ui() -> dict[str, object]:
    """
    UI ì»¨íŠ¸ë¡¤ì—ì„œ ì†Œë¹„ ì˜ˆì¸¡ ê´€ë ¨ ë§¤ê°œë³€ìˆ˜ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.

    Returns:
        ì†Œë¹„ ì˜ˆì¸¡ ë§¤ê°œë³€ìˆ˜ ë”•ì…”ë„ˆë¦¬:
        - lookback_days: ì¶”ì„¸ ê³„ì‚° ê¸°ê°„ (ì¼)
        - events: í”„ë¡œëª¨ì…˜ ì´ë²¤íŠ¸ ëª©ë¡
    """
    lookback_days = int(
        st.session_state.get(
            "trend_lookback_days", CONFIG.consumption.default_lookback_days
        )
    )
    promo_on = bool(st.session_state.get("promo_enabled", False))
    promo_start = st.session_state.get("promo_start")
    promo_end = st.session_state.get("promo_end")
    promo_uplift = float(st.session_state.get("promo_uplift_pct", 0.0)) / 100.0

    events: list[dict[str, object]] = []
    if promo_on and promo_start and promo_end and promo_uplift != 0.0:
        # uplift ê°’ì„ ì„¤ì •ëœ ë²”ìœ„ë¡œ í´ë¨í•‘
        promo_uplift = max(
            CONFIG.consumption.min_promo_uplift,
            min(promo_uplift, CONFIG.consumption.max_promo_uplift),
        )
        events.append(
            {
                "start": pd.to_datetime(promo_start),
                "end": pd.to_datetime(promo_end),
                "uplift": promo_uplift,
            }
        )

    return {"lookback_days": lookback_days, "events": events}


def _render_sidebar_filters(
    *,
    centers: List[str],
    skus: List[str],
    bound_min: pd.Timestamp,
    bound_max: pd.Timestamp,
    today: pd.Timestamp,
    default_past_days: int,
    default_future_days: int,
) -> Dict[str, Any]:
    """
    ì‚¬ì´ë“œë°” í•„í„°ë¥¼ ë Œë”ë§í•˜ê³  ì„ íƒëœ ê°’ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.

    6-7ë‹¨ê³„: ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” & ì‚¬ì´ë“œë°” í•„í„° ë Œë”ë§
    """

    # ë‚ ì§œ ë²”ìœ„ í´ë¨í•‘ í•¨ìˆ˜
    def _clamp_range(
        range_value: Tuple[pd.Timestamp, pd.Timestamp],
    ) -> Tuple[pd.Timestamp, pd.Timestamp]:
        start_val, end_val = range_value
        start_val = pd.Timestamp(start_val).normalize()
        end_val = pd.Timestamp(end_val).normalize()
        start_val = max(min(start_val, bound_max), bound_min)
        end_val = max(min(end_val, bound_max), bound_min)
        if end_val < start_val:
            end_val = start_val
        return (start_val, end_val)

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    def _init_range() -> None:
        if "date_range" not in st.session_state:
            default_start = max(today - pd.Timedelta(days=default_past_days), bound_min)
            default_end = min(today + pd.Timedelta(days=default_future_days), bound_max)
            if default_start > default_end:
                default_start = default_end
            st.session_state.date_range = (default_start, default_end)
        else:
            st.session_state.date_range = _clamp_range(
                tuple(st.session_state.date_range)
            )

    _init_range()

    # ì‚¬ì´ë“œë°” í•„í„° ë Œë”ë§
    with st.sidebar:
        # ë°ì´í„° ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
        if st.button("ğŸ”„ ì‹œíŠ¸ ìƒˆë¡œê³ ì¹¨", key="sidebar_gsheet_refresh", use_container_width=True):
            st.session_state["_trigger_refresh"] = True
            st.rerun()

        st.divider()
        st.header("í•„í„°")

        preset_centers = ["íƒœê´‘KR", "AMZUS"]
        default_centers = [c for c in preset_centers if c in centers]
        if not default_centers:
            default_centers = centers
        selected_centers = st.multiselect("ì„¼í„°", centers, default=default_centers)

        preset_skus = ["BA00021", "BA00022", "BA00047"]
        default_skus = [s for s in preset_skus if s in skus]
        if not default_skus:
            default_skus = skus if len(skus) <= 10 else skus[:10]
        selected_skus = st.multiselect("SKU", skus, default=default_skus)

        st.subheader("ê¸°ê°„ ì„¤ì •")
        date_range_value = st.slider(
            "ê¸°ê°„",
            min_value=bound_min.to_pydatetime(),
            max_value=bound_max.to_pydatetime(),
            value=tuple(
                d.to_pydatetime() for d in _clamp_range(st.session_state.date_range)
            ),
            format="YYYY-MM-DD",
        )
        start_ts = pd.Timestamp(date_range_value[0]).normalize()
        end_ts = pd.Timestamp(date_range_value[1]).normalize()
        st.session_state.date_range = (start_ts, end_ts)
        st.caption(
            "ê¸°ë³¸ê°’: ì„¼í„° íƒœê´‘KRÂ·AMZUS / SKU BA00021Â·BA00022Â·BA00047 / ê¸°ê°„ ì˜¤ëŠ˜âˆ’20ì¼ ~ +30ì¼"
        )

        st.divider()
        st.header("í‘œì‹œ ì˜µì…˜")
        show_prod = st.checkbox("ìƒì‚°ì¤‘ í‘œì‹œ", value=False)
        show_transit = False
        st.caption("ì²´í¬ ì‹œ ê³„ë‹¨ì‹ ì°¨íŠ¸ì— ìƒì‚°ì¤‘ ë¼ì¸ì´ í‘œì‹œë©ë‹ˆë‹¤.")

        use_cons_forecast = st.checkbox("ì¶”ì„¸ ê¸°ë°˜ ì¬ê³  ì˜ˆì¸¡", value=True)
        st.subheader("ì¶”ì„¸ ê³„ì‚° ì„¤ì •")
        lookback_days = int(
            st.number_input(
                "ì¶”ì„¸ ê³„ì‚° ê¸°ê°„(ì¼)",
                min_value=CONFIG.consumption.min_lookback_days,
                max_value=CONFIG.consumption.max_lookback_days,
                value=CONFIG.consumption.default_lookback_days,
                step=7,
                key="trend_lookback_days",
            )
        )

        with st.expander("í”„ë¡œëª¨ì…˜ ê°€ì¤‘ì¹˜(+%)", expanded=False):
            st.checkbox("ê°€ì¤‘ì¹˜ ì ìš©", value=False, key="promo_enabled")
            st.date_input("ì‹œì‘ì¼", key="promo_start")
            st.date_input("ì¢…ë£Œì¼", key="promo_end")
            st.number_input(
                "ê°€ì¤‘ì¹˜(%)",
                min_value=-100.0,
                max_value=300.0,
                value=30.0,
                step=5.0,
                key="promo_uplift_pct",
            )

        st.divider()
        st.header("ì…ê³  ë°˜ì˜ ê°€ì •")
        lag_days = int(
            st.number_input(
                "ì…ê³  ë°˜ì˜ ë¦¬ë“œíƒ€ì„(ì¼) â€“ inbound ë¯¸ê¸°ë¡ ì‹œ arrival+N",
                min_value=0,
                max_value=21,
                value=CONFIG.timeline.default_lag_days,
                step=1,
            )
        )

    return {
        "selected_centers": selected_centers,
        "selected_skus": selected_skus,
        "start_ts": start_ts,
        "end_ts": end_ts,
        "show_prod": show_prod,
        "show_transit": show_transit,
        "use_cons_forecast": use_cons_forecast,
        "lookback_days": lookback_days,
        "lag_days": lag_days,
    }


def _tidy_from_pivot(
    pivot: Optional[pd.DataFrame], mask: Optional[Sequence[bool]]
) -> pd.DataFrame:
    """
    í”¼ë²— í…Œì´ë¸”ì„ tidy í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

    Args:
        pivot: í”¼ë²—ëœ ì¬ê³  ë°ì´í„°í”„ë ˆì„
        mask: í•„í„°ë§í•  í–‰ ë§ˆìŠ¤í¬ (ì„ íƒì )

    Returns:
        tidy í˜•ì‹ì˜ ë°ì´í„°í”„ë ˆì„ (date, resource_code, stock_qty ì»¬ëŸ¼)
    """
    if pivot is None or pivot.empty:
        return pd.DataFrame(columns=["date", "resource_code", "stock_qty"])
    subset = pivot if mask is None else pivot.loc[mask]
    if subset.empty:
        return pd.DataFrame(columns=["date", "resource_code", "stock_qty"])
    tidy = (
        subset.stack()
        .reset_index()
        .rename(columns={"level_0": "date", "level_1": "resource_code", 0: "stock_qty"})
    )
    tidy["date"] = pd.to_datetime(tidy["date"]).dt.normalize()
    tidy["stock_qty"] = pd.to_numeric(tidy["stock_qty"], errors="coerce").fillna(0)
    return tidy


def _filter_amazon_centers(selected_centers: List[str]) -> List[str]:
    """
    ì„ íƒëœ ì„¼í„°ì—ì„œ Amazon ê³„ì—´ ì„¼í„°ë§Œ í•„í„°ë§í•©ë‹ˆë‹¤.

    Args:
        selected_centers: ì„ íƒëœ ì„¼í„° ëª©ë¡

    Returns:
        Amazon ê³„ì—´ ì„¼í„° ëª©ë¡
    """
    amazon_centers = [
        c
        for c in selected_centers
        if isinstance(c, str) and (c.upper().startswith("AMZ") or "AMAZON" in c.upper())
    ]
    if not amazon_centers and "AMZUS" in selected_centers:
        amazon_centers = ["AMZUS"]
    return amazon_centers


def _infer_amazon_centers_from_snapshot(snapshot_df: pd.DataFrame) -> List[str]:
    """Return every Amazon-affiliated center detected in the snapshot."""

    if "center" not in snapshot_df.columns:
        return []

    centers = snapshot_df["center"].dropna().astype(str).str.strip()
    amazon_centers = [
        center
        for center in centers.unique()
        if center and (center.upper().startswith("AMZ") or "AMAZON" in center.upper())
    ]
    return sorted(amazon_centers)


def _build_amazon_kpi_data(
    *,
    snap_amz: pd.DataFrame,
    selected_skus: List[str],
    amazon_centers: List[str],
    show_delta: bool,
) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
    """
    Amazon KPI ë°ì´í„°ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.

    Args:
        snap_amz: Amazon ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        selected_skus: ì„ íƒëœ SKU ëª©ë¡
        amazon_centers: Amazon ì„¼í„° ëª©ë¡
        show_delta: ì „ ìŠ¤ëƒ…ìƒ· ëŒ€ë¹„ ë¸íƒ€ í‘œì‹œ ì—¬ë¶€

    Returns:
        (kpi_df, previous_df) íŠœí”Œ
    """
    kpi_df = build_amazon_snapshot_kpis(
        snap_amz,
        skus=selected_skus,
        center=amazon_centers,
        cover_base="available",
        use_ma7=True,
    )
    previous_df = None
    if show_delta and kpi_df is not None and not kpi_df.empty:
        latest_snap_ts = pd.to_datetime(kpi_df["snap_time"].max())
        if not pd.isna(latest_snap_ts):
            # snap_timeì´ ëª¨ë‘ nullì´ë©´ date ì»¬ëŸ¼ ì‚¬ìš©
            time_col = "snap_time" if snap_amz["snap_time"].notna().any() else "date"

            # ì„±ëŠ¥ ìµœì í™”: í•„í„°ë§ì„ ì§ì ‘ ìˆ˜í–‰í•˜ì—¬ ë¶ˆí•„ìš”í•œ copy ì œê±°
            snap_prev_ts = pd.to_datetime(snap_amz[time_col], errors="coerce")
            snap_prev_mask = (snap_prev_ts.notna()) & (snap_prev_ts < latest_snap_ts)
            snap_prev = snap_amz[snap_prev_mask]
            if not snap_prev.empty:
                previous_df = build_amazon_snapshot_kpis(
                    snap_prev,
                    skus=selected_skus,
                    center=amazon_centers,
                    cover_base="available",
                    use_ma7=True,
                )
    return kpi_df, previous_df


def _build_shopee_kpi_data(
    *,
    snapshot_df: pd.DataFrame,
    selected_skus: List[str],
    shopee_centers: List[str],
    show_delta: bool,
) -> Tuple[Optional[pd.DataFrame], Optional[pd.DataFrame]]:
    """
    SHOPEE KPI ë°ì´í„°ë¥¼ ë¹Œë“œí•©ë‹ˆë‹¤.

    Args:
        snapshot_df: ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        selected_skus: ì„ íƒëœ SKU ëª©ë¡
        shopee_centers: SHOPEE ì„¼í„° ëª©ë¡
        show_delta: ì „ ìŠ¤ëƒ…ìƒ· ëŒ€ë¹„ ë¸íƒ€ í‘œì‹œ ì—¬ë¶€

    Returns:
        (kpi_df, previous_df) íŠœí”Œ
    """
    kpi_df = build_shopee_snapshot_kpis(
        snapshot_df,
        skus=selected_skus,
        centers=shopee_centers,
    )
    previous_df = None
    if show_delta and kpi_df is not None and not kpi_df.empty:
        # ì„¼í„°ë³„ë¡œ ì´ì „ ìŠ¤ëƒ…ìƒ· ì°¾ê¸° (ê° ì„¼í„°ì˜ 2ë²ˆì§¸ ìµœì‹  ì‹œê°„)
        prev_snapshots = []
        debug_info = []  # ë””ë²„ê·¸ìš©
        for center in shopee_centers:
            center_kpi = kpi_df[kpi_df["center"] == center]
            if center_kpi.empty:
                debug_info.append(f"{center}: KPI ë°ì´í„° ì—†ìŒ")
                continue

            # í•´ë‹¹ ì„¼í„°ì˜ í˜„ì¬ ìµœì‹  ì‹œê°„
            center_latest_ts = pd.to_datetime(center_kpi["snap_time"].max())
            if pd.isna(center_latest_ts):
                debug_info.append(f"{center}: ìµœì‹  ì‹œê°„ ì—†ìŒ")
                continue

            # í•´ë‹¹ ì„¼í„°ì— ëŒ€í•´ time_col ê²°ì • (ì„¼í„°ë³„ë¡œ!)
            center_mask = snapshot_df["center"] == center
            center_data = snapshot_df[center_mask]

            # ì´ ì„¼í„°ì— snap_timeì´ ìˆê³  ìœ íš¨í•œ ê°’ì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ date ì‚¬ìš©
            center_time_col = "snap_time"
            if "snap_time" not in center_data.columns or not center_data[
                "snap_time"
            ].notna().any():
                center_time_col = "date"

            # í•´ë‹¹ ì„¼í„°ì˜ ëª¨ë“  ìŠ¤ëƒ…ìƒ· ì‹œê°„ ê°€ì ¸ì˜¤ê¸°
            snap_times = pd.to_datetime(center_data[center_time_col], errors="coerce")
            center_times = center_data[snap_times.notna()][center_time_col].unique()
            center_times_sorted = sorted(
                [pd.to_datetime(t) for t in center_times], reverse=True
            )

            # 2ë²ˆì§¸ ìµœì‹  ì‹œê°„ ì°¾ê¸° (í˜„ì¬ ìµœì‹  ì œì™¸)
            prev_times = [t for t in center_times_sorted if t < center_latest_ts]

            # ë””ë²„ê·¸ ì •ë³´ ìˆ˜ì§‘
            debug_info.append(
                f"{center}: time_col={center_time_col}, ìµœì‹ ={center_latest_ts:%Y-%m-%d %H:%M}, "
                f"ì „ì²´ì‹œê°„={len(center_times_sorted)}ê°œ, "
                f"ì´ì „ì‹œê°„={len(prev_times)}ê°œ"
            )
            if prev_times:
                prev_latest_ts = prev_times[0]  # ë°”ë¡œ ì´ì „ ìŠ¤ëƒ…ìƒ·
                debug_info.append(f"  â†’ ì´ì „={prev_latest_ts:%Y-%m-%d %H:%M}")
                # ì •í™•íˆ ê·¸ ì‹œê°„ì˜ ë°ì´í„°ë§Œ ì„ íƒ
                prev_mask = center_mask & (
                    pd.to_datetime(snapshot_df[center_time_col], errors="coerce")
                    == prev_latest_ts
                )
                center_prev = snapshot_df[prev_mask]
                if not center_prev.empty:
                    prev_snapshots.append(center_prev)
                    debug_info.append(f"  â†’ ë°ì´í„° {len(center_prev)}í–‰ ë°œê²¬")
                else:
                    debug_info.append(f"  â†’ ë°ì´í„° ì—†ìŒ!")
            else:
                debug_info.append(f"  â†’ ì´ì „ ìŠ¤ëƒ…ìƒ· ì‹œê°„ ì—†ìŒ!")


        # ëª¨ë“  ì„¼í„°ì˜ ì´ì „ ìŠ¤ëƒ…ìƒ· í•©ì¹˜ê¸°
        if prev_snapshots:
            snap_prev = pd.concat(prev_snapshots, ignore_index=True)
            previous_df = build_shopee_snapshot_kpis(
                snap_prev,
                skus=selected_skus,
                centers=shopee_centers,
            )

        # ë””ë²„ê·¸ ì •ë³´ë¥¼ ì„¸ì…˜ì— ì €ì¥
        st.session_state["_shopee_delta_debug"] = debug_info
    return kpi_df, previous_df


def _render_amazon_section(
    *,
    selected_centers: List[str],
    snapshot_df: pd.DataFrame,
    selected_skus: List[str],
    timeline_for_chart: pd.DataFrame,
    start_ts: pd.Timestamp,
    end_ts: pd.Timestamp,
    today_norm: pd.Timestamp,
    moves_df: pd.DataFrame,
    lookback_days: int,
    events: List[Dict[str, Any]],
    use_cons_forecast: bool,
    lag_days: int,
    horizon_days: int,
    latest_snapshot_dt: Optional[pd.Timestamp],
) -> None:
    """
    Amazon US íŒë§¤ vs. ì¬ê³  ì°¨íŠ¸ ì„¹ì…˜ì„ ë Œë”ë§í•©ë‹ˆë‹¤.

    13ë‹¨ê³„: Amazon US íŒë§¤ vs ì¬ê³  ì°¨íŠ¸
    """
    amazon_centers = _filter_amazon_centers(selected_centers)
    fallback_centers: List[str] = []
    if not amazon_centers:
        fallback_centers = _infer_amazon_centers_from_snapshot(snapshot_df)
        amazon_centers = fallback_centers

    st.divider()
    st.subheader("Amazon US ëŒ€ì‹œë³´ë“œ")

    if not amazon_centers:
        st.info("Amazon ê³„ì—´ ì„¼í„° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    if fallback_centers:
        st.caption("ì„ íƒëœ ì„¼í„°ì™€ ë¬´ê´€í•˜ê²Œ Amazon ë°ì´í„°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

    sku_colors_map = _sku_color_map(selected_skus)
    snap_amz = filter_by_centers(snapshot_df, amazon_centers)

    # Amazon KPI ì„¤ì • í† ê¸€
    # ì„¤ì •: ì „ ìŠ¤ëƒ…ìƒ· ëŒ€ë¹„ Î”ë§Œ ìœ ì§€ (ì»¤ë²„ì¼ ê¸°ì¤€ í† ê¸€ ì œê±°)
    show_delta = st.toggle("ì „ ìŠ¤ëƒ…ìƒ· ëŒ€ë¹„ Î”", value=True)

    kpi_df, previous_df = _build_amazon_kpi_data(
        snap_amz=snap_amz,
        selected_skus=selected_skus,
        amazon_centers=amazon_centers,
        show_delta=show_delta,
    )

    # SKU â†’ í’ˆëª… ë§¤í•‘
    amz_resource_name_map = build_resource_name_map(snap_amz)

    render_amazon_snapshot_kpis(
        kpi_df,
        sku_colors=sku_colors_map,
        show_delta=show_delta,
        previous_df=previous_df,
        max_cols=4,
        resource_name_map=amz_resource_name_map,
    )

    # ì¬ê³  í”¼ë²— ìƒì„± ë° ì‹¤ì œ/ì˜ˆì¸¡ ë¶„ë¦¬
    amz_inv_pivot = _timeline_inventory_matrix(
        timeline_for_chart,
        centers=amazon_centers,
        skus=selected_skus,
        start=start_ts,
        end=end_ts,
    )

    amazon_timeline_for_chart: Optional[pd.DataFrame] = timeline_for_chart
    if amz_inv_pivot is None:
        amazon_timeline_actual = build_core_timeline(
            snapshot_df,
            moves_df,
            centers=amazon_centers,
            skus=selected_skus,
            start=start_ts,
            end=end_ts,
            today=today_norm,
            lag_days=int(lag_days),
            horizon_days=int(max(0, horizon_days)),
        )

        amazon_timeline_for_chart = amazon_timeline_actual
        if (
            use_cons_forecast
            and amazon_timeline_actual is not None
            and not amazon_timeline_actual.empty
        ):
            cons_start = None
            if latest_snapshot_dt is not None:
                cons_start = (latest_snapshot_dt + pd.Timedelta(days=1)).normalize()

            amazon_timeline_forecast = apply_consumption_with_events(
                amazon_timeline_actual,
                snapshot_df,
                centers=amazon_centers,
                skus=selected_skus,
                start=start_ts,
                end=end_ts,
                lookback_days=lookback_days,
                events=events,
                cons_start=cons_start,
            )
            if (
                amazon_timeline_forecast is not None
                and not amazon_timeline_forecast.empty
            ):
                amazon_timeline_for_chart = amazon_timeline_forecast

        amz_inv_pivot = _timeline_inventory_matrix(
            amazon_timeline_for_chart,
            centers=amazon_centers,
            skus=selected_skus,
            start=start_ts,
            end=end_ts,
        )

    mask_actual = None
    mask_forecast = None
    if amz_inv_pivot is not None:
        mask_actual = amz_inv_pivot.index <= today_norm
        mask_forecast = amz_inv_pivot.index > today_norm
    inv_actual_from_step = _tidy_from_pivot(amz_inv_pivot, mask_actual)
    inv_forecast_from_step = _tidy_from_pivot(amz_inv_pivot, mask_forecast)

    # snap_ì •ì œ ì‹œíŠ¸ì˜ sales_qty ì»¬ëŸ¼ì„ ì‚¬ìš©í•˜ì—¬ íŒë§¤ ë°ì´í„° ë¡œë“œ
    # (snapshot_rawì˜ fba_output_stock ëŒ€ì‹  snap_ì •ì œì˜ sales_qty ì‚¬ìš©)
    amz_ctx = build_amazon_forecast_context(
        snap_long=snapshot_df,
        moves=moves_df,
        snapshot_raw=snapshot_df,  # snap_ì •ì œ ë°ì´í„° ì „ë‹¬ (sales_qty ì»¬ëŸ¼ í¬í•¨)
        centers=amazon_centers,
        skus=selected_skus,
        start=start_ts,
        end=end_ts,
        today=today_norm,
        lookback_days=int(lookback_days),
        promotion_events=events,
        use_consumption_forecast=use_cons_forecast,
    )
    render_amazon_sales_vs_inventory(
        amz_ctx,
        inv_actual=inv_actual_from_step,
        inv_forecast=inv_forecast_from_step,
        sku_colors=sku_colors_map,
        use_inventory_for_sales=True,
    )


def main() -> None:
    """
    v9 ëŒ€ì‹œë³´ë“œ ë©”ì¸ í•¨ìˆ˜.

    ì „ì²´ ëŒ€ì‹œë³´ë“œ UIë¥¼ ë Œë”ë§í•˜ê³  ë°ì´í„° íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    logger.info("SCM Dashboard v9 ì‹œì‘")

    # ========================================
    # 1ë‹¨ê³„: í˜ì´ì§€ ì„¤ì •
    # ========================================
    st.set_page_config(page_title="SCM Dashboard v9", layout="wide")
    st.title("SCM Dashboard v9")

    # ========================================
    # 2ë‹¨ê³„: ë°ì´í„° ë¡œë“œ (ì„¸ì…˜ ê´€ë¦¬)
    # ========================================
    logger.info("ë°ì´í„° ë¡œë“œ ì‹œì‘")
    data = ensure_data()
    if data is None:
        logger.warning("ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•ŠìŒ")
        st.info("ë°ì´í„°ë¥¼ ë¡œë“œí•˜ë©´ ì°¨íŠ¸ì™€ í…Œì´ë¸”ì´ í‘œì‹œë©ë‹ˆë‹¤.")
        return
    logger.info(
        f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: ìŠ¤ëƒ…ìƒ· {len(data.snapshot)}í–‰, ì´ë™ {len(data.moves)}í–‰"
    )

    # ë°ì´í„° í’ˆì§ˆ ê²€ì¦
    is_valid, error_msg = _validate_data_quality(data.snapshot, data.moves)
    if not is_valid:
        logger.error(f"ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {error_msg}")
        st.error(f"ë°ì´í„° í’ˆì§ˆ ì˜¤ë¥˜: {error_msg}")
        return

    # ========================================
    # 3ë‹¨ê³„: ìŠ¤ëƒ…ìƒ· ë°ì´í„° ì •ê·œí™”
    # ========================================
    snapshot_df = data.snapshot.copy()
    if "date" in snapshot_df.columns:
        snapshot_df["date"] = safe_to_datetime(snapshot_df["date"])
    elif "snapshot_date" in snapshot_df.columns:
        snapshot_df["date"] = safe_to_datetime(snapshot_df["snapshot_date"])
    else:
        snapshot_df["date"] = pd.NaT

    # SKU â†’ í’ˆëª… ë§¤í•‘ì„ ë¯¸ë¦¬ ìƒì„±í•˜ì—¬ ê° ëŒ€ì‹œë³´ë“œì—ì„œ ì¬ì‚¬ìš©
    resource_name_map = build_resource_name_map(snapshot_df)

    # ========================================
    # 4ë‹¨ê³„: ì„¼í„° ë° SKU ì˜µì…˜ ì¶”ì¶œ
    # ========================================
    centers, skus = extract_center_and_sku_options(data.moves, snapshot_df)
    logger.info(f"ì„¼í„° {len(centers)}ê°œ, SKU {len(skus)}ê°œ ì¶”ì¶œ")
    if not centers or not skus:
        logger.error("ì„¼í„° ë˜ëŠ” SKU ì •ë³´ ì—†ìŒ")
        st.warning("ì„¼í„° ë˜ëŠ” SKU ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ========================================
    # 5ë‹¨ê³„: ë‚ ì§œ ë²”ìœ„ ê³„ì‚°
    # ========================================
    today = pd.Timestamp.today().normalize()
    snap_dates = snapshot_df["date"].dropna()
    latest_dt = snap_dates.max() if not snap_dates.empty else pd.NaT
    latest_snapshot_dt = (
        None if pd.isna(latest_dt) else pd.to_datetime(latest_dt).normalize()
    )

    # CONFIGì—ì„œ ì„¤ì •ê°’ ê°€ì ¸ì˜¤ê¸°
    default_past_days = CONFIG.ui.default_past_days
    default_future_days = CONFIG.ui.default_future_days
    base_past_days = CONFIG.ui.base_past_days
    base_future_days = CONFIG.ui.base_future_days

    bound_min, bound_max = calculate_date_bounds(
        today=today,
        snapshot_df=snapshot_df,
        moves_df=data.moves,
        base_past_days=base_past_days,
        base_future_days=base_future_days,
    )

    # ========================================
    # 6-7ë‹¨ê³„: ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” & ì‚¬ì´ë“œë°” í•„í„° ë Œë”ë§
    # ========================================
    filters = _render_sidebar_filters(
        centers=centers,
        skus=skus,
        bound_min=bound_min,
        bound_max=bound_max,
        today=today,
        default_past_days=default_past_days,
        default_future_days=default_future_days,
    )

    selected_centers = filters["selected_centers"]
    selected_skus = filters["selected_skus"]
    start_ts = filters["start_ts"]
    end_ts = filters["end_ts"]
    show_prod = filters["show_prod"]
    show_transit = filters["show_transit"]
    use_cons_forecast = filters["use_cons_forecast"]
    lag_days = filters["lag_days"]

    # ========================================
    # 8ë‹¨ê³„: í•„í„° ìœ íš¨ì„± ê²€ì¦
    # ========================================
    if not selected_centers:
        logger.warning("ì„¼í„°ê°€ ì„ íƒë˜ì§€ ì•ŠìŒ")
        st.warning("ìµœì†Œ í•œ ê°œì˜ ì„¼í„°ë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        return
    if not selected_skus:
        logger.warning("SKUê°€ ì„ íƒë˜ì§€ ì•ŠìŒ")
        st.warning("ìµœì†Œ í•œ ê°œì˜ SKUë¥¼ ì„ íƒí•˜ì„¸ìš”.")
        return

    selected_centers = [
        str(center) for center in selected_centers if str(center).strip()
    ]
    selected_skus = [str(sku) for sku in selected_skus if str(sku).strip()]
    logger.info(
        f"í•„í„° ì ìš©: ì„¼í„° {selected_centers}, SKU {len(selected_skus)}ê°œ, ê¸°ê°„ {start_ts} ~ {end_ts}"
    )

    cons_params = get_consumption_params_from_ui()
    lookback_days = int(cons_params.get("lookback_days", 28))
    events = list(cons_params.get("events", []))

    # ========================================
    # 9ë‹¨ê³„: íƒ€ì„ë¼ì¸ ë¹Œë“œ (ì…ë ¥ ê²€ì¦)
    # ========================================
    # ë„ë©”ì¸ ì˜ˆì™¸ë¥¼ UI ì—ëŸ¬ ë©”ì‹œì§€ë¡œ ë³€í™˜
    today_norm = pd.Timestamp.today().normalize()
    if latest_snapshot_dt is not None:
        proj_days_for_build = max(0, int((end_ts - latest_snapshot_dt).days))
    else:
        proj_days_for_build = max(0, int((end_ts - start_ts).days))

    logger.info("íƒ€ì„ë¼ì¸ ë¹Œë“œ ì‹œì‘")
    with handle_domain_errors():
        validate_timeline_inputs(snapshot_df, data.moves, start_ts, end_ts)

    timeline_actual = build_core_timeline(
        snapshot_df,
        data.moves,
        centers=selected_centers,
        skus=selected_skus,
        start=start_ts,
        end=end_ts,
        today=today_norm,
        lag_days=int(lag_days),
        horizon_days=int(proj_days_for_build),
    )

    # íƒ€ì„ë¼ì¸ì´ ë¹„ì–´ìˆì–´ë„ ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë°ì´í„°ëŠ” í‘œì‹œë˜ì–´ì•¼ í•˜ë¯€ë¡œ returní•˜ì§€ ì•ŠìŒ
    has_timeline_data = timeline_actual is not None and not timeline_actual.empty
    if not has_timeline_data:
        logger.warning("íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŒ - ìŠ¤ëƒ…ìƒ· ê¸°ë°˜ ë°ì´í„°ë§Œ í‘œì‹œ")
    else:
        logger.info(f"íƒ€ì„ë¼ì¸ ë¹Œë“œ ì™„ë£Œ: {len(timeline_actual)}í–‰")

    # ========================================
    # 10ë‹¨ê³„: ì†Œë¹„ ì˜ˆì¸¡ ì ìš© (íƒ€ì„ë¼ì¸ì´ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    # ========================================
    timeline_for_chart = None
    if has_timeline_data:
        cons_start = None
        if latest_snapshot_dt is not None:
            cons_start = (latest_snapshot_dt + pd.Timedelta(days=1)).normalize()

        timeline_forecast = apply_consumption_with_events(
            timeline_actual,
            snapshot_df,
            centers=selected_centers,
            skus=selected_skus,
            start=start_ts,
            end=end_ts,
            lookback_days=lookback_days,
            events=events,
            cons_start=cons_start,
        )

        # ì„±ëŠ¥ ìµœì í™”: ë¶ˆí•„ìš”í•œ copy ì œê±°
        if timeline_forecast is None or timeline_forecast.empty:
            timeline_forecast = timeline_actual

        timeline_for_chart = timeline_forecast if use_cons_forecast else timeline_actual

    # ========================================
    # 11ë‹¨ê³„: íƒ­ êµ¬ì¡°ë¡œ ëŒ€ì‹œë³´ë“œ ë Œë”ë§
    # ========================================
    tab1, tab2 = st.tabs(["ğŸ“Š ì¬ê³  ëŒ€ì‹œë³´ë“œ", "ğŸ¢ ì„¼í„°ë³„ ëŒ€ì‹œë³´ë“œ"])

    with tab1:
        # ========================================
        # ì¬ê³  ëŒ€ì‹œë³´ë“œ: ìš”ì•½ KPI
        # ========================================
        with st.expander("ğŸ“Š ìš”ì•½ KPI", expanded=True):
            render_sku_summary_cards(
                snapshot_df,
                data.moves,
                centers=selected_centers,
                skus=selected_skus,
                today=today_norm,
                latest_snapshot=latest_dt,
                lag_days=int(lag_days),
                start=start_ts,
                end=end_ts,
                lookback_days=lookback_days,
                horizon_pad_days=CONFIG.timeline.horizon_pad_days,
                events=events,
            )

        st.divider()

        # ========================================
        # ì¬ê³  ëŒ€ì‹œë³´ë“œ: ê³„ë‹¨ì‹ ì°¨íŠ¸
        # ========================================
        if has_timeline_data and timeline_for_chart is not None:
            render_step_chart(
                timeline_for_chart,
                start=start_ts,
                end=end_ts,
                centers=selected_centers,
                skus=selected_skus,
                show_production=show_prod,
                show_in_transit=show_transit,
                today=today_norm,
                snapshot=snapshot_df,
            )
        else:
            st.info("ì„ íƒí•œ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì„¼í„°/SKU/ê¸°ê°„ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")

        st.divider()

        # ========================================
        # ì¬ê³  ëŒ€ì‹œë³´ë“œ: ì…ê³  ì˜ˆì • ë° WIP í…Œì´ë¸”
        # ========================================
        render_inbound_and_wip_tables(
            moves=data.moves,
            snapshot=snapshot_df,
            selected_centers=selected_centers,
            selected_skus=selected_skus,
            start=start_ts,
            end=end_ts,
            lag_days=lag_days,
            today=today_norm,
        )

        # ========================================
        # ì¬ê³  ëŒ€ì‹œë³´ë“œ: ì¬ê³  í˜„í™© í…Œì´ë¸”
        # ========================================
        display_df = render_inventory_table(
            snapshot=snapshot_df,
            selected_centers=selected_centers,
            latest_dt=latest_dt,
            resource_name_map=resource_name_map,
        )

        # ========================================
        # ì¬ê³  ëŒ€ì‹œë³´ë“œ: ë¡œíŠ¸ ìƒì„¸
        # ========================================
        # center_latest_dates ê³„ì‚°
        center_latest_series = (
            filter_by_centers(snapshot_df, selected_centers).groupby("center")["date"].max()
        )
        center_latest_dates = {
            center: ts.normalize()
            for center, ts in center_latest_series.items()
            if pd.notna(ts)
        }

        visible_skus = (
            display_df.get("SKU", pd.Series(dtype=str))
            .dropna()
            .astype(str)
            .unique()
            .tolist()
        )

        render_lot_details(
            visible_skus=visible_skus,
            selected_centers=selected_centers,
            center_latest_dates=center_latest_dates,
            latest_dt=latest_dt,
        )

    with tab2:
        # ========================================
        # ì„¼í„°ë³„ ëŒ€ì‹œë³´ë“œ: íƒœê´‘KR ê°€ìƒì°½ê³ 
        # ========================================
        # íƒœê´‘KR ê°€ìƒì°½ê³ (ìš´ì˜/í‚¤í•‘) ë°°ë¶„ ë°ì´í„°ë¥¼ êµ¬ë²„ì „ ì„¸ì…˜ì—ì„œë„ ì•ˆì „í•˜ê²Œ ì¡°íšŒ
        taekwang_stock_df = getattr(data, "tk_stock_distrib", None)

        if taekwang_stock_df is not None:
            render_taekwang_stock_dashboard(
                taekwang_stock_df,
                selected_skus=selected_skus,
                resource_name_map=resource_name_map,
                sku_colors=_sku_color_map(selected_skus),
                inbound_moves=data.moves,
            )
        else:
            logger.warning(
                "tk_stock_distrib ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. "
                "Google Sheetsì— 'tk_stock_distrib' ì‹œíŠ¸ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê±°ë‚˜, "
                "Streamlit ì„¸ì…˜ì„ ìƒˆë¡œê³ ì¹¨(Ctrl+R)í•´ì£¼ì„¸ìš”."
            )

        # ========================================
        # ì„¼í„°ë³„ ëŒ€ì‹œë³´ë“œ: Amazon US
        # ========================================
        _render_amazon_section(
            selected_centers=selected_centers,
            snapshot_df=snapshot_df,
            selected_skus=selected_skus,
            timeline_for_chart=timeline_for_chart,
            start_ts=start_ts,
            end_ts=end_ts,
            today_norm=today_norm,
            moves_df=data.moves,
            lookback_days=lookback_days,
            events=events,
            use_cons_forecast=use_cons_forecast,
            lag_days=int(lag_days),
            horizon_days=int(proj_days_for_build),
            latest_snapshot_dt=latest_snapshot_dt,
        )

        # ========================================
        # ì„¼í„°ë³„ ëŒ€ì‹œë³´ë“œ: SHOPEE
        # ========================================
        # SHOPEE ì„¼í„° ëª©ë¡ (í•„í„°ì™€ ë¬´ê´€)
        shopee_centers = ["SBSMY", "SBSSG", "SBSTH", "SBSPH"]

        # ìŠ¤ëƒ…ìƒ·ì— SHOPEE ì„¼í„° ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸
        has_shopee_data = False
        if not snapshot_df.empty and "center" in snapshot_df.columns:
            snapshot_centers = snapshot_df["center"].dropna().astype(str).str.strip().unique()
            has_shopee_data = any(c in shopee_centers for c in snapshot_centers)

        if has_shopee_data:
            st.divider()
            # st.expanderë¡œ í† ê¸€ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸° (ê¸°ë³¸ê°’: ì—´ë¦¼)
            with st.expander("ğŸ›ï¸ SHOPEE", expanded=True):
                st.subheader("SHOPEE ëŒ€ì‹œë³´ë“œ")

                # SHOPEE KPI ì„¤ì • í† ê¸€
                shopee_show_delta = st.toggle("ì „ ìŠ¤ëƒ…ìƒ· ëŒ€ë¹„ Î”", value=True, key="shopee_delta")

                # KPI ë°ì´í„° ë¹Œë“œ (í˜„ì¬ + ì´ì „ ìŠ¤ëƒ…ìƒ·)
                shopee_kpi_df, shopee_previous_df = _build_shopee_kpi_data(
                    snapshot_df=snapshot_df,
                    selected_skus=selected_skus,
                    shopee_centers=shopee_centers,
                    show_delta=shopee_show_delta,
                )

                # KPI ì¹´ë“œ ë Œë”ë§
                render_shopee_snapshot_kpis(
                    shopee_kpi_df,
                    selected_skus=selected_skus,
                    sku_colors=_sku_color_map(selected_skus),
                    resource_name_map=resource_name_map,
                    show_delta=shopee_show_delta,
                    previous_df=shopee_previous_df,
                    max_cols=4,
                )

    # ========================================
    # 18ë‹¨ê³„: AI ì–´ì‹œìŠ¤í„´íŠ¸ (1.5ë‹¨ê³„ í•˜ì´ë¸Œë¦¬ë“œ)
    # ========================================
    st.divider()
    st.header("ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸")

    try:
        from ai_chatbot_simple import render_simple_chatbot_tab
        render_simple_chatbot_tab(
            snapshot_df=snapshot_df,
            moves_df=data.moves,
            timeline_df=timeline_for_chart,  # ğŸ†• 30ì¼ì¹˜ ì‹œê³„ì—´ + ì˜ˆì¸¡!
            selected_centers=selected_centers,
            selected_skus=selected_skus
        )
    except ImportError as e:
        st.warning(f"AI ì–´ì‹œìŠ¤í„´íŠ¸ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        st.info("ai_chatbot_simple.py íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        st.error(f"AI ì–´ì‹œìŠ¤í„´íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        st.caption("secrets.tomlì— Gemini API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
