
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import re
from datetime import datetime, timedelta
from io import BytesIO

st.set_page_config(page_title="ê¸€ë¡œë²Œ ëŒ€ì‹œë³´ë“œ â€” v4", layout="wide")

st.title("ğŸ“¦ ì„¼í„°Ã—SKU ì¬ê³  íë¦„ (ê³„ë‹¨ì‹) ëŒ€ì‹œë³´ë“œ â€” v4")

st.caption("í˜„ì¬ ì¬ê³ ëŠ” í•­ìƒ **ìŠ¤ëƒ…ìƒ· ê¸°ì¤€**ì…ë‹ˆë‹¤. In-Transit / WIP ë¼ì¸ì€ ì˜ˆì¸¡ìš© ê°€ìƒ ë¼ì¸ìœ¼ë¡œ, ìŠ¤ëƒ…ìƒ· ìˆ˜ì¹˜ì—ëŠ” ë°˜ì˜ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# -------------------- Helpers --------------------
def _coalesce_columns(df, candidates, parse_date=False):
    all_names = []
    for item in candidates:
        if isinstance(item, (list, tuple, set)):
            all_names.extend([str(x).strip() for x in item])
        else:
            all_names.append(str(item).strip())
    cols = [c for c in df.columns if str(c).strip() in all_names]
    if not cols:
        return pd.Series(pd.NaT if parse_date else np.nan, index=df.index)
    sub = df[cols].copy()
    if parse_date:
        for c in cols:
            sub[c] = pd.to_datetime(sub[c], errors="coerce")
    out = sub.bfill(axis=1).iloc[:, 0]
    return out

@st.cache_data(ttl=300)
def load_from_excel(file):
    # Streamlit UploadedFile ì§€ì›
    data = file.read() if hasattr(file, "read") else file
    bio = BytesIO(data) if isinstance(data, (bytes, bytearray)) else file

    xl = pd.ExcelFile(bio, engine="openpyxl")
    need = {"SCM_í†µí•©": None, "sample_snapshot": None}
    for s in xl.sheet_names:
        if s in need:
            need[s] = s
    if need["SCM_í†µí•©"] is None or need["sample_snapshot"] is None:
        st.error("ì—‘ì…€ì— 'SCM_í†µí•©'ê³¼ 'sample_snapshot' ì‹œíŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()

    df_move = pd.read_excel(bio, sheet_name=need["SCM_í†µí•©"], engine="openpyxl")
    bio.seek(0)
    df_snap = pd.read_excel(bio, sheet_name=need["sample_snapshot"], engine="openpyxl")
    bio.seek(0)
    # WIP ì‹œíŠ¸ëŠ” ìˆì„ ìˆ˜ë„/ì—†ì„ ìˆ˜ë„
    wip_df = None
    if "ì…ê³ ì˜ˆì •ë‚´ì—­" in xl.sheet_names:
        wip_df = pd.read_excel(bio, sheet_name="ì…ê³ ì˜ˆì •ë‚´ì—­", engine="openpyxl")
    return df_move, df_snap, wip_df

def normalize_snapshot(df_snap):
    df = df_snap.copy()
    df.columns = [str(c).strip() for c in df.columns]
    rename_map = {}
    for c in df.columns:
        cs = str(c)
        if ("ìŠ¤ëƒ…ìƒ·" in cs and "ì¼ì" in cs) or cs.lower() in ["snapshot_date","date"]:
            rename_map[c] = "snapshot_date"
        elif cs.strip() in ["ì°½ê³ ëª…","center"]:
            rename_map[c] = "center"
    df = df.rename(columns=rename_map)
    if "snapshot_date" not in df.columns or "center" not in df.columns:
        st.error("sample_snapshot ì‹œíŠ¸ì— 'ìŠ¤ëƒ…ìƒ· ì¼ì'ì™€ 'ì°½ê³ ëª…'ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    id_cols = ["snapshot_date", "center"]
    sku_cols = [c for c in df.columns if c not in id_cols and "ìŠ¤ëƒ…ìƒ·" not in str(c)]
    longy = df.melt(id_vars=id_cols, value_vars=sku_cols, var_name="resource_code", value_name="stock_qty")
    longy["snapshot_date"] = pd.to_datetime(longy["snapshot_date"], errors="coerce")
    longy["stock_qty"] = pd.to_numeric(longy["stock_qty"], errors="coerce").fillna(0).astype(int)
    return longy.dropna(subset=["snapshot_date","center","resource_code"])

def normalize_moves(df):
    df = df.copy()
    df.columns = [str(c).strip() for c in df.columns]
    resource_code = _coalesce_columns(df, [["resource_code","ìƒí’ˆì½”ë“œ","RESOURCE_CODE"]])
    qty_ea       = _coalesce_columns(df, [["qty_ea","QTY_EA","ìˆ˜ëŸ‰(EA)"]])
    carrier_mode = _coalesce_columns(df, [["carrier_mode","ìš´ì†¡ë°©ë²•","carrier mode"]])
    from_center  = _coalesce_columns(df, [["from_center","ì¶œë°œì°½ê³ "]])
    to_center    = _coalesce_columns(df, [["to_center","ë„ì°©ì°½ê³ "]])
    onboard_date = _coalesce_columns(df, [["onboard_date","ë°°ì •ì¼","ì¶œë°œì¼","H"]], parse_date=True)  # Hì—´ ì˜ë¯¸
    arrival_date = _coalesce_columns(df, [["arrival_date","ë„ì°©ì¼","eta_date","ETA"]], parse_date=True)
    inbound_date = _coalesce_columns(df, [["inbound_date","ì…ê³ ì¼"]], parse_date=True)
    real_depart  = _coalesce_columns(df, [["ì‹¤ì œ ì„ ì ì¼","real_departure","AI"]], parse_date=True)

    out = pd.DataFrame({
        "resource_code": resource_code.astype(str).str.strip(),
        "qty_ea": pd.to_numeric(qty_ea, errors="coerce").fillna(0).astype(int),
        "carrier_mode": carrier_mode.astype(str).str.strip(),
        "from_center": from_center.astype(str).str.strip(),
        "to_center": to_center.astype(str).str.strip(),
        "onboard_date": onboard_date,
        "arrival_date": arrival_date,
        "inbound_date": inbound_date,
        "real_departure": real_depart,
    })
    out["event_date"] = out["inbound_date"].where(out["inbound_date"].notna(), out["arrival_date"])
    return out

def _parse_po_date(po_str):
    """
    ì˜ˆ: 'T250812-0001' -> 2025-08-12
    ê·œì¹™: ì˜ë¬¸ 1ì + YYMMDD + '-' ...
    """
    if not isinstance(po_str, str):
        return pd.NaT
    m = re.search(r"[A-Za-z](\d{2})(\d{2})(\d{2})", po_str)
    if not m:
        return pd.NaT
    yy, mm, dd = m.groups()
    year = 2000 + int(yy)  # 20xx ê°€ì •
    try:
        return pd.Timestamp(datetime(year, int(mm), int(dd)))
    except Exception:
        return pd.NaT

def load_wip_from_incoming(df_incoming, default_center="íƒœê´‘KR"):
    """
    'ì…ê³ ì˜ˆì •ë‚´ì—­' ì‹œíŠ¸ ì •ê·œí™”:
      - wip_start = po_no(ë°œì£¼ë²ˆí˜¸)ì—ì„œ íŒŒì‹±í•œ ë‚ ì§œ(ì—†ìœ¼ë©´ wip_ready-10ì¼)
      - wip_ready = intended_push_date
      - qty_ea    = quantity / total_quantity
      - to_center = íƒœê´‘KR (ê³ ì •)
      - lot       = ì œì¡°ë²ˆí˜¸(ì„ íƒ)
    """
    if df_incoming is None or df_incoming.empty:
        return pd.DataFrame()

    df = df_incoming.copy()
    df.columns = [str(c).strip().lower() for c in df.columns]

    # ì»¬ëŸ¼ ì¶”ë¡ 
    po_col   = next((c for c in df.columns if c in ["po_no","ponumber","po"]), None)
    date_col = next((c for c in df.columns if "intended_push_date" in c or "ì…ê³ " in c), None)
    sku_col  = next((c for c in df.columns if c in ["product_code","resource_code","ìƒí’ˆì½”ë“œ"]), None)
    qty_col  = next((c for c in df.columns if c in ["quantity","qty","ìˆ˜ëŸ‰","total_quantity"]), None)
    lot_col  = next((c for c in df.columns if c in ["lot","ì œì¡°ë²ˆí˜¸","lot_no","lotnumber"]), None)

    if not date_col or not sku_col or not qty_col:
        return pd.DataFrame()

    out = pd.DataFrame({
        "resource_code": df[sku_col].astype(str).str.strip(),
        "to_center": default_center,
        "wip_ready": pd.to_datetime(df[date_col], errors="coerce"),
        "qty_ea": pd.to_numeric(df[qty_col], errors="coerce").fillna(0).astype(int),
        "lot": df[lot_col].astype(str).str.strip() if lot_col else ""
    })

    # ë°œì£¼ì¼ íŒŒì‹± â†’ wip_start
    out["wip_start"] = df[po_col].map(_parse_po_date) if po_col else pd.NaT
    # ë°œì£¼ì¼ì´ ëª» ì½í˜”ìœ¼ë©´(ì˜ˆì™¸ ì¼€ì´ìŠ¤) ìµœì†Œí•œ wip_ready - 10ì¼ë¡œ ë³´ì •
    mask_na = out["wip_start"].isna() & out["wip_ready"].notna()
    out.loc[mask_na, "wip_start"] = out.loc[mask_na, "wip_ready"] - pd.to_timedelta(10, unit="D")

    # ìœ íš¨ê°’ë§Œ
    out = out.dropna(subset=["resource_code","wip_ready","wip_start"]).reset_index(drop=True)
    return out[["resource_code","to_center","wip_start","wip_ready","qty_ea","lot"]]

def merge_wip_as_moves(moves_df, wip_df):
    if wip_df is None or wip_df.empty:
        return moves_df
    wip_moves = pd.DataFrame({
        "resource_code": wip_df["resource_code"],
        "qty_ea": wip_df["qty_ea"].astype(int),
        "carrier_mode": "WIP",
        "from_center": "WIP",
        "to_center": wip_df["to_center"],
        "onboard_date": wip_df["wip_start"],
        "arrival_date": wip_df["wip_ready"],
        "inbound_date": pd.NaT,
        "real_departure": pd.NaT,
        "event_date": wip_df["wip_ready"],
        "lot": wip_df.get("lot", "")
    })
    return pd.concat([moves_df, wip_moves], ignore_index=True)

def build_timeline(snap_long, moves, centers_sel, skus_sel,
                   start_dt, end_dt, horizon_days=0):
    """
    ë°˜í™˜: date, center, resource_code, stock_qty
    - ì‹¤ì œ ì„¼í„° ë¼ì¸: ìŠ¤ëƒ…ìƒ· + (ì¶œë°œ:onboard -, ë„ì°©:event +)
    - In-Transit ê°€ìƒ ë¼ì¸: onboard +, event -
    """
    horizon_end = end_dt + pd.Timedelta(days=horizon_days)
    full_dates = pd.date_range(start_dt, horizon_end, freq="D")

    base = snap_long[
        snap_long["center"].isin(centers_sel) &
        snap_long["resource_code"].isin(skus_sel)
    ].copy().rename(columns={"snapshot_date":"date"})
    if base.empty:
        return pd.DataFrame(columns=["date","center","resource_code","stock_qty"])
    base = base[(base["date"] >= start_dt) & (base["date"] <= end_dt)]

    lines =()

    lines = []

    # 1) ì‹¤ì œ ì„¼í„° ë¼ì¸
    for (ct, sku), grp in base.groupby(["center","resource_code"]):
        grp = grp.sort_values("date")
        last_dt = grp["date"].max()

        if horizon_days > 0:
            proj_dates = pd.date_range(last_dt + pd.Timedelta(days=1), horizon_end, freq="D")
            proj_df = pd.DataFrame({"date": proj_dates, "center": ct,
                                    "resource_code": sku, "stock_qty": np.nan})
            ts = pd.concat([grp[["date","center","resource_code","stock_qty"]], proj_df], ignore_index=True)
        else:
            ts = grp[["date","center","resource_code","stock_qty"]].copy()

        ts = ts.sort_values("date")
        ts["stock_qty"] = ts["stock_qty"].ffill()

        mv = moves[moves["resource_code"] == sku].copy()

        eff_minus = (
            mv[(mv["from_center"].astype(str) == str(ct)) &
               (mv["onboard_date"].notna()) &
               (mv["onboard_date"] > last_dt)]
            .groupby("onboard_date", as_index=False)["qty_ea"].sum()
            .rename(columns={"onboard_date":"date","qty_ea":"delta"})
        )
        eff_minus["delta"] *= -1

        eff_plus = (
            mv[(mv["to_center"].astype(str) == str(ct)) &
               (mv["event_date"].notna()) &
               (mv["event_date"] > last_dt)]
            .groupby("event_date", as_index=False)["qty_ea"].sum()
            .rename(columns={"event_date":"date","qty_ea":"delta"})
        )

        eff_all = pd.concat([eff_minus, eff_plus], ignore_index=True).sort_values("date")
        for d, delta in zip(eff_all["date"], eff_all["delta"]):
            ts.loc[ts["date"] >= d, "stock_qty"] = ts.loc[ts["date"] >= d, "stock_qty"] + delta

        ts["stock_qty"] = ts["stock_qty"].clip(lower=0)
        lines.append(ts)

    # 2) In-Transit ê°€ìƒ ë¼ì¸ (Non-WIP / WIP ë¶„ë¦¬)
    mv_sel = moves[
        moves["resource_code"].isin(skus_sel) &
        (moves["from_center"].astype(str).isin(centers_sel) | moves["to_center"].astype(str).isin(centers_sel) | (moves["carrier_mode"].astype(str).str.upper()=="WIP"))
    ].copy()

    for sku, g in mv_sel.groupby("resource_code"):
        # Non-WIP í†µí•© In-Transit
        g_nonwip = g[g["carrier_mode"].astype(str).str.upper() != "WIP"]
        if not g_nonwip.empty:
            add_onboard = (
                g_nonwip[g_nonwip["onboard_date"].notna()]
                .groupby("onboard_date", as_index=False)["qty_ea"].sum()
                .rename(columns={"onboard_date":"date","qty_ea":"delta"})
            )
            add_event = (
                g_nonwip[g_nonwip["event_date"].notna()]
                .groupby("event_date", as_index=False)["qty_ea"].sum()
                .rename(columns={"event_date":"date","qty_ea":"delta"})
            )
            add_event["delta"] *= -1
            deltas = pd.concat([add_onboard, add_event], ignore_index=True)
            if not deltas.empty:
                s = pd.Series(0, index=pd.to_datetime(full_dates))
                for d, v in deltas.groupby("date")["delta"].sum().items():
                    d = pd.to_datetime(d)
                    if d < full_dates[0]:
                        s.iloc[:] = s.iloc[:] + v
                    else:
                        s.loc[s.index >= d] = s.loc[s.index >= d] + v
                vdf = pd.DataFrame({
                    "date": s.index,
                    "center": "In-Transit",
                    "resource_code": sku,
                    "stock_qty": s.values.clip(min=0)
                })
                lines.append(vdf)

        # WIP ë³„ë„ ë¼ì¸
        g_wip = g[g["carrier_mode"].astype(str).str.upper() == "WIP"]
        if not g_wip.empty:
            add_onboard = (
                g_wip[g_wip["onboard_date"].notna()]
                .groupby("onboard_date", as_index=False)["qty_ea"].sum()
                .rename(columns={"onboard_date":"date","qty_ea":"delta"})
            )
            add_event = (
                g_wip[g_wip["event_date"].notna()]
                .groupby("event_date", as_index=False)["qty_ea"].sum()
                .rename(columns={"event_date":"date","qty_ea":"delta"})
            )
            add_event["delta"] *= -1
            deltas = pd.concat([add_onboard, add_event], ignore_index=True)
            if not deltas.empty:
                s = pd.Series(0, index=pd.to_datetime(full_dates))
                for d, v in deltas.groupby("date")["delta"].sum().items():
                    d = pd.to_datetime(d)
                    if d < full_dates[0]:
                        s.iloc[:] = s.iloc[:] + v
                    else:
                        s.loc[s.index >= d] = s.loc[s.index >= d] + v
                vdf = pd.DataFrame({
                    "date": s.index,
                    "center": "WIP",
                    "resource_code": sku,
                    "stock_qty": s.values.clip(min=0)
                })
                lines.append(vdf)

    if not lines:
        return pd.DataFrame(columns=["date","center","resource_code","stock_qty"])

    out = pd.concat(lines, ignore_index=True)
    out = out[(out["date"] >= start_dt) & (out["date"] <= horizon_end)]
    return out

# -------------------- Tabs for inputs --------------------
tab1, tab2 = st.tabs(["ì—‘ì…€ ì—…ë¡œë“œ", "CSV ìˆ˜ë™ ì—…ë¡œë“œ"])

with tab1:
    xfile = st.file_uploader("ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"], key="excel")
    if xfile is not None:
        df_move, df_snap, df_incoming = load_from_excel(xfile)
        moves_raw = normalize_moves(df_move)
        snap_long = normalize_snapshot(df_snap)

        # WIP ë¶ˆëŸ¬ì˜¤ê¸° ë° ë³‘í•©
        try:
            wip_df = load_wip_from_incoming(df_incoming)
            moves = merge_wip_as_moves(moves_raw, wip_df)
            st.success(f"WIP {len(wip_df)}ê±´ ë°˜ì˜ ì™„ë£Œ" if wip_df is not None and not wip_df.empty else "WIP ì—†ìŒ")
        except Exception as e:
            moves = moves_raw
            st.warning(f"WIP ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")

with tab2:
    cs_snap = st.file_uploader("sample_snapshot.csv ì—…ë¡œë“œ", type=["csv"], key="snapcsv")
    cs_move = st.file_uploader("SCM_í†µí•©.csv ì—…ë¡œë“œ", type=["csv"], key="movecsv")
    if cs_snap is not None and cs_move is not None:
        snap_raw = pd.read_csv(cs_snap)
        move_raw = pd.read_csv(cs_move)
        moves = normalize_moves(move_raw)
        if "resource_code" in [c.lower() for c in snap_raw.columns]:
            sr = snap_raw.copy()
            cn = {}
            for c in sr.columns:
                cl = c.lower()
                if cl in ["date","snapshot_date","ìŠ¤ëƒ…ìƒ· ì¼ì"]:
                    cn[c] = "snapshot_date"
                elif cl in ["center","ì°½ê³ ëª…"]:
                    cn[c] = "center"
                elif cl == "resource_code":
                    cn[c] = "resource_code"
                elif cl in ["stock_qty","qty","quantity"]:
                    cn[c] = "stock_qty"
            sr = sr.rename(columns=cn)
            sr["snapshot_date"] = pd.to_datetime(sr["snapshot_date"], errors="coerce")
            sr["stock_qty"] = pd.to_numeric(sr["stock_qty"], errors="coerce").fillna(0).astype(int)
            snap_long = sr[["snapshot_date","center","resource_code","stock_qty"]].dropna()
        else:
            snap_long = normalize_snapshot(snap_raw)

if "snap_long" not in locals():
    st.info("ì—‘ì…€ ë˜ëŠ” CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ í•„í„°/ì°¨íŠ¸ê°€ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
    st.stop()

# -------------------- Filters --------------------
centers = sorted(snap_long["center"].dropna().astype(str).unique().tolist())
skus = sorted(snap_long["resource_code"].dropna().astype(str).unique().tolist())
min_date = snap_long["snapshot_date"].min()
max_date = snap_long["snapshot_date"].max()

st.sidebar.header("í•„í„°")
centers_sel = st.sidebar.multiselect("ì„¼í„° ì„ íƒ", centers, default=(["íƒœê´‘KR"] if "íƒœê´‘KR" in centers else centers[:1]))
skus_sel = st.sidebar.multiselect("SKU ì„ íƒ", skus, default=([s for s in ["BA00022","BA00021"] if s in skus] or skus[:2]))
date_range = st.sidebar.slider("ê¸°ê°„",
    min_value=min(min_date.to_pydatetime(), (pd.Timestamp.today().normalize() - timedelta(days=60)).to_pydatetime()),
    max_value=max(max_date.to_pydatetime(), (pd.Timestamp.today().normalize() + timedelta(days=60)).to_pydatetime()),
    value=((pd.Timestamp.today().normalize() - timedelta(days=20)).to_pydatetime(), (pd.Timestamp.today().normalize() + timedelta(days=20)).to_pydatetime()),
    format="YYYY-MM-DD")
horizon = st.sidebar.number_input("ë¯¸ë˜ ì „ë§ ì¼ìˆ˜", min_value=0, max_value=60, value=20)
show_wip   = st.sidebar.checkbox("WIP í‘œì‹œ", value=True)

start_dt = pd.to_datetime(date_range[0]).normalize()
end_dt = pd.to_datetime(date_range[1]).normalize()

# -------------------- KPIs --------------------
st.subheader("ìš”ì•½ KPI")

# ìŠ¤ëƒ…ìƒ· ê¸°ì¤€ ìµœì‹ ì¼
latest_dt = snap_long["snapshot_date"].max()
latest_dt_str = pd.to_datetime(latest_dt).strftime("%Y-%m-%d")

# SKUë³„ í˜„ì¬ ì¬ê³ (ì„ íƒ ì„¼í„° ê¸°ì¤€, ìµœì‹  ìŠ¤ëƒ…ìƒ·)
latest_rows = snap_long[(snap_long["snapshot_date"] == latest_dt) & (snap_long["center"].isin(centers_sel))]
sku_totals = {sku: int(latest_rows[latest_rows["resource_code"]==sku]["stock_qty"].sum()) for sku in skus_sel}

# In-Transit (WIP ì œì™¸, ì…/ì¶œê³  ëª¨ë‘ í¬í•¨)
today = pd.Timestamp.today().normalize()
in_transit_mask = (
    (moves["onboard_date"].notna()) &
    (moves["onboard_date"] <= today) &
    (moves["inbound_date"].isna()) &
    ((moves["arrival_date"].isna()) | (moves["arrival_date"] > today)) &
    ((moves["to_center"].astype(str).isin(centers_sel)) | (moves["from_center"].astype(str).isin(centers_sel))) &
    (moves["resource_code"].astype(str).isin(skus_sel)) &
    (moves["carrier_mode"].astype(str).str.upper() != "WIP")
)
in_transit_total = int(moves[in_transit_mask]["qty_ea"].sum())

# WIP(ì˜¤ëŠ˜ ê¸°ì¤€ ì”ëŸ‰, ì„ íƒ ì„¼í„°/SKU ë²”ìœ„)
wip_moves = moves[moves["carrier_mode"].astype(str).str.upper() == "WIP"].copy()
wip_moves = wip_moves[
    wip_moves["to_center"].astype(str).isin(centers_sel) &
    wip_moves["resource_code"].astype(str).isin(skus_sel)
].copy()
if not wip_moves.empty:
    on = (wip_moves.dropna(subset=["onboard_date"]).groupby("onboard_date", as_index=True)["qty_ea"].sum())
    ev = (wip_moves.dropna(subset=["event_date"]).groupby("event_date", as_index=True)["qty_ea"].sum() * -1)
    wip_flow = pd.concat([on, ev]).groupby(level=0).sum().sort_index()
    wip_cum = wip_flow[wip_flow.index <= today].cumsum()
    wip_today = int(wip_cum.iloc[-1]) if not wip_cum.empty else 0
else:
    wip_today = 0

# SKUë³„ í˜„ì¬ ì¬ê³  ì¹´ë“œ
def _chunk(lst, n):
    for i in range(0, len(lst), n):
        yield lst[i:i+n]

for group in _chunk(skus_sel, 4):
    cols = st.columns(len(group))
    for i, sku in enumerate(group):
        cols[i].metric(f"{sku} í˜„ì¬ ì¬ê³ (ìŠ¤ëƒ…ìƒ· {latest_dt_str})", f"{sku_totals.get(sku, 0):,}")

# í†µí•© KPI
k_it, k_wip = st.columns(2)
k_it.metric("ì´ë™ ì¤‘ ì¬ê³  (In-Transit)", f"{in_transit_total:,}")
k_wip.metric("í˜„ì¬ WIP(ë¯¸ì™„ë£Œ ìƒì‚°)", f"{wip_today:,}")

st.divider()

# -------------------- Step Chart (Plotly) --------------------
st.subheader("ê³„ë‹¨ì‹ ì¬ê³  íë¦„")
timeline = build_timeline(snap_long, moves, centers_sel, skus_sel,
                          start_dt, end_dt, horizon_days=horizon)
if timeline.empty:
    st.info("ì„ íƒ ì¡°ê±´ì— í•´ë‹¹í•˜ëŠ” íƒ€ì„ë¼ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
else:
    # ê¸°ê°„ + ì „ë§ ë²”ìœ„ ìŠ¬ë¼ì´ìŠ¤
    vis_df = timeline[
        (timeline["date"] >= start_dt) &
        (timeline["date"] <= (end_dt + pd.Timedelta(days=horizon)))
    ].copy()

    # In-Transitì€ í•­ìƒ í†µí•©
    vis_df["center"] = vis_df["center"].str.replace(r"^In-Transit.*", "In-Transit", regex=True)

    # WIP í‘œì‹œ ì˜µì…˜
    if not show_wip:
        vis_df = vis_df[vis_df["center"] != "WIP"]

    # ë¼ë²¨ ì¬ìƒì„± (ë°˜ë“œì‹œ ë§ˆì§€ë§‰ì—)
    vis_df["label"] = vis_df["resource_code"] + " @ " + vis_df["center"]

    # ê·¸ë¦¬ê¸°
    fig = px.line(
        vis_df,
        x="date",
        y="stock_qty",
        color="label",
        line_shape="hv",
        title="ì„ íƒí•œ SKU Ã— ì„¼í„°(ë° In-Transit/WIP) ê³„ë‹¨ì‹ ì¬ê³  íë¦„",
        render_mode="svg"
    )
    fig.update_traces(
        mode="lines",
        hovertemplate="ë‚ ì§œ: %{x|%Y-%m-%d}<br>ì¬ê³ : %{y:,} EA<br>%{fullData.name}<extra></extra>"
    )
    fig.update_layout(
        hovermode="x unified",
        xaxis_title="Date",
        yaxis_title="Inventory (qty_ea)",
        legend_title_text="SKU @ Center / In-Transit(íŒŒë‘ ì ì„ ) / WIP(ë¹¨ê°• ì ì„ )",
        margin=dict(l=20, r=20, t=60, b=20)
    )

    # ---- ìŠ¤íƒ€ì¼: ì‹¤ì œ ì„¼í„° ì–‡ê²Œ(2px, 0.9), IT/WIP ì ì„  2px 0.8 ----
COLOR_WIP = "#e11d48"   # ë¹¨ê°• (WIP)
COLOR_IT  = "#2563eb"   # íŒŒë‘ (In-Transit)

# íŒŒë‘/ë¹¨ê°•ê³¼ ê²¹ì¹˜ì§€ ì•ŠëŠ” 'ì„¼í„°' ì „ìš© íŒ”ë ˆíŠ¸
CENTER_PALETTE = [
    "#111827",  # almost black (neutral)
    "#475569",  # slate
    "#0f766e",  # teal
    "#d97706",  # amber
    "#7c3aed",  # violet
    "#16a34a",  # green
    "#a855f7",  # purple
    "#f59e0b",  # orange/amber
]

# ì„¼í„° ë¼ì¸: ì–‡ê³ (2px) ì•½ê°„ íˆ¬ëª…(0.9)
center_colors = {}
ci = 0
for i, tr in enumerate(fig.data):
    name = (tr.name or "")
    if ("In-Transit" in name) or (" WIP" in name):
        continue
    fig.data[i].update(line=dict(width=2.0), opacity=0.9)
    center = name.split(" @ ")[-1] if " @ " in name else ""
    if center not in center_colors:
        center_colors[center] = CENTER_PALETTE[ci % len(CENTER_PALETTE)]
        ci += 1
    fig.data[i].update(line=dict(color=center_colors[center]))
    fig.data[i].legendgroup = "Center"
    fig.data[i].legendrank = 10  # ìƒë‹¨

# In-Transit: íŒŒë‘ ì ì„  2px, 0.8
for i, tr in enumerate(fig.data):
    name = (tr.name or "")
    if "In-Transit" in name:
        fig.data[i].update(line=dict(color=COLOR_IT, dash="dot", width=2.0), opacity=0.8)
        fig.data[i].legendgroup = "In-Transit"
        fig.data[i].legendrank = 20

# WIP: ë¹¨ê°• ì ì„  2px, 0.8
for i, tr in enumerate(fig.data):
    name = (tr.name or "")
    if name.endswith(" @ WIP") or " WIP" in name:
        fig.data[i].update(line=dict(color=COLOR_WIP, dash="dot", width=2.0), opacity=0.8)
        fig.data[i].legendgroup = "WIP"
        fig.data[i].legendrank = 30

    # ì°¨íŠ¸ í‚¤ (í•„í„° ì¡°í•©ìœ¼ë¡œ ìœ ë‹ˆí¬í•˜ê²Œ)
chart_key = f"stepchart|centers={','.join(centers_sel)}|skus={','.join(skus_sel)}|{start_dt:%Y%m%d}-{end_dt:%Y%m%d}|h{horizon}|w{int(show_wip)}"

st.plotly_chart(
    fig,
    use_container_width=True,
    config={"displaylogo": False},
    key=chart_key,  # â† ê³ ìœ  í‚¤
)


# -------------------- Upcoming Arrivals --------------------
st.subheader("ì…ê³  ì˜ˆì • ë‚´ì—­ (ì„ íƒ ì„¼í„°/SKU)")

today = pd.Timestamp.today().normalize()
window_end = end_dt + pd.Timedelta(days=horizon)
start_cut = today  # ê³¼ê±° ETA ì œì™¸ (D-0 í¬í•¨)

# (A) ìš´ì†¡(ë¹„ WIP) - íƒœê´‘ ì œì™¸ ì„¼í„°
arr_transport = moves[
    (moves["event_date"].notna()) &
    (moves["event_date"] >= start_cut) & (moves["event_date"] <= window_end) &
    (moves["carrier_mode"].astype(str).str.upper() != "WIP") &
    (moves["to_center"].astype(str).isin([c for c in centers_sel if c != "íƒœê´‘KR"])) &
    (moves["resource_code"].astype(str).isin(skus_sel))
].copy()
arr_transport["lot"] = ""  # ì¼ë°˜ ì´ë™ê±´ì€ lot ë¹„ì›€

# (B) WIP - íƒœê´‘KR ì„ íƒ ì‹œ
arr_wip = pd.DataFrame()
if "íƒœê´‘KR" in centers_sel:
    arr_wip = moves[
        (moves["event_date"].notna()) &
        (moves["event_date"] >= start_cut) & (moves["event_date"] <= window_end) &
        (moves["carrier_mode"].astype(str).str.upper() == "WIP") &
        (moves["to_center"].astype(str) == "íƒœê´‘KR") &
        (moves["resource_code"].astype(str).isin(skus_sel))
    ].copy()

upcoming = pd.concat([arr_transport, arr_wip], ignore_index=True)
if upcoming.empty:
    st.caption("ë„ì°© ì˜ˆì • ì—†ìŒ (ì˜¤ëŠ˜ ì´í›„)")
else:
    upcoming["days_to_arrival"] = (upcoming["event_date"] - today).dt.days
    upcoming = upcoming.sort_values(["event_date","to_center","resource_code"])
    cols = ["event_date","days_to_arrival","to_center","resource_code","qty_ea","carrier_mode","onboard_date","lot"]
    cols = [c for c in cols if c in upcoming.columns]
    st.dataframe(upcoming[cols].head(1000), use_container_width=True, height=300)


# -------------------- Simulation --------------------
st.subheader("ì¶œê³  ê°€ëŠ¥ ì‹œë®¬ë ˆì´ì…˜")
sim_c1, sim_c2, sim_c3, sim_c4 = st.columns(4)
with sim_c1:
    sim_center = st.selectbox("ì„¼í„°", centers, index=max(0, centers.index("íƒœê´‘KR") if "íƒœê´‘KR" in centers else 0))
with sim_c2:
    default_skus = [s for s in ["BA00022","BA00021"] if s in skus] or skus
    sim_sku = st.selectbox("SKU", skus, index=max(0, skus.index(default_skus[0])))
with sim_c3:
    sim_days = st.number_input(f"ë©°ì¹  ë’¤ (ê¸°ì¤€ì¼: {today.strftime('%Y-%m-%d')})", min_value=0, max_value=60, value=20, step=1)
    st.caption(f"â†’ ëª©í‘œì¼: {(today + pd.Timedelta(days=int(sim_days))).strftime('%Y-%m-%d')}")
with sim_c4:
    sim_qty = st.number_input("í•„ìš” ìˆ˜ëŸ‰", min_value=0, step=1000, value=20000)

sim_tl = build_timeline(snap_long, moves, [sim_center], [sim_sku],
                        start_dt=min_date, end_dt=max_date, horizon_days=sim_days)
if sim_tl.empty:
    st.info("í•´ë‹¹ ì¡°í•©ì˜ íƒ€ì„ë¼ì¸ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    sim_target_date = sim_tl["date"].max()
    real_mask = (sim_tl["center"]==sim_center) & ~sim_tl["center"].isin(["WIP"]) & ~sim_tl["center"].str.startswith("In-Transit", na=False)
    sim_stock = int(sim_tl[(sim_tl["date"]==sim_target_date) & real_mask]["stock_qty"].sum())
    ok = sim_stock >= sim_qty
    st.metric(f"{sim_days}ì¼ ë’¤({(today + pd.Timedelta(days=int(sim_days))).strftime('%Y-%m-%d')}) '{sim_center}'ì˜ '{sim_sku}' ì˜ˆìƒ ì¬ê³ ",
              f"{sim_stock:,}", delta=f"í•„ìš” {sim_qty:,}")
    if ok:
        st.success("ì¶œê³  ê°€ëŠ¥")
    else:
        st.error("ì¶œê³  ë¶ˆê°€")
