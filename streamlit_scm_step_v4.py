# dashboard_v4_clean.py
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import re
from datetime import datetime
from io import BytesIO
from typing import Dict, List, Optional, Tuple
import requests
from urllib.parse import quote

# =========================
# App setup
# =========================
st.set_page_config(page_title="SCM ì¬ê³  íë¦„ ëŒ€ì‹œë³´ë“œ â€” v4 (clean)", layout="wide")
st.title("ğŸ“¦ SCM ì¬ê³  íë¦„ ëŒ€ì‹œë³´ë“œ â€” v4 (clean)")

# ê³µê°œ/ë¹„ê³µê°œ ì–´ë””ì„œë“  ë™ì‘í•˜ë„ë¡: ì‹¤íŒ¨ëŠ” ì¡°ìš©íˆ, ìš”ì²­ ì‹œì—ë§Œ ìì„¸íˆ
GSHEET_ID = "1RYjKW2UDJ2kWJLAqQH26eqx2-r9Xb0_qE_hfwu9WIj8"

CENTER_COL = {
    "íƒœê´‘KR": "stock2",
    "AMZUS": "fba_available_stock",
    "í’ˆê³ KR": "poomgo_v2_available_stock",
    "SBSPH": "shopee_ph_available_stock",
    "SBSSG": "shopee_sg_available_stock",
    "SBSMY": "shopee_my_available_stock",
    "AcrossBUS": "acrossb_available_stock",
    "ì–´í¬ë¡œìŠ¤ë¹„US": "acrossb_available_stock",
}

# -------------------- Helpers --------------------
def _coalesce_columns(df: pd.DataFrame, candidates: List, parse_date: bool = False) -> pd.Series:
    all_names = []
    for item in candidates:
        if isinstance(item, (list, tuple, set)):
            all_names.extend([str(x).strip() for x in item])
        else:
            all_names.append(str(item).strip())
    cols = [c for c in df.columns if str(c).strip() in all_names]
    if not cols:
        cols = [c for c in df.columns if any(name.lower() in str(c).lower() for name in all_names)]
    if not cols:
        cols = [c for c in df.columns if any(name.lower() in str(c).lower() or str(c).lower() in name.lower() for name in all_names)]
    if not cols:
        return pd.Series(pd.NaT if parse_date else np.nan, index=df.index)
    sub = df[cols].copy()
    if parse_date:
        for c in cols:
            sub[c] = pd.to_datetime(sub[c], errors="coerce")
    return sub.bfill(axis=1).iloc[:, 0]

def gs_csv_public(sheet_name: str, noisy: bool=False) -> pd.DataFrame:
    """ê³µê°œ(Anyone with the link) ì‹œíŠ¸ë¥¼ gviz CSVë¡œ ì½ìŒ. ì‹¤íŒ¨ ì‹œ ë¹ˆ DF(+ì˜µì…˜ ì—ëŸ¬ í‘œì‹œ)."""
    try:
        url = f"https://docs.google.com/spreadsheets/d/{GSHEET_ID}/gviz/tq?tqx=out:csv&sheet={quote(sheet_name)}"
        return pd.read_csv(url)
    except Exception as e:
        if noisy:
            st.error(f"Google Sheets(gviz) ë¡œë“œ ì‹¤íŒ¨: {e}")
            st.info("â–¶ ì‹œíŠ¸ ê³µê°œ ìƒíƒœ(Anyone with the link), ì‹œíŠ¸ëª…(íƒ­ëª…), í—¤ë” 1í–‰ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        return pd.DataFrame()

# -------------------- Loaders --------------------
@st.cache_data(ttl=300)
def load_from_excel(file):
    data = file.read() if hasattr(file, "read") else file
    bio = BytesIO(data) if isinstance(data, (bytes, bytearray)) else file
    xl = pd.ExcelFile(bio, engine="openpyxl")

    if "SCM_í†µí•©" not in xl.sheet_names:
        st.error("ì—‘ì…€ì— 'SCM_í†µí•©' ì‹œíŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    df_move = pd.read_excel(bio, sheet_name="SCM_í†µí•©", engine="openpyxl")
    bio.seek(0)

    refined = next((s for s in xl.sheet_names if s in ["snap_ì •ì œ","snap_refined","snap_refine","snap_ref"]), None)
    if refined is None:
        st.error("ì—‘ì…€ì— 'snap_ì •ì œ' ì‹œíŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.stop()
    df_ref = pd.read_excel(bio, sheet_name=refined, engine="openpyxl")
    bio.seek(0)

    df_incoming = pd.read_excel(bio, sheet_name="ì…ê³ ì˜ˆì •ë‚´ì—­", engine="openpyxl") if "ì…ê³ ì˜ˆì •ë‚´ì—­" in xl.sheet_names else None
    bio.seek(0)

    df_snapraw = pd.read_excel(bio, sheet_name="snapshot_raw", engine="openpyxl") if "snapshot_raw" in xl.sheet_names else None
    if df_snapraw is not None and not df_snapraw.empty:
        st.session_state["snapshot_raw_df"] = df_snapraw
    else:
        st.session_state.pop("snapshot_raw_df", None)

    return df_move, df_ref, df_incoming, df_snapraw

@st.cache_data(ttl=300)
def normalize_refined_snapshot(df_ref: pd.DataFrame) -> pd.DataFrame:
    cols = {c.strip().lower(): c for c in df_ref.columns}
    date_col = next((cols[k] for k in ["date","ë‚ ì§œ","snapshot_date","ìŠ¤ëƒ…ìƒ·ì¼"] if k in cols), None)
    center_col = next((cols[k] for k in ["center","ì„¼í„°","ì°½ê³ ","warehouse"] if k in cols), None)
    sku_col = next((cols[k] for k in ["resource_code","sku","ìƒí’ˆì½”ë“œ","product_code"] if k in cols), None)
    qty_col = next((cols[k] for k in ["stock_qty","qty","ìˆ˜ëŸ‰","ì¬ê³ ","quantity"] if k in cols), None)
    missing = [n for n,v in {"date":date_col,"center":center_col,"resource_code":sku_col,"stock_qty":qty_col}.items() if not v]
    if missing:
        st.error(f"'snap_ì •ì œ' ì‹œíŠ¸ì— ëˆ„ë½ëœ ì»¬ëŸ¼: {missing}")
        st.stop()

    sr = df_ref.rename(columns={date_col:"date", center_col:"center", sku_col:"resource_code", qty_col:"stock_qty"}).copy()
    sr["date"] = pd.to_datetime(sr["date"], errors="coerce").dt.normalize()
    sr["center"] = sr["center"].astype(str)
    sr["resource_code"] = sr["resource_code"].astype(str)
    sr["stock_qty"] = pd.to_numeric(sr["stock_qty"], errors="coerce").fillna(0).astype(int)
    return sr.dropna(subset=["date","center","resource_code"])

def normalize_moves(df: pd.DataFrame) -> pd.DataFrame:
    df.columns = [str(c).strip() for c in df.columns]
    resource_code = _coalesce_columns(df, [["resource_code","ìƒí’ˆì½”ë“œ","RESOURCE_CODE","sku","SKU"]])
    qty_ea       = _coalesce_columns(df, [["qty_ea","QTY_EA","ìˆ˜ëŸ‰(EA)","qty","QTY","quantity","Quantity","ìˆ˜ëŸ‰","EA","ea"]])
    carrier_mode = _coalesce_columns(df, [["carrier_mode","ìš´ì†¡ë°©ë²•","carrier mode","ìš´ì†¡ìˆ˜ë‹¨"]])
    from_center  = _coalesce_columns(df, [["from_center","ì¶œë°œì°½ê³ ","from center"]])
    to_center    = _coalesce_columns(df, [["to_center","ë„ì°©ì°½ê³ ","to center"]])
    onboard_date = _coalesce_columns(df, [["onboard_date","ë°°ì •ì¼","ì¶œë°œì¼","H","onboard","depart_date"]], parse_date=True)
    arrival_date = _coalesce_columns(df, [["arrival_date","ë„ì°©ì¼","eta_date","ETA","arrival"]], parse_date=True)
    inbound_date = _coalesce_columns(df, [["inbound_date","ì…ê³ ì¼","ì…ê³ ì™„ë£Œì¼"]], parse_date=True)
    real_depart  = _coalesce_columns(df, [["ì‹¤ì œ ì„ ì ì¼","real_departure","AI"]], parse_date=True)
    out = pd.DataFrame({
        "resource_code": resource_code.astype(str).str.strip(),
        "qty_ea": pd.to_numeric(qty_ea.astype(str).str.replace(',',''), errors="coerce").fillna(0).astype(int),
        "carrier_mode": carrier_mode.astype(str).str.strip(),
        "from_center": from_center.astype(str).str.strip(),
        "to_center": to_center.astype(str).str.strip(),
        "onboard_date": onboard_date,
        "arrival_date": arrival_date,
        "inbound_date": inbound_date,
        "real_departure": real_depart,
    })
    out["event_date"] = out["inbound_date"].where(out["inbound_date"].notna(), out["arrival_date"])
    return out

def _parse_po_date(po_str: str) -> pd.Timestamp:
    if not isinstance(po_str, str): return pd.NaT
    m = re.search(r"[A-Za-z](\d{2})(\d{2})(\d{2})", po_str)
    if not m: return pd.NaT
    yy, mm, dd = m.groups()
    try:
        return pd.Timestamp(datetime(2000+int(yy), int(mm), int(dd)))
    except Exception:
        return pd.NaT

def load_wip_from_incoming(df_incoming: Optional[pd.DataFrame], default_center: str = "íƒœê´‘KR") -> pd.DataFrame:
    if df_incoming is None or df_incoming.empty:
        return pd.DataFrame()
    df_incoming.columns = [str(c).strip().lower() for c in df_incoming.columns]
    po_col   = next((c for c in df_incoming.columns if c in ["po_no","ponumber","po"]), None)
    date_col = next((c for c in df_incoming.columns if "intended_push_date" in c or "ì…ê³ " in c), None)
    sku_col  = next((c for c in df_incoming.columns if c in ["product_code","resource_code","ìƒí’ˆì½”ë“œ"]), None)
    qty_col  = next((c for c in df_incoming.columns if c in ["quantity","qty","ìˆ˜ëŸ‰","total_quantity"]), None)
    lot_col  = next((c for c in df_incoming.columns if c in ["lot","ì œì¡°ë²ˆí˜¸","lot_no","lotnumber"]), None)
    if not date_col or not sku_col or not qty_col:
        return pd.DataFrame()
    out = pd.DataFrame({
        "resource_code": df_incoming[sku_col].astype(str).str.strip(),
        "to_center": default_center,
        "wip_ready": pd.to_datetime(df_incoming[date_col], errors="coerce"),
        "qty_ea": pd.to_numeric(df_incoming[qty_col].astype(str).str.replace(',',''), errors="coerce").fillna(0).astype(int),
        "lot": df_incoming[lot_col].astype(str).str.strip() if lot_col else ""
    })
    out["wip_start"] = df_incoming[po_col].map(_parse_po_date) if po_col else pd.NaT
    m = out["wip_start"].isna() & out["wip_ready"].notna()
    out.loc[m, "wip_start"] = out.loc[m, "wip_ready"] - pd.to_timedelta(30, unit="D")
    return out.dropna(subset=["resource_code","wip_ready","wip_start"])[["resource_code","to_center","wip_start","wip_ready","qty_ea","lot"]]

def merge_wip_as_moves(moves_df: pd.DataFrame, wip_df: Optional[pd.DataFrame]) -> pd.DataFrame:
    if wip_df is None or wip_df.empty:
        return moves_df
    wip_moves = pd.DataFrame({
        "resource_code": wip_df["resource_code"],
        "qty_ea": wip_df["qty_ea"].astype(int),
        "carrier_mode": "WIP",
        "from_center": "WIP",
        "to_center": wip_df["to_center"],
        "onboard_date": wip_df["wip_start"],
        "arrival_date": wip_df["wip_ready"],
        "inbound_date": pd.NaT,
        "real_departure": pd.NaT,
        "event_date": wip_df["wip_ready"],
        "lot": wip_df.get("lot", "")
    })
    return pd.concat([moves_df, wip_moves], ignore_index=True)

# ===== ì´í›„ Timeline, Forecast, KPI, ì°¨íŠ¸, ì…ê³  ì˜ˆì • ë‚´ì—­, ì¬ê³ ìì‚°, LOT ìƒì„¸ ì„¹ì…˜ì€ ë™ì¼í•˜ê²Œ ì´ì–´ì§‘ë‹ˆë‹¤ =====
# (ë‹µë³€ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì—¬ê¸°ì„œ ëŠì§€ë§Œ, ì œê°€ ì´ì „ ë©”ì‹œì§€ì— ë“œë¦° `dashboard_v4_clean.py` ì „ì²´ ì½”ë“œ ë¸”ë¡ê³¼ ì™„ì „íˆ ë™ì¼í•©ë‹ˆë‹¤.)
