"""
AI ì±—ë´‡ ë‹¨ìˆœ ë²„ì „: ë²¡í„° ê²€ìƒ‰ ì—†ì´ ì§ì ‘ ë°ì´í„° ì „ë‹¬
- ë³µì¡ë„ ì œê±°: Chroma, ì„ë² ë”©, ì„¸ì…˜ ê´€ë¦¬ ì—†ìŒ
- ê°„ë‹¨í•œ ì ‘ê·¼: í•„í„°ë§ëœ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ â†’ Geminiì— ì „ë‹¬
- 10ë¶„ êµ¬í˜„ ëª©í‘œ
"""

import streamlit as st
import pandas as pd
import google.generativeai as genai
import plotly.express as px
import plotly.graph_objects as go


def prepare_data_context(
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame = None,
    timeline_df: pd.DataFrame = None,
    max_rows: int = 50
) -> str:
    """
    ë°ì´í„°í”„ë ˆì„ì„ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

    Args:
        snapshot_df: í•„í„°ë§ëœ ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        moves_df: íŒë§¤/ì…ê³  ì´ë™ ë°ì´í„° (ì˜µì…˜)
        timeline_df: 30ì¼ ì‹œê³„ì—´ + ì˜ˆì¸¡ ë°ì´í„° (ì˜µì…˜)
        max_rows: ìµœëŒ€ í¬í•¨í•  í–‰ ìˆ˜ (í† í° ì œí•œ ê³ ë ¤)

    Returns:
        í…ìŠ¤íŠ¸ í˜•íƒœì˜ ë°ì´í„° ìš”ì•½
    """
    if snapshot_df.empty:
        return "ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."

    df = snapshot_df

    # ìµœì‹  ë‚ ì§œë§Œ ìœ ì§€
    if "date" in df.columns:
        df = df.copy()
        df["date"] = pd.to_datetime(df["date"], errors="coerce")
        df = df.sort_values("date").groupby(["center", "resource_code"], as_index=False).last()

    # ìƒìœ„ Nê°œ í–‰ë§Œ ì‚¬ìš© (í† í° ì œí•œ)
    sample = df.head(max_rows)

    # ìš”ì•½ í†µê³„
    stats = f"""
ğŸ“Š ë°ì´í„° ìš”ì•½:
- ì´ ì¬ê³ : {df['stock_qty'].sum():,.0f}ê°œ
- ì„¼í„° ìˆ˜: {df['center'].nunique()}ê³³
- SKU ìˆ˜: {df['resource_code'].nunique()}ê°œ
- ìµœì‹  ë‚ ì§œ: {df['date'].max().strftime('%Y-%m-%d') if 'date' in df.columns else 'N/A'}

ì„¼í„°ë³„ ì¬ê³ :
"""
    for center, group in df.groupby("center")["stock_qty"].sum().items():
        stats += f"- {center}: {group:,.0f}ê°œ\n"

    # ìƒìœ„ SKU
    stats += f"\nìƒìœ„ SKU (ì¬ê³ ëŸ‰):\n"
    for sku, qty in df.groupby("resource_code")["stock_qty"].sum().nlargest(10).items():
        stats += f"- {sku}: {qty:,.0f}ê°œ\n"

    # íŒë§¤/ì…ê³  ë°ì´í„° ì¶”ê°€!
    if moves_df is not None and not moves_df.empty:
        stats += f"\nğŸ“¦ íŒë§¤/ì…ê³  ë°ì´í„° (ìµœê·¼ 30ì¼):\n"

        # ìµœê·¼ 30ì¼ í•„í„°
        if "date" in moves_df.columns:
            moves_recent = moves_df.copy()
            moves_recent["date"] = pd.to_datetime(moves_recent["date"], errors="coerce")
            cutoff_date = moves_recent["date"].max() - pd.Timedelta(days=30)
            moves_recent = moves_recent[moves_recent["date"] >= cutoff_date]

            # ì„¼í„°/SKU í•„í„° (ì„ íƒëœ ê²ƒë§Œ)
            if "center" in moves_recent.columns and "center" in df.columns:
                centers_in_snapshot = df["center"].unique()
                moves_recent = moves_recent[moves_recent["center"].isin(centers_in_snapshot)]
            if "resource_code" in moves_recent.columns:
                skus_in_snapshot = df["resource_code"].unique()
                moves_recent = moves_recent[moves_recent["resource_code"].isin(skus_in_snapshot)]

            # íŒë§¤/ì…ê³  ì§‘ê³„ (30ì¼ ì „ì²´)
            if "quantity" in moves_recent.columns:
                stats += "ì „ì²´ ì§‘ê³„ (30ì¼):\n"
                # move_typeë³„ ì§‘ê³„
                if "move_type" in moves_recent.columns:
                    for move_type, group in moves_recent.groupby("move_type")["quantity"].sum().items():
                        stats += f"- {move_type}: {group:,.0f}ê°œ\n"

                # SKUë³„ íŒë§¤ëŸ‰
                stats += f"\nSKUë³„ ì´ë™ëŸ‰ (ìƒìœ„ 5ê°œ):\n"
                sku_moves = moves_recent.groupby("resource_code")["quantity"].sum().nlargest(5)
                for sku, qty in sku_moves.items():
                    stats += f"- {sku}: {qty:,.0f}ê°œ\n"

                # ìµœê·¼ 7ì¼ ì¼ë³„ ìƒì„¸ ë°ì´í„° ì¶”ê°€!
                latest_date = moves_recent["date"].max()
                moves_last_7days = moves_recent[moves_recent["date"] >= latest_date - pd.Timedelta(days=7)]

                if not moves_last_7days.empty:
                    stats += f"\nğŸ“… ìµœê·¼ 7ì¼ ì¼ë³„ ìƒì„¸ (ìƒìœ„ 3ê°œ SKU):\n"

                    # ìƒìœ„ 3ê°œ SKUë§Œ
                    top_skus = moves_recent.groupby("resource_code")["quantity"].sum().nlargest(3).index

                    for sku in top_skus:
                        sku_data = moves_last_7days[moves_last_7days["resource_code"] == sku]
                        if not sku_data.empty:
                            stats += f"\n{sku}:\n"

                            # ë‚ ì§œë³„ë¡œ ì •ë ¬
                            sku_data_sorted = sku_data.sort_values("date", ascending=False)

                            # ë‚ ì§œë³„ + move_typeë³„ë¡œ ê·¸ë£¹í™”
                            for date, date_group in sku_data_sorted.groupby("date"):
                                # NaT ì²´í¬
                                if pd.isna(date):
                                    continue

                                date_str = date.strftime('%Y-%m-%d')

                                # ì„¼í„°ë³„/íƒ€ì…ë³„ ì„¸ë¶„í™”
                                for idx, row in date_group.iterrows():
                                    center = row.get("center", "N/A")
                                    move_type = row.get("move_type", "N/A")
                                    qty = row.get("quantity", 0)
                                    stats += f"  Â· {date_str} | {center} | {move_type}: {qty:,.0f}ê°œ\n"

    # 30ì¼ ì‹œê³„ì—´ + ì˜ˆì¸¡ ë°ì´í„° ì¶”ê°€!
    if timeline_df is not None and not timeline_df.empty:
        stats += f"\nğŸ“ˆ ì¬ê³  ì¶”ì„¸ ë° ì˜ˆì¸¡ ë°ì´í„°:\n"

        timeline = timeline_df.copy()
        if "date" in timeline.columns:
            timeline["date"] = pd.to_datetime(timeline["date"], errors="coerce")
            timeline = timeline.sort_values("date")

            # ì‹¤ì œ ë°ì´í„°ì™€ ì˜ˆì¸¡ ë°ì´í„° êµ¬ë¶„
            if "is_forecast" in timeline.columns:
                actual_data = timeline[timeline["is_forecast"] == False]
                forecast_data = timeline[timeline["is_forecast"] == True]

                if not actual_data.empty:
                    actual_min = actual_data["date"].min()
                    actual_max = actual_data["date"].max()
                    if pd.notna(actual_min) and pd.notna(actual_max):
                        actual_min_str = actual_min.strftime('%Y-%m-%d')
                        actual_max_str = actual_max.strftime('%Y-%m-%d')
                        stats += f"- ğŸ“Š ì‹¤ì œ ë°ì´í„° ê¸°ê°„: {actual_min_str} ~ {actual_max_str}\n"

                if not forecast_data.empty:
                    forecast_min = forecast_data["date"].min()
                    forecast_max = forecast_data["date"].max()
                    if pd.notna(forecast_min) and pd.notna(forecast_max):
                        forecast_min_str = forecast_min.strftime('%Y-%m-%d')
                        forecast_max_str = forecast_max.strftime('%Y-%m-%d')
                        stats += f"- ğŸ”® ì˜ˆì¸¡ ë°ì´í„° ê¸°ê°„: {forecast_min_str} ~ {forecast_max_str}\n"
            else:
                # is_forecast ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ ë²”ìœ„ë§Œ í‘œì‹œ
                date_min = timeline["date"].min().strftime('%Y-%m-%d') if pd.notna(timeline["date"].min()) else 'N/A'
                date_max = timeline["date"].max().strftime('%Y-%m-%d') if pd.notna(timeline["date"].max()) else 'N/A'
                stats += f"- ì „ì²´ ê¸°ê°„: {date_min} ~ {date_max}\n"

            # ì„¼í„°/SKU í•„í„° (ì„ íƒëœ ê²ƒë§Œ)
            if "center" in timeline.columns and "center" in df.columns:
                centers_in_snapshot = df["center"].unique()
                timeline = timeline[timeline["center"].isin(centers_in_snapshot)]
            if "resource_code" in timeline.columns:
                skus_in_snapshot = df["resource_code"].unique()
                timeline = timeline[timeline["resource_code"].isin(skus_in_snapshot)]

            # SKUë³„ ì‹¤ì œ ì¶”ì„¸ ë¶„ì„ (ìƒìœ„ 5ê°œ)
            if "resource_code" in timeline.columns and "stock_qty" in timeline.columns:
                # ì‹¤ì œ ë°ì´í„°ë§Œ ì‚¬ìš©í•´ì„œ ì¶”ì„¸ ê³„ì‚°
                if "is_forecast" in timeline.columns:
                    actual_timeline = timeline[timeline["is_forecast"] == False]
                else:
                    actual_timeline = timeline

                if not actual_timeline.empty:
                    stats += f"\nğŸ“Š ì‹¤ì œ ì¬ê³  ì¶”ì„¸ (ìƒìœ„ 5ê°œ SKU):\n"

                    # ê° SKUì˜ ì‹¤ì œ ì¶”ì„¸ ê³„ì‚°
                    for sku in skus_in_snapshot[:5]:  # ìƒìœ„ 5ê°œë§Œ
                        sku_timeline = actual_timeline[actual_timeline["resource_code"] == sku].sort_values("date")
                        if len(sku_timeline) >= 2:
                            # ìµœì‹  vs ìµœì´ˆ
                            first_qty = sku_timeline.iloc[0]["stock_qty"]
                            last_qty = sku_timeline.iloc[-1]["stock_qty"]
                            change = last_qty - first_qty
                            trend = "â†—ï¸ ì¦ê°€" if change > 0 else "â†˜ï¸ ê°ì†Œ" if change < 0 else "â†’ ìœ ì§€"

                            # í‰ê·  ì¬ê³ 
                            avg_qty = sku_timeline["stock_qty"].mean()

                            stats += f"- {sku}: {first_qty:,.0f}ê°œ â†’ {last_qty:,.0f}ê°œ ({trend}, í‰ê·  {avg_qty:,.0f}ê°œ)\n"

            # SKUë³„ ì˜ˆì¸¡ ì •ë³´
            if "is_forecast" in timeline.columns:
                forecast_data = timeline[timeline["is_forecast"] == True]
                if not forecast_data.empty and "resource_code" in forecast_data.columns:
                    stats += f"\nğŸ”® SKUë³„ ì˜ˆì¸¡ ì¬ê³  (ìƒìœ„ 3ê°œ):\n"

                    # SKUë³„ ìµœì¢… ì˜ˆì¸¡ê°’
                    for sku in skus_in_snapshot[:3]:
                        sku_forecast = forecast_data[forecast_data["resource_code"] == sku]
                        if not sku_forecast.empty:
                            final_forecast = sku_forecast.iloc[-1]["stock_qty"]
                            final_date_val = sku_forecast.iloc[-1]["date"]
                            if pd.notna(final_date_val):
                                final_date = final_date_val.strftime('%Y-%m-%d')
                                stats += f"- {sku}: {final_forecast:,.0f}ê°œ (ì˜ˆì¸¡ì¼: {final_date})\n"

    # ìƒ˜í”Œ ë°ì´í„° (ìƒìœ„ Nê°œ)
    stats += f"\nğŸ“‹ ì¬ê³  ìƒì„¸ ë°ì´í„° (ìƒìœ„ {min(max_rows, len(df))}ê°œ):\n"
    for idx, row in sample.iterrows():
        stats += (
            f"  Â· {row.get('center', 'N/A')} | "
            f"{row.get('resource_code', 'N/A')} | "
            f"ì¬ê³ : {row.get('stock_qty', 0):,.0f}ê°œ"
        )
        if pd.notna(row.get('resource_name')):
            stats += f" ({row.get('resource_name')})"
        stats += "\n"

    if len(df) > max_rows:
        stats += f"\n... ì™¸ {len(df) - max_rows}ê°œ í•­ëª©\n"

    return stats


def detect_stockout_risks(
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame,
    timeline_df: pd.DataFrame = None,
    days_threshold: int = 7
) -> list[dict]:
    """
    í’ˆì ˆ ì„ë°• SKU ê°ì§€

    Args:
        snapshot_df: í˜„ì¬ ì¬ê³  ë°ì´í„°
        moves_df: íŒë§¤ ë°ì´í„°
        timeline_df: ì˜ˆì¸¡ ë°ì´í„° (ì˜µì…˜)
        days_threshold: í’ˆì ˆ ì„ë°• ê¸°ì¤€ (ì¼)

    Returns:
        í’ˆì ˆ ì„ë°• SKU ë¦¬ìŠ¤íŠ¸
    """
    risks = []

    if snapshot_df.empty or moves_df is None or moves_df.empty:
        return risks

    try:
        # ìµœê·¼ 7ì¼ í‰ê·  íŒë§¤ëŸ‰ ê³„ì‚°
        moves_recent = moves_df.copy()
        if "date" in moves_recent.columns:
            moves_recent["date"] = pd.to_datetime(moves_recent["date"], errors="coerce")
            cutoff_date = moves_recent["date"].max() - pd.Timedelta(days=7)
            moves_recent = moves_recent[moves_recent["date"] >= cutoff_date]

            # íŒë§¤ë§Œ í•„í„° (CustomerShipment ë“±)
            if "move_type" in moves_recent.columns:
                sales_types = ["CustomerShipment", "ì¶œê³ ", "íŒë§¤"]
                moves_recent = moves_recent[moves_recent["move_type"].isin(sales_types)]

            # SKUë³„ ì¼í‰ê·  íŒë§¤ëŸ‰
            if "resource_code" in moves_recent.columns and "quantity" in moves_recent.columns:
                daily_sales = moves_recent.groupby("resource_code")["quantity"].sum() / 7

                # í˜„ì¬ ì¬ê³ ì™€ ë¹„êµ
                for sku in daily_sales.index:
                    if daily_sales[sku] <= 0:
                        continue

                    current_stock = snapshot_df[snapshot_df["resource_code"] == sku]["stock_qty"].sum()
                    days_left = current_stock / daily_sales[sku]

                    if 0 < days_left <= days_threshold:
                        risks.append({
                            "sku": sku,
                            "current_stock": current_stock,
                            "daily_sales": daily_sales[sku],
                            "days_left": days_left,
                            "severity": "high" if days_left <= 3 else "medium"
                        })

        # ì‹¬ê°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        risks.sort(key=lambda x: x["days_left"])

    except Exception as e:
        st.warning(f"í’ˆì ˆ ìœ„í—˜ ê°ì§€ ì˜¤ë¥˜: {e}")

    return risks[:5]  # ìƒìœ„ 5ê°œë§Œ


def detect_anomalies(
    snapshot_df: pd.DataFrame,
    timeline_df: pd.DataFrame = None,
    threshold: float = 0.5
) -> list[dict]:
    """
    ì¬ê³  ì´ìƒì¹˜ ê°ì§€ (ê¸‰ì¦/ê¸‰ê°)

    Args:
        snapshot_df: í˜„ì¬ ì¬ê³ 
        timeline_df: ì‹œê³„ì—´ ë°ì´í„°
        threshold: ë³€í™”ìœ¨ ì„ê³„ê°’ (50% = 0.5)

    Returns:
        ì´ìƒì¹˜ SKU ë¦¬ìŠ¤íŠ¸
    """
    anomalies = []

    if timeline_df is None or timeline_df.empty:
        return anomalies

    try:
        timeline = timeline_df.copy()
        if "date" in timeline.columns and "resource_code" in timeline.columns:
            timeline["date"] = pd.to_datetime(timeline["date"], errors="coerce")

            # ì‹¤ì œ ë°ì´í„°ë§Œ
            if "is_forecast" in timeline.columns:
                timeline = timeline[timeline["is_forecast"] == False]

            # SKUë³„ ìµœê·¼ 7ì¼ vs ì´ì „ 7ì¼ ë¹„êµ
            latest_date = timeline["date"].max()
            recent_7days = timeline[timeline["date"] >= latest_date - pd.Timedelta(days=7)]
            prev_7days = timeline[
                (timeline["date"] >= latest_date - pd.Timedelta(days=14)) &
                (timeline["date"] < latest_date - pd.Timedelta(days=7))
            ]

            for sku in timeline["resource_code"].unique():
                recent_avg = recent_7days[recent_7days["resource_code"] == sku]["stock_qty"].mean()
                prev_avg = prev_7days[prev_7days["resource_code"] == sku]["stock_qty"].mean()

                if pd.notna(recent_avg) and pd.notna(prev_avg) and prev_avg > 0:
                    change_rate = (recent_avg - prev_avg) / prev_avg

                    if abs(change_rate) >= threshold:
                        anomalies.append({
                            "sku": sku,
                            "recent_avg": recent_avg,
                            "prev_avg": prev_avg,
                            "change_rate": change_rate,
                            "type": "ê¸‰ì¦" if change_rate > 0 else "ê¸‰ê°"
                        })

            # ë³€í™”ìœ¨ ì ˆëŒ“ê°’ ìˆœìœ¼ë¡œ ì •ë ¬
            anomalies.sort(key=lambda x: abs(x["change_rate"]), reverse=True)

    except Exception as e:
        st.warning(f"ì´ìƒì¹˜ ê°ì§€ ì˜¤ë¥˜: {e}")

    return anomalies[:3]  # ìƒìœ„ 3ê°œë§Œ


def check_data_quality(
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame = None,
    timeline_df: pd.DataFrame = None
) -> list[dict]:
    """
    ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ê°ì§€

    Returns:
        í’ˆì§ˆ ì´ìŠˆ ë¦¬ìŠ¤íŠ¸
    """
    issues = []

    try:
        # 1. ìŒìˆ˜ ì¬ê³  ì²´í¬
        if "stock_qty" in snapshot_df.columns:
            negative_stock = snapshot_df[snapshot_df["stock_qty"] < 0]
            if not negative_stock.empty:
                issues.append({
                    "type": "negative_stock",
                    "severity": "high",
                    "message": f"âš ï¸ ìŒìˆ˜ ì¬ê³  ë°œê²¬: {len(negative_stock)}ê°œ SKU",
                    "details": negative_stock[["resource_code", "center", "stock_qty"]].head(3).to_dict("records")
                })

        # 2. ë‚ ì§œ ëˆ„ë½ ì²´í¬ (moves_df)
        if moves_df is not None and not moves_df.empty and "date" in moves_df.columns:
            moves_df_copy = moves_df.copy()
            moves_df_copy["date"] = pd.to_datetime(moves_df_copy["date"], errors="coerce")
            null_dates = moves_df_copy["date"].isna().sum()
            if null_dates > 0:
                issues.append({
                    "type": "missing_dates",
                    "severity": "medium",
                    "message": f"âš ï¸ íŒë§¤ ë°ì´í„° ë‚ ì§œ ëˆ„ë½: {null_dates}ê±´",
                    "details": None
                })

        # 3. ìµœì‹  ë°ì´í„° í™•ì¸
        if "date" in snapshot_df.columns:
            snapshot_df_copy = snapshot_df.copy()
            snapshot_df_copy["date"] = pd.to_datetime(snapshot_df_copy["date"], errors="coerce")
            latest_date = snapshot_df_copy["date"].max()
            if pd.notna(latest_date):
                from datetime import datetime, timedelta
                days_old = (datetime.now() - latest_date).days
                if days_old > 1:
                    issues.append({
                        "type": "stale_data",
                        "severity": "low",
                        "message": f"â„¹ï¸ ì¬ê³  ë°ì´í„°ê°€ {days_old}ì¼ ì „ì…ë‹ˆë‹¤ (ìµœì‹ : {latest_date.strftime('%Y-%m-%d')})",
                        "details": None
                    })

    except Exception as e:
        st.warning(f"ë°ì´í„° í’ˆì§ˆ ì²´í¬ ì˜¤ë¥˜: {e}")

    return issues


def render_proactive_insights(
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame,
    timeline_df: pd.DataFrame
):
    """
    í”„ë¡œì•¡í‹°ë¸Œ ì¸ì‚¬ì´íŠ¸ UI ë Œë”ë§
    """
    # ì¸ì‚¬ì´íŠ¸ ê°ì§€
    stockout_risks = detect_stockout_risks(snapshot_df, moves_df, timeline_df)
    anomalies = detect_anomalies(snapshot_df, timeline_df)
    quality_issues = check_data_quality(snapshot_df, moves_df, timeline_df)

    # ì¸ì‚¬ì´íŠ¸ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ í‘œì‹œ
    if stockout_risks or anomalies or quality_issues:
        with st.expander("ğŸ”” ì£¼ëª©í•  ì´ìŠˆ", expanded=True):
            col1, col2, col3 = st.columns(3)

            # í’ˆì ˆ ìœ„í—˜
            with col1:
                if stockout_risks:
                    st.markdown("**âš ï¸ í’ˆì ˆ ì„ë°•**")
                    for risk in stockout_risks[:3]:
                        severity_icon = "ğŸ”´" if risk["severity"] == "high" else "ğŸŸ¡"
                        st.caption(
                            f"{severity_icon} {risk['sku']}: "
                            f"{risk['days_left']:.1f}ì¼ ë‚¨ìŒ "
                            f"(ì¬ê³  {risk['current_stock']:.0f}ê°œ)"
                        )

            # ì´ìƒì¹˜
            with col2:
                if anomalies:
                    st.markdown("**ğŸ“Š ê¸‰ê²©í•œ ë³€í™”**")
                    for anomaly in anomalies[:3]:
                        icon = "ğŸ“ˆ" if anomaly["type"] == "ê¸‰ì¦" else "ğŸ“‰"
                        st.caption(
                            f"{icon} {anomaly['sku']}: "
                            f"{anomaly['type']} {abs(anomaly['change_rate'])*100:.0f}% "
                            f"({anomaly['prev_avg']:.0f}â†’{anomaly['recent_avg']:.0f})"
                        )

            # ë°ì´í„° í’ˆì§ˆ
            with col3:
                if quality_issues:
                    st.markdown("**ğŸ” ë°ì´í„° ì´ìŠˆ**")
                    for issue in quality_issues[:3]:
                        st.caption(issue["message"])


def calculate_kpi(
    function_name: str,
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame = None,
    **kwargs
) -> dict:
    """
    KPI ê³„ì‚° í•¨ìˆ˜ (Function callingìš©)

    Args:
        function_name: í˜¸ì¶œí•  í•¨ìˆ˜ ì´ë¦„
        snapshot_df: ì¬ê³  ë°ì´í„°
        moves_df: íŒë§¤ ë°ì´í„°
        **kwargs: ì¶”ê°€ íŒŒë¼ë¯¸í„°

    Returns:
        ê³„ì‚° ê²°ê³¼ dict
    """
    try:
        if function_name == "calculate_total_stock":
            total = snapshot_df["stock_qty"].sum()
            return {"total_stock": float(total), "unit": "ê°œ"}

        elif function_name == "get_stock_by_center":
            center_stock = snapshot_df.groupby("center")["stock_qty"].sum().to_dict()
            return {"center_stock": {k: float(v) for k, v in center_stock.items()}, "unit": "ê°œ"}

        elif function_name == "get_stock_by_sku":
            sku = kwargs.get("sku")
            if sku:
                sku_data = snapshot_df[snapshot_df["resource_code"] == sku]
                if not sku_data.empty:
                    total = sku_data["stock_qty"].sum()
                    by_center = sku_data.groupby("center")["stock_qty"].sum().to_dict()
                    return {
                        "sku": sku,
                        "total_stock": float(total),
                        "by_center": {k: float(v) for k, v in by_center.items()},
                        "unit": "ê°œ"
                    }
            return {"error": "SKU not found"}

        elif function_name == "calculate_stockout_days":
            sku = kwargs.get("sku")
            if sku and moves_df is not None:
                # ìµœê·¼ 7ì¼ í‰ê·  íŒë§¤ëŸ‰
                moves_recent = moves_df.copy()
                moves_recent["date"] = pd.to_datetime(moves_recent["date"], errors="coerce")
                cutoff_date = moves_recent["date"].max() - pd.Timedelta(days=7)
                moves_recent = moves_recent[
                    (moves_recent["date"] >= cutoff_date) &
                    (moves_recent["resource_code"] == sku)
                ]

                if not moves_recent.empty:
                    daily_sales = moves_recent["quantity"].sum() / 7
                    current_stock = snapshot_df[snapshot_df["resource_code"] == sku]["stock_qty"].sum()

                    if daily_sales > 0:
                        days_left = current_stock / daily_sales
                        return {
                            "sku": sku,
                            "current_stock": float(current_stock),
                            "daily_sales_avg": float(daily_sales),
                            "days_until_stockout": float(days_left),
                            "status": "urgent" if days_left < 3 else "warning" if days_left < 7 else "ok"
                        }

            return {"error": "Cannot calculate stockout days"}

        elif function_name == "get_top_selling_skus":
            limit = kwargs.get("limit", 5)
            if moves_df is not None:
                moves_recent = moves_df.copy()
                moves_recent["date"] = pd.to_datetime(moves_recent["date"], errors="coerce")
                cutoff_date = moves_recent["date"].max() - pd.Timedelta(days=30)
                moves_recent = moves_recent[moves_recent["date"] >= cutoff_date]

                top_skus = moves_recent.groupby("resource_code")["quantity"].sum().nlargest(limit)
                return {
                    "top_skus": {k: float(v) for k, v in top_skus.items()},
                    "period": "last_30_days",
                    "unit": "ê°œ"
                }

            return {"error": "No sales data available"}

    except Exception as e:
        return {"error": str(e)}

    return {"error": "Unknown function"}


def detect_kpi_need(question: str) -> tuple[bool, str, dict]:
    """
    ì§ˆë¬¸ì—ì„œ KPI ê³„ì‚° í•„ìš” ì—¬ë¶€ ê°ì§€

    Returns:
        (need_kpi, function_name, kwargs)
    """
    question_lower = question.lower()

    # ì´ ì¬ê³ 
    if "ì´ ì¬ê³ " in question_lower or "ì „ì²´ ì¬ê³ " in question_lower:
        return (True, "calculate_total_stock", {})

    # ì„¼í„°ë³„ ì¬ê³ 
    if ("ì„¼í„°ë³„" in question_lower or "center" in question_lower) and "ì¬ê³ " in question_lower:
        return (True, "get_stock_by_center", {})

    # SKUë³„ ì¬ê³ 
    import re
    sku_pattern = r'\b[A-Z]{2}\d{5}\b'
    skus = re.findall(sku_pattern, question)
    if skus and "ì¬ê³ " in question_lower:
        return (True, "get_stock_by_sku", {"sku": skus[0]})

    # í’ˆì ˆ ì„ë°•
    if skus and ("í’ˆì ˆ" in question_lower or "ì†Œì§„" in question_lower or "ë‚¨ì€" in question_lower):
        return (True, "calculate_stockout_days", {"sku": skus[0]})

    # ìƒìœ„ íŒë§¤
    if "ìƒìœ„" in question_lower and ("íŒë§¤" in question_lower or "íŒë§¤ëŸ‰" in question_lower):
        return (True, "get_top_selling_skus", {"limit": 5})

    return (False, None, {})


def ask_ai(question: str, data_context: str, snapshot_df: pd.DataFrame = None, moves_df: pd.DataFrame = None) -> str:
    """
    Geminiì—ê²Œ ì§ˆë¬¸í•˜ê¸° (Function calling í†µí•©)

    Args:
        question: ì‚¬ìš©ì ì§ˆë¬¸
        data_context: ë°ì´í„° ì»¨í…ìŠ¤íŠ¸
        snapshot_df: ì¬ê³  ë°ì´í„° (KPI ê³„ì‚°ìš©)
        moves_df: íŒë§¤ ë°ì´í„° (KPI ê³„ì‚°ìš©)

    Returns:
        AI ë‹µë³€
    """
    try:
        from datetime import datetime
        today = datetime.now().strftime('%Y-%m-%d')

        # 1. KPI ê³„ì‚° í•„ìš” ì—¬ë¶€ ê°ì§€
        need_kpi, func_name, kwargs = detect_kpi_need(question)

        kpi_result = None
        if need_kpi and snapshot_df is not None:
            kpi_result = calculate_kpi(func_name, snapshot_df, moves_df, **kwargs)

        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        # Gemini 2.0 ëª¨ë¸ ì‚¬ìš© (ìµœì‹  ë²„ì „)
        model = genai.GenerativeModel("gemini-2.0-flash-exp")

        # 2. KPI ê²°ê³¼ê°€ ìˆìœ¼ë©´ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        kpi_section = ""
        if kpi_result:
            import json
            kpi_section = f"""

[ì •í™•í•œ ê³„ì‚° ê²°ê³¼]
{json.dumps(kpi_result, ensure_ascii=False, indent=2)}

**ì¤‘ìš”:** ìœ„ ê³„ì‚° ê²°ê³¼ëŠ” ì½”ë“œë¡œ ì •í™•í•˜ê²Œ ê³„ì‚°ëœ ê°’ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì´ ìˆ«ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."""

        prompt = f"""ë‹¹ì‹ ì€ SCM ì¬ê³  ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

**í˜„ì¬ ë‚ ì§œ: {today}**

ì•„ë˜ ì¬ê³  ë°ì´í„°ë¥¼ ì°¸ê³ í•´ì„œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.

[ì¬ê³  ë°ì´í„°]
{data_context}{kpi_section}

[ì‚¬ìš©ì ì§ˆë¬¸]
{question}

**ë‹µë³€ ê·œì¹™:**
1. [ì •í™•í•œ ê³„ì‚° ê²°ê³¼]ê°€ ìˆìœ¼ë©´ ë°˜ë“œì‹œ ê·¸ ìˆ«ìë¥¼ ì‚¬ìš©í•˜ì„¸ìš” (í…ìŠ¤íŠ¸ ë°ì´í„° ëŒ€ì‹ )
2. ìˆ«ìëŠ” ì‰¼í‘œë¡œ í¬ë§·íŒ…í•˜ì„¸ìš” (ì˜ˆ: 1,234ê°œ)
3. 2-4ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
4. ë°ì´í„°ì— ì—†ëŠ” ë‚´ìš©ì€ "ë°ì´í„°ì—ì„œ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µë³€í•˜ì„¸ìš”
5. ë‚ ì§œë¥¼ ì–¸ê¸‰í•  ë•ŒëŠ” í˜„ì¬ ë‚ ì§œ({today})ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê³¼ê±°/ë¯¸ë˜ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì„¸ìš”
6. "ğŸ“Š ì‹¤ì œ ë°ì´í„° ê¸°ê°„"ì€ ê³¼ê±° ì‹¤ì œ ë°ì´í„°, "ğŸ”® ì˜ˆì¸¡ ë°ì´í„° ê¸°ê°„"ì€ ë¯¸ë˜ ì˜ˆì¸¡ ë°ì´í„°ì…ë‹ˆë‹¤
7. í•œêµ­ì–´ë¡œ ì‘ì„±í•˜ì„¸ìš”

ë‹µë³€:"""

        response = model.generate_content(prompt)
        return response.text

    except Exception as e:
        return f"âš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}\n\nì œê³µëœ ë°ì´í„°:\n{data_context}"


def suggest_followup_questions(question: str, answer: str, data_context: str) -> list[str]:
    """
    ë‹µë³€ì„ ê¸°ë°˜ìœ¼ë¡œ í›„ì† ì§ˆë¬¸ ì œì•ˆ

    Args:
        question: ì›ë˜ ì§ˆë¬¸
        answer: AI ë‹µë³€
        data_context: ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ (ê°„ëµ ë²„ì „)

    Returns:
        í›„ì† ì§ˆë¬¸ 3ê°œ
    """
    try:
        genai.configure(api_key=st.secrets["gemini"]["api_key"])
        model = genai.GenerativeModel("gemini-2.0-flash-exp")

        # ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ìš”ì•½ (í† í° ì ˆì•½)
        context_summary = data_context[:500] + "..." if len(data_context) > 500 else data_context

        prompt = f"""ë‹¹ì‹ ì€ SCM ì¬ê³  ê´€ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ë‹¤ìŒ ì§ˆë¬¸ì„ í–ˆê³ , ë‹µë³€ì„ ë°›ì•˜ìŠµë‹ˆë‹¤:

[ì§ˆë¬¸] {question}
[ë‹µë³€] {answer}

[ì´ìš© ê°€ëŠ¥í•œ ë°ì´í„°]
{context_summary}

ì´ì œ ì‚¬ìš©ìê°€ ê¶ê¸ˆí•´í•  ë§Œí•œ **í›„ì† ì§ˆë¬¸ 3ê°œ**ë¥¼ ì œì•ˆí•˜ì„¸ìš”.

**ê·œì¹™:**
1. ì›ë˜ ì§ˆë¬¸ê³¼ ê´€ë ¨ë˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ì§ˆë¬¸
2. ì œê³µëœ ë°ì´í„°ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ë§Œ ì œì•ˆ
3. ê° ì§ˆë¬¸ì€ 15ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
4. êµ¬ì²´ì ì¸ SKU/ì„¼í„°/ë‚ ì§œê°€ ìˆìœ¼ë©´ í¬í•¨
5. í•œ ì¤„ì— í•˜ë‚˜ì”©, ë²ˆí˜¸ ì—†ì´ ì‘ì„±

ì˜ˆì‹œ:
BA00021ì˜ íŒë§¤ ì¶”ì„¸ëŠ”?
ë‹¤ìŒì£¼ ì˜ˆìƒ ì¬ê³ ëŠ”?
ì–´ëŠ ì„¼í„°ê°€ ì¬ê³ ê°€ ë¶€ì¡±í•œê°€ìš”?

í›„ì† ì§ˆë¬¸:"""

        response = model.generate_content(prompt)
        questions = [q.strip() for q in response.text.strip().split('\n') if q.strip()]
        return questions[:3]  # ìƒìœ„ 3ê°œë§Œ

    except Exception as e:
        # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì§ˆë¬¸ ë°˜í™˜
        return [
            "ì„¼í„°ë³„ ì¬ê³  ë¶„í¬ëŠ”?",
            "ì¬ê³ ê°€ ë¶€ì¡±í•œ SKUëŠ”?",
            "ìµœê·¼ íŒë§¤ ì¶”ì„¸ëŠ”?"
        ]


def extract_entities_from_question(question: str, snapshot_df: pd.DataFrame, moves_df: pd.DataFrame = None) -> dict:
    """
    ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (SKU, ì„¼í„°, ë‚ ì§œ ë“±)

    Returns:
        {"skus": [list], "centers": [list], "date_range": tuple or None}
    """
    import re
    from datetime import datetime, timedelta

    entities = {
        "skus": [],
        "centers": [],
        "date_range": None
    }

    # 1. SKU ì¶”ì¶œ (BA00021 í˜•ì‹)
    sku_pattern = r'\b[A-Z]{2}\d{5}\b'
    found_skus = re.findall(sku_pattern, question)
    if found_skus and "resource_code" in snapshot_df.columns:
        # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” SKUë§Œ
        valid_skus = snapshot_df["resource_code"].unique()
        entities["skus"] = [sku for sku in found_skus if sku in valid_skus]

    # 2. ì„¼í„° ì¶”ì¶œ
    question_upper = question.upper()
    if "center" in snapshot_df.columns:
        all_centers = snapshot_df["center"].unique()
        for center in all_centers:
            if center in question_upper or center.lower() in question.lower():
                entities["centers"].append(center)

    # AMZUS, KR01 ë“± í”í•œ íŒ¨í„´
    center_patterns = [r'\bAMZUS\b', r'\bAMZKR\b', r'\bKR0[1-9]\b']
    for pattern in center_patterns:
        matches = re.findall(pattern, question_upper)
        entities["centers"].extend(matches)

    entities["centers"] = list(set(entities["centers"]))  # ì¤‘ë³µ ì œê±°

    # 3. ë‚ ì§œ ì¶”ì¶œ (ìƒëŒ€ì  í‘œí˜„)
    today = datetime.now()
    question_lower = question.lower()

    if "ì˜¤ëŠ˜" in question_lower:
        entities["date_range"] = (today, today)
    elif "ì–´ì œ" in question_lower:
        yesterday = today - timedelta(days=1)
        entities["date_range"] = (yesterday, yesterday)
    elif "ìµœê·¼ 7ì¼" in question_lower or "ì§€ë‚œ ì¼ì£¼ì¼" in question_lower:
        entities["date_range"] = (today - timedelta(days=7), today)
    elif "ìµœê·¼ 30ì¼" in question_lower or "ì§€ë‚œ í•œë‹¬" in question_lower:
        entities["date_range"] = (today - timedelta(days=30), today)
    elif "ì´ë²ˆì£¼" in question_lower:
        # ì´ë²ˆ ì£¼ ì›”ìš”ì¼ë¶€í„°
        weekday = today.weekday()
        monday = today - timedelta(days=weekday)
        entities["date_range"] = (monday, today)

    # ì ˆëŒ€ ë‚ ì§œ íŒ¨í„´ (YYYY-MM-DD)
    date_pattern = r'\d{4}-\d{2}-\d{2}'
    date_matches = re.findall(date_pattern, question)
    if date_matches:
        try:
            date_obj = datetime.strptime(date_matches[0], '%Y-%m-%d')
            entities["date_range"] = (date_obj, date_obj)
        except:
            pass

    return entities


def analyze_question_for_chart(question: str) -> dict:
    """
    ì§ˆë¬¸ì„ ë¶„ì„í•´ì„œ ì°¨íŠ¸ í•„ìš” ì—¬ë¶€ ë° íƒ€ì… íŒë‹¨

    Returns:
        {"need_chart": bool, "chart_type": str, "entities": dict}
    """
    question_lower = question.lower()

    # ì°¨íŠ¸ê°€ í•„ìš”í•œ í‚¤ì›Œë“œ
    chart_keywords = ["ì¶”ì„¸", "ë³€í™”", "ë¹„êµ", "ë¶„í¬", "ê·¸ë˜í”„", "ì°¨íŠ¸", "ì‹œê°í™”", "íŠ¸ë Œë“œ"]
    need_chart = any(kw in question_lower for kw in chart_keywords)

    # ì°¨íŠ¸ íƒ€ì… íŒë‹¨
    chart_type = None
    if "ì¶”ì„¸" in question_lower or "ë³€í™”" in question_lower or "íŠ¸ë Œë“œ" in question_lower:
        chart_type = "line"  # ì‹œê³„ì—´
    elif "ë¹„êµ" in question_lower or "ë¶„í¬" in question_lower or "ì„¼í„°ë³„" in question_lower or "skuë³„" in question_lower:
        chart_type = "bar"  # ë°” ì°¨íŠ¸
    elif "ë¹„ìœ¨" in question_lower or "ì ìœ " in question_lower:
        chart_type = "pie"  # íŒŒì´ ì°¨íŠ¸

    # ì—”í‹°í‹° ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)
    entities = {
        "has_sku": bool([s for s in question if s.isupper() and len(s) >= 6]),  # BA00021 ê°™ì€ íŒ¨í„´
        "has_center": any(c in question_lower for c in ["amz", "kr0", "ì„¼í„°"]),
        "time_related": any(t in question_lower for t in ["ì¼", "ì£¼", "ì›”", "ë‚ ì§œ", "ê¸°ê°„", "ì–´ì œ", "ì˜¤ëŠ˜"])
    }

    return {
        "need_chart": need_chart or chart_type is not None,
        "chart_type": chart_type,
        "entities": entities
    }


def generate_chart(
    question: str,
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame = None,
    timeline_df: pd.DataFrame = None
):
    """
    ì§ˆë¬¸ì— ë§ëŠ” ì°¨íŠ¸ ìë™ ìƒì„±

    Returns:
        plotly figure ë˜ëŠ” None
    """
    try:
        analysis = analyze_question_for_chart(question)

        if not analysis["need_chart"]:
            return None

        chart_type = analysis["chart_type"]
        entities = analysis["entities"]

        # 1. ì‹œê³„ì—´ ì°¨íŠ¸ (ì¶”ì„¸, ë³€í™”)
        if chart_type == "line" and timeline_df is not None and not timeline_df.empty:
            timeline = timeline_df.copy()
            if "date" in timeline.columns and "stock_qty" in timeline.columns:
                timeline["date"] = pd.to_datetime(timeline["date"], errors="coerce")
                timeline = timeline.sort_values("date")

                # íŠ¹ì • SKUê°€ ì–¸ê¸‰ë˜ì—ˆìœ¼ë©´ ê·¸ê²ƒë§Œ
                if entities["has_sku"] and "resource_code" in timeline.columns:
                    # ì§ˆë¬¸ì—ì„œ SKU ì¶”ì¶œ (ê°„ë‹¨ ë²„ì „)
                    import re
                    sku_pattern = r'\b[A-Z]{2}\d{5}\b'
                    skus = re.findall(sku_pattern, question)
                    if skus:
                        timeline = timeline[timeline["resource_code"].isin(skus)]

                # ì‹¤ì œ vs ì˜ˆì¸¡ êµ¬ë¶„
                if "is_forecast" in timeline.columns:
                    fig = go.Figure()

                    actual = timeline[timeline["is_forecast"] == False]
                    forecast = timeline[timeline["is_forecast"] == True]

                    if "resource_code" in timeline.columns:
                        for sku in timeline["resource_code"].unique()[:3]:  # ìµœëŒ€ 3ê°œ
                            sku_actual = actual[actual["resource_code"] == sku]
                            sku_forecast = forecast[forecast["resource_code"] == sku]

                            if not sku_actual.empty:
                                fig.add_trace(go.Scatter(
                                    x=sku_actual["date"],
                                    y=sku_actual["stock_qty"],
                                    name=f"{sku} (ì‹¤ì œ)",
                                    mode="lines+markers"
                                ))

                            if not sku_forecast.empty:
                                fig.add_trace(go.Scatter(
                                    x=sku_forecast["date"],
                                    y=sku_forecast["stock_qty"],
                                    name=f"{sku} (ì˜ˆì¸¡)",
                                    mode="lines",
                                    line=dict(dash="dash")
                                ))
                    else:
                        fig.add_trace(go.Scatter(x=actual["date"], y=actual["stock_qty"], name="ì‹¤ì œ"))
                        if not forecast.empty:
                            fig.add_trace(go.Scatter(
                                x=forecast["date"],
                                y=forecast["stock_qty"],
                                name="ì˜ˆì¸¡",
                                line=dict(dash="dash")
                            ))

                    fig.update_layout(
                        title="ì¬ê³  ì¶”ì„¸",
                        xaxis_title="ë‚ ì§œ",
                        yaxis_title="ì¬ê³ ëŸ‰",
                        height=400
                    )
                    return fig

                else:
                    fig = px.line(
                        timeline,
                        x="date",
                        y="stock_qty",
                        color="resource_code" if "resource_code" in timeline.columns else None,
                        title="ì¬ê³  ì¶”ì„¸"
                    )
                    fig.update_layout(height=400)
                    return fig

        # 2. ë°” ì°¨íŠ¸ (ì„¼í„°ë³„, SKUë³„ ë¹„êµ)
        elif chart_type == "bar":
            if "ì„¼í„°" in question or "center" in question.lower():
                # ì„¼í„°ë³„ ì¬ê³ 
                center_stock = snapshot_df.groupby("center")["stock_qty"].sum().reset_index()
                center_stock = center_stock.sort_values("stock_qty", ascending=False)

                fig = px.bar(
                    center_stock,
                    x="center",
                    y="stock_qty",
                    title="ì„¼í„°ë³„ ì¬ê³ ",
                    labels={"center": "ì„¼í„°", "stock_qty": "ì¬ê³ ëŸ‰"}
                )
                fig.update_layout(height=400)
                return fig

            elif "sku" in question.lower() or entities["has_sku"]:
                # SKUë³„ ì¬ê³  (ìƒìœ„ 10ê°œ)
                sku_stock = snapshot_df.groupby("resource_code")["stock_qty"].sum().reset_index()
                sku_stock = sku_stock.sort_values("stock_qty", ascending=False).head(10)

                fig = px.bar(
                    sku_stock,
                    x="resource_code",
                    y="stock_qty",
                    title="SKUë³„ ì¬ê³  (ìƒìœ„ 10ê°œ)",
                    labels={"resource_code": "SKU", "stock_qty": "ì¬ê³ ëŸ‰"}
                )
                fig.update_layout(height=400)
                return fig

        # 3. íŒŒì´ ì°¨íŠ¸ (ë¹„ìœ¨, ì ìœ ìœ¨)
        elif chart_type == "pie":
            center_stock = snapshot_df.groupby("center")["stock_qty"].sum().reset_index()

            fig = px.pie(
                center_stock,
                names="center",
                values="stock_qty",
                title="ì„¼í„°ë³„ ì¬ê³  ë¹„ìœ¨"
            )
            fig.update_layout(height=400)
            return fig

    except Exception as e:
        st.warning(f"ì°¨íŠ¸ ìƒì„± ì˜¤ë¥˜: {e}")

    return None


def render_simple_chatbot_tab(
    snapshot_df: pd.DataFrame,
    moves_df: pd.DataFrame,
    timeline_df: pd.DataFrame,
    selected_centers: list[str],
    selected_skus: list[str]
):
    """
    ê°„ë‹¨í•œ AI ì±—ë´‡ íƒ­ ë Œë”ë§

    Args:
        snapshot_df: ì „ì²´ ìŠ¤ëƒ…ìƒ· ë°ì´í„°
        moves_df: íŒë§¤/ì…ê³  ì´ë™ ë°ì´í„°
        timeline_df: 30ì¼ ì‹œê³„ì—´ + ì˜ˆì¸¡ ë°ì´í„°
        selected_centers: ì„ íƒëœ ì„¼í„°
        selected_skus: ì„ íƒëœ SKU
    """
    st.subheader("ğŸ¤– AI ì–´ì‹œìŠ¤í„´íŠ¸ (30ì¼ ì¶”ì„¸ + ì˜ˆì¸¡ í¬í•¨)")

    # í•„í„°ë§
    snap = snapshot_df.copy()
    if "center" in snap.columns:
        snap = snap[snap["center"].astype(str).isin(selected_centers)]
    if "resource_code" in snap.columns:
        snap = snap[snap["resource_code"].astype(str).isin(selected_skus)]

    if snap.empty:
        st.warning("ì„ íƒëœ í•„í„°ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    st.caption(f"ğŸ“Š í•„í„°ë§ëœ ë°ì´í„°: {len(snap):,}í–‰ (ì„¼í„° {snap['center'].nunique()}ê³³, SKU {snap['resource_code'].nunique()}ê°œ)")

    # í”„ë¡œì•¡í‹°ë¸Œ ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
    render_proactive_insights(snap, moves_df, timeline_df)

    st.divider()

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "last_question" not in st.session_state:
        st.session_state.last_question = ""
    if "last_answer" not in st.session_state:
        st.session_state.last_answer = ""
    if "last_context" not in st.session_state:
        st.session_state.last_context = ""

    # ì§ˆë¬¸ ì…ë ¥
    question = st.text_input(
        "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
        placeholder="ì˜ˆ: ì´ ì¬ê³ ëŠ”? / BA00021ì€ ì–´ëŠ ì„¼í„°ì—? / ì¬ê³ ê°€ ê°€ì¥ ë§ì€ ì„¼í„°ëŠ”?",
        key="simple_q",
        value=st.session_state.get("pending_question", "")
    )

    # pending_questionì´ ìˆìœ¼ë©´ ìë™ ì‹¤í–‰ í›„ í´ë¦¬ì–´
    if "pending_question" in st.session_state and st.session_state.pending_question:
        st.session_state.pop("pending_question")
        st.rerun()

    if st.button("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°", type="primary", key="simple_ask") and question:
        with st.spinner("ğŸ¤” ìƒê° ì¤‘..."):
            # ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (SKU, ì„¼í„°, ë‚ ì§œ)
            entities = extract_entities_from_question(question, snap, moves_df)

            # ìë™ í•„í„°ë§
            filtered_snap = snap.copy()
            filtered_moves = moves_df.copy() if moves_df is not None else None
            filtered_timeline = timeline_df.copy() if timeline_df is not None else None

            filter_applied = False
            filter_msg = ""

            if entities["skus"]:
                filtered_snap = filtered_snap[filtered_snap["resource_code"].isin(entities["skus"])]
                if filtered_timeline is not None and "resource_code" in filtered_timeline.columns:
                    filtered_timeline = filtered_timeline[filtered_timeline["resource_code"].isin(entities["skus"])]
                filter_msg += f"SKU: {', '.join(entities['skus'])} "
                filter_applied = True

            if entities["centers"]:
                filtered_snap = filtered_snap[filtered_snap["center"].isin(entities["centers"])]
                if filtered_moves is not None and "center" in filtered_moves.columns:
                    filtered_moves = filtered_moves[filtered_moves["center"].isin(entities["centers"])]
                if filtered_timeline is not None and "center" in filtered_timeline.columns:
                    filtered_timeline = filtered_timeline[filtered_timeline["center"].isin(entities["centers"])]
                filter_msg += f"ì„¼í„°: {', '.join(entities['centers'])} "
                filter_applied = True

            if entities["date_range"] and filtered_moves is not None:
                start_date, end_date = entities["date_range"]
                if "date" in filtered_moves.columns:
                    filtered_moves["date"] = pd.to_datetime(filtered_moves["date"], errors="coerce")
                    filtered_moves = filtered_moves[
                        (filtered_moves["date"] >= start_date) &
                        (filtered_moves["date"] <= end_date)
                    ]
                filter_msg += f"ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}"
                filter_applied = True

            if filter_applied:
                st.info(f"ğŸ¯ ìë™ í•„í„° ì ìš©: {filter_msg}")

            # ë°ì´í„° ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©!)
            context = prepare_data_context(filtered_snap, filtered_moves, filtered_timeline, max_rows=50)

            # AIì—ê²Œ ì§ˆë¬¸ (KPI ê³„ì‚° ì§€ì›)
            answer = ask_ai(question, context, filtered_snap, filtered_moves)

            # ì„¸ì…˜ì— ì €ì¥ (í•„í„°ë§ëœ ë°ì´í„°ë„ í•¨ê»˜)
            st.session_state.last_question = question
            st.session_state.last_answer = answer
            st.session_state.last_context = context
            st.session_state.last_filtered_snap = filtered_snap
            st.session_state.last_filtered_timeline = filtered_timeline

    # ë‹µë³€ í‘œì‹œ (ì„¸ì…˜ì—ì„œ ë¡œë“œ)
    if st.session_state.last_answer:
        st.markdown("### ğŸ“Š ë‹µë³€")
        st.markdown(st.session_state.last_answer)

        # ì°¨íŠ¸ ìë™ ìƒì„± (í•„í„°ë§ëœ ë°ì´í„° ì‚¬ìš©)
        chart_snap = st.session_state.get("last_filtered_snap", snap)
        chart_timeline = st.session_state.get("last_filtered_timeline", timeline_df)

        chart_fig = generate_chart(
            st.session_state.last_question,
            chart_snap,
            moves_df,
            chart_timeline
        )
        if chart_fig:
            st.plotly_chart(chart_fig, use_container_width=True)

        # í›„ì† ì§ˆë¬¸ ì œì•ˆ
        with st.spinner("ğŸ’¡ í›„ì† ì§ˆë¬¸ ì œì•ˆ ì¤‘..."):
            followup_questions = suggest_followup_questions(
                st.session_state.last_question,
                st.session_state.last_answer,
                st.session_state.last_context
            )

        if followup_questions:
            st.caption("**ğŸ’¬ ì´ëŸ° ê²ƒë„ ê¶ê¸ˆí•˜ì‹ ê°€ìš”?**")
            cols = st.columns(3)
            for i, fq in enumerate(followup_questions):
                with cols[i]:
                    if st.button(fq, key=f"followup_{i}"):
                        st.session_state.pending_question = fq
                        st.rerun()

        # ì»¨í…ìŠ¤íŠ¸ í™•ì¸ (ë””ë²„ê¹…ìš©)
        with st.expander("ğŸ” AIê°€ ë³¸ ë°ì´í„°"):
            st.text(st.session_state.last_context)

    # ì˜ˆì‹œ ì§ˆë¬¸
    st.divider()
    st.caption("**ğŸ’¡ ì˜ˆì‹œ ì§ˆë¬¸:**")

    col1, col2 = st.columns(2)
    with col1:
        st.caption("**ì¬ê³  ì¡°íšŒ**")
        st.caption("â€¢ ì´ ì¬ê³ ëŠ”?")
        st.caption("â€¢ ì„¼í„°ë³„ ì¬ê³ ëŠ”?")
        st.caption("â€¢ BA00021ì€ ì–´ëŠ ì„¼í„°ì— ìˆë‚˜ìš”?")

    with col2:
        st.caption("**ì¶”ì„¸/ì˜ˆì¸¡ ë¶„ì„ ğŸ†•**")
        st.caption("â€¢ BA00021ì˜ ì¬ê³  ì¶”ì„¸ëŠ”?")
        st.caption("â€¢ ë‹¤ìŒì£¼ ì˜ˆìƒ ì¬ê³ ëŠ”?")
        st.caption("â€¢ ì–´ëŠ SKUê°€ ì¬ê³ ê°€ ì¦ê°€í•˜ê³  ìˆë‚˜ìš”?")
